This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: log_docs/, **/*.md
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
.github/
  workflows/
    coverage.yml
    test.yml
bin/
  install.js
  postinstall.js
  scud.js
scud-cli/
  benches/
    storage_bench.rs
  src/
    commands/
      ai/
        analyze_complexity.rs
        expand.rs
        mod.rs
        parse_prd.rs
        research.rs
      add_to_group.rs
      assign.rs
      claim.rs
      create_group.rs
      group_status.rs
      init.rs
      list_groups.rs
      list.rs
      mod.rs
      next.rs
      release.rs
      set_status.rs
      show.rs
      stats.rs
      tags.rs
      use_tag.rs
      whois.rs
    llm/
      client.rs
      mod.rs
      prompts.rs
    models/
      epic.rs
      group.rs
      mod.rs
      task.rs
      workflow.rs
    storage/
      mod.rs
    lib.rs
    main.rs
  Cargo.toml
scud-mcp/
  src/
    resources/
      stats.ts
      tasks.ts
      workflow.ts
    tools/
      ai.ts
      core.ts
      epic.ts
      parallel.ts
      task.ts
    utils/
      exec.ts
    index.ts
    types.ts
  .gitignore
  .npmignore
  EXAMPLE_CONFIG.json
  package.json
  tsconfig.json
src/
  validators/
    taskmaster-validator.js
  task-manager.js
.gitignore
.npmignore
install-claude-code.sh
install-opencode.sh
package.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(find:*)"
    ],
    "deny": [],
    "ask": []
  }
}
</file>

<file path=".github/workflows/coverage.yml">
name: Coverage

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]

jobs:
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true

      - name: Install tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Generate coverage
        run: |
          cd scud-cli
          cargo tarpaulin --out Xml --output-dir ../

      - name: Upload to codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./cobertura.xml
          fail_ci_if_error: false
          verbose: true
</file>

<file path=".github/workflows/test.yml">
name: Test

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]

env:
  CARGO_TERM_COLOR: always

jobs:
  test:
    name: Test on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        rust: [stable]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: ${{ matrix.rust }}
          override: true
          components: rustfmt, clippy

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: ~/.cargo/registry
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}

      - name: Cache cargo build
        uses: actions/cache@v4
        with:
          path: scud-cli/target
          key: ${{ runner.os }}-cargo-build-target-${{ hashFiles('**/Cargo.lock') }}

      - name: Run tests
        run: |
          cd scud-cli
          cargo test --all-features

      - name: Run clippy
        run: |
          cd scud-cli
          cargo clippy --all-targets --all-features -- -D warnings

      - name: Check formatting
        run: |
          cd scud-cli
          cargo fmt -- --check

      - name: Build release binary
        run: |
          cd scud-cli
          cargo build --release

      - name: Test Node.js wrapper
        run: |
          npm install
          ./bin/scud.js --help
</file>

<file path="bin/install.js">
#!/usr/bin/env node

/**
 * BMAD-TM Lite Installation Script
 * Handles initialization and setup in user projects
 */

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

const command = process.argv[2] || 'init';
const cwd = process.cwd();

// ANSI colors
const colors = {
  green: '\x1b[32m',
  blue: '\x1b[34m',
  yellow: '\x1b[33m',
  red: '\x1b[31m',
  reset: '\x1b[0m'
};

function log(message, color = 'reset') {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

function checkTaskMaster() {
  try {
    execSync('task-master --version', { stdio: 'ignore' });
    return true;
  } catch {
    return false;
  }
}

function initProject() {
  log('\nðŸš€ Initializing BMAD-TM Lite in your project\n', 'blue');

  // Check Task Master
  log('Step 1: Checking Task Master CLI...', 'blue');
  if (checkTaskMaster()) {
    log('âœ“ Task Master CLI found', 'green');
  } else {
    log('âœ— Task Master CLI not found', 'red');
    log('\nInstall Task Master CLI:', 'yellow');
    log('  npm install -g task-master\n');
    process.exit(1);
  }

  // Create .taskmaster directory
  log('\nStep 2: Creating Task Master structure...', 'blue');
  const taskmasterDir = path.join(cwd, '.taskmaster');
  const tasksDir = path.join(taskmasterDir, 'tasks');

  if (!fs.existsSync(taskmasterDir)) {
    fs.mkdirSync(taskmasterDir, { recursive: true });
  }
  if (!fs.existsSync(tasksDir)) {
    fs.mkdirSync(tasksDir, { recursive: true });
  }

  const tasksFile = path.join(tasksDir, 'tasks.json');
  if (!fs.existsSync(tasksFile)) {
    fs.writeFileSync(tasksFile, '{}');
    log('âœ“ Created tasks.json', 'green');
  } else {
    log('âœ“ tasks.json already exists', 'green');
  }

  // Create workflow state
  log('\nStep 3: Creating workflow state...', 'blue');
  const workflowFile = path.join(taskmasterDir, 'workflow-state.json');
  if (!fs.existsSync(workflowFile)) {
    const workflowState = {
      version: '1.0.0',
      current_phase: 'ideation',
      active_epic: null,
      phases: {
        ideation: {
          status: 'active',
          completed_at: null,
          agent: 'tm-pm',
          description: 'Product definition and PRD creation'
        },
        planning: {
          status: 'pending',
          completed_at: null,
          agent: 'tm-sm',
          description: 'Epic parsing and task breakdown'
        },
        architecture: {
          status: 'pending',
          completed_at: null,
          agent: 'tm-architect',
          description: 'Technical design and architecture planning'
        },
        implementation: {
          status: 'pending',
          completed_at: null,
          agent: 'tm-dev',
          description: 'Task execution and development'
        },
        retrospective: {
          status: 'pending',
          completed_at: null,
          agent: 'tm-retrospective',
          description: 'Post-epic analysis and learning capture'
        }
      },
      history: [],
      completed_epics: [],
      last_updated: null
    };
    fs.writeFileSync(workflowFile, JSON.stringify(workflowState, null, 2));
    log('âœ“ Created workflow-state.json', 'green');
  } else {
    log('âœ“ workflow-state.json already exists', 'green');
  }

  // Create docs directories
  log('\nStep 4: Creating documentation directories...', 'blue');
  const docsDirs = ['docs/prd', 'docs/epics', 'docs/architecture', 'docs/retrospectives'];
  docsDirs.forEach(dir => {
    const fullPath = path.join(cwd, dir);
    if (!fs.existsSync(fullPath)) {
      fs.mkdirSync(fullPath, { recursive: true });
    }
  });
  log('âœ“ Documentation directories created', 'green');

  // Copy .claude commands
  log('\nStep 5: Installing slash commands...', 'blue');
  const packageRoot = path.join(__dirname, '..');
  const sourceCommands = path.join(packageRoot, '.claude');
  const targetCommands = path.join(cwd, '.claude');

  if (fs.existsSync(sourceCommands)) {
    copyDir(sourceCommands, targetCommands);
    log('âœ“ Slash commands installed to .claude/commands/', 'green');
    log('  â€¢ /status', 'blue');
    log('  â€¢ /tm-pm', 'blue');
    log('  â€¢ /tm-sm', 'blue');
    log('  â€¢ /tm-architect', 'blue');
    log('  â€¢ /tm-dev', 'blue');
    log('  â€¢ /tm-retrospective', 'blue');
  } else {
    log('âš  Could not find source commands', 'yellow');
  }

  // Create .gitignore entry
  log('\nStep 6: Updating .gitignore...', 'blue');
  const gitignorePath = path.join(cwd, '.gitignore');
  const gitignoreEntry = '\n# BMAD-TM Lite\n.taskmaster/\n';

  if (fs.existsSync(gitignorePath)) {
    const content = fs.readFileSync(gitignorePath, 'utf8');
    if (!content.includes('.taskmaster/')) {
      fs.appendFileSync(gitignorePath, gitignoreEntry);
      log('âœ“ Updated .gitignore', 'green');
    } else {
      log('âœ“ .gitignore already configured', 'green');
    }
  } else {
    fs.writeFileSync(gitignorePath, gitignoreEntry);
    log('âœ“ Created .gitignore', 'green');
  }

  // Success message
  log('\nâœ… BMAD-TM Lite initialized successfully!\n', 'green');
  log('Next steps:', 'blue');
  log('  1. Run: bmad-tm status');
  log('  2. Start with: /tm-pm (or use Claude Code slash command)\n');
}

function copyDir(src, dest) {
  if (!fs.existsSync(dest)) {
    fs.mkdirSync(dest, { recursive: true });
  }

  const entries = fs.readdirSync(src, { withFileTypes: true });

  for (const entry of entries) {
    const srcPath = path.join(src, entry.name);
    const destPath = path.join(dest, entry.name);

    if (entry.isDirectory()) {
      copyDir(srcPath, destPath);
    } else {
      fs.copyFileSync(srcPath, destPath);
    }
  }
}

// Handle commands
switch (command) {
  case 'init':
    initProject();
    break;
  case '--claude-code':
    log('Installing for Claude Code CLI...', 'blue');
    log('âš  Not yet implemented', 'yellow');
    break;
  case '--project':
    initProject();
    break;
  default:
    log(`Unknown command: ${command}`, 'red');
    process.exit(1);
}
</file>

<file path="bin/postinstall.js">
#!/usr/bin/env node

/**
 * Post-install script for npm
 * Shows helpful information after installation
 */

console.log(`
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                     â”‚
â”‚  BMAD-TM Lite installed! ðŸš€         â”‚
â”‚                                     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

To get started in your project:

  1. Initialize BMAD-TM Lite:
     $ bmad-tm init

  2. Check status:
     $ bmad-tm status

  3. Start workflow (in Claude Code):
     $ /tm-pm

ðŸ“š Documentation:
   â€¢ README.md in node_modules/bmad-tm-lite/
   â€¢ Or visit: https://github.com/yourusername/bmad-tm-lite

ðŸ’¡ Commands:
   â€¢ bmad-tm init       - Initialize in project
   â€¢ bmad-tm status     - Check workflow state
   â€¢ bmad-tm validate   - Validate setup
   â€¢ bmad-tm help       - Show help

Happy building! ðŸŽ‰
`);
</file>

<file path="scud-cli/benches/storage_bench.rs">
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use scud::models::{Epic, Task};
use scud::storage::Storage;
use std::collections::HashMap;
use tempfile::TempDir;

fn bench_load_all_vs_load_one(c: &mut Criterion) {
    let temp_dir = TempDir::new().unwrap();
    let storage = Storage::new(Some(temp_dir.path().to_path_buf()));
    storage.initialize().unwrap();

    // Create 50 epics with 100 tasks each (5000 tasks total)
    let mut tasks = HashMap::new();
    for i in 0..50 {
        let mut epic = Epic::new(format!("EPIC-{}", i));
        for j in 0..100 {
            epic.add_task(Task::new(
                format!("task-{}", j),
                format!("Task {}", j),
                "Description".to_string(),
            ));
        }
        tasks.insert(format!("EPIC-{}", i), epic);
    }
    storage.save_tasks(&tasks).unwrap();

    let mut group = c.benchmark_group("storage_operations");

    group.bench_function("load_all_epics_then_get_one", |b| {
        b.iter(|| {
            let all_tasks = storage.load_tasks().unwrap();
            black_box(all_tasks.get("EPIC-25").unwrap());
        })
    });

    group.bench_function("load_one_epic_directly", |b| {
        b.iter(|| {
            let epic = storage.load_epic("EPIC-25").unwrap();
            black_box(&epic);
        })
    });

    group.finish();
}

fn bench_active_epic_cache(c: &mut Criterion) {
    let temp_dir = TempDir::new().unwrap();
    let storage = Storage::new(Some(temp_dir.path().to_path_buf()));
    storage.initialize().unwrap();

    let mut tasks = HashMap::new();
    tasks.insert("TEST-1".to_string(), Epic::new("TEST-1".to_string()));
    storage.save_tasks(&tasks).unwrap();
    storage.set_active_epic("TEST-1").unwrap();

    let mut group = c.benchmark_group("active_epic_cache");

    group.bench_function("first_call_no_cache", |b| {
        b.iter(|| {
            storage.clear_cache();
            let active = storage.get_active_epic().unwrap();
            black_box(active);
        })
    });

    group.bench_function("second_call_with_cache", |b| {
        // Prime the cache
        storage.get_active_epic().unwrap();

        b.iter(|| {
            let active = storage.get_active_epic().unwrap();
            black_box(active);
        })
    });

    group.finish();
}

criterion_group!(benches, bench_load_all_vs_load_one, bench_active_epic_cache);
criterion_main!(benches);
</file>

<file path="scud-cli/src/commands/ai/research.rs">
use anyhow::Result;
use colored::Colorize;
use indicatif::{ProgressBar, ProgressStyle};
use std::path::PathBuf;

use crate::llm::{LLMClient, Prompts};

pub async fn run(_project_root: Option<PathBuf>, query: &str) -> Result<()> {
    let client = LLMClient::new()?;

    let spinner = ProgressBar::new_spinner();
    spinner.set_style(
        ProgressStyle::default_spinner()
            .template("{spinner:.blue} {msg}")
            .unwrap(),
    );
    spinner.set_message(format!("Researching: {}", query));
    spinner.enable_steady_tick(std::time::Duration::from_millis(100));

    let prompt = Prompts::research_topic(query);
    let response = client.complete(&prompt).await?;

    spinner.finish_and_clear();

    println!("\n{}", "Research Results".blue().bold());
    println!("{}", "================".blue());
    println!("{}: {}", "Query".yellow(), query);
    println!();
    println!("{}", response);
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/add_to_group.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, group_id: &str, epic_tag: &str) -> Result<()> {
    let storage = Storage::new(project_root);

    // Validate epic exists
    let tasks = storage.load_tasks()?;
    if !tasks.contains_key(epic_tag) {
        anyhow::bail!("Epic '{}' not found", epic_tag);
    }

    // Load and update group
    let mut groups = storage.load_groups()?;
    let group = groups
        .get_group_mut(group_id)
        .ok_or_else(|| anyhow::anyhow!("Group '{}' not found", group_id))?;

    if group.contains_epic(epic_tag) {
        anyhow::bail!("Epic '{}' is already in group '{}'", epic_tag, group_id);
    }

    group.add_epic(epic_tag.to_string());
    storage.save_groups(&groups)?;

    println!(
        "{} Added epic {} to group {}",
        "âœ“".green(),
        epic_tag.cyan(),
        group_id.green()
    );

    Ok(())
}
</file>

<file path="scud-cli/src/commands/assign.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, task_id: &str, assignee: &str) -> Result<()> {
    let storage = Storage::new(project_root);
    let active_epic = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    let mut all_tasks = storage.load_tasks()?;
    let epic = all_tasks
        .get_mut(&active_epic)
        .ok_or_else(|| anyhow::anyhow!("Epic '{}' not found", active_epic))?;

    let task = epic
        .get_task_mut(task_id)
        .ok_or_else(|| anyhow::anyhow!("Task {} not found in epic '{}'", task_id, active_epic))?;

    task.assign(assignee);
    storage.save_tasks(&all_tasks)?;

    println!(
        "{} Task {} assigned to {}",
        "âœ“".green(),
        task_id.cyan(),
        assignee.green()
    );

    Ok(())
}
</file>

<file path="scud-cli/src/commands/claim.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, task_id: &str, name: &str) -> Result<()> {
    let storage = Storage::new(project_root);
    let active_epic = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    let mut all_tasks = storage.load_tasks()?;
    let epic = all_tasks
        .get_mut(&active_epic)
        .ok_or_else(|| anyhow::anyhow!("Epic '{}' not found", active_epic))?;

    let task = epic
        .get_task_mut(task_id)
        .ok_or_else(|| anyhow::anyhow!("Task {} not found in epic '{}'", task_id, active_epic))?;

    // Try to claim the task
    match task.claim(name) {
        Ok(()) => {
            // Get task title before saving (to avoid borrow checker issues)
            let task_title = task.title.clone();

            storage.save_tasks(&all_tasks)?;

            println!("{}", "âœ… Task claimed successfully!".green().bold());
            println!();
            println!("{:<20} {}", "Task ID:".yellow(), task_id.cyan());
            println!("{:<20} {}", "Title:".yellow(), task_title.bold());
            println!("{:<20} {}", "Claimed by:".yellow(), name.green());
            println!("{:<20} {}", "Status:".yellow(), "locked".yellow());
            println!();
            println!("{}", "Next steps:".blue());
            println!("  1. Start working on the task");
            println!("  2. Run: scud set-status {} in-progress", task_id);
            println!("  3. When done: scud set-status {} done", task_id);
            println!("  4. Task will auto-release when marked done");
            println!();
        }
        Err(err) => {
            anyhow::bail!("Failed to claim task: {}", err);
        }
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/create_group.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::models::EpicGroup;
use crate::storage::Storage;

pub fn run(
    project_root: Option<PathBuf>,
    name: &str,
    epics_str: &str,
    description: Option<&str>,
) -> Result<()> {
    let storage = Storage::new(project_root);

    // Parse epic tags
    let epic_tags: Vec<String> = epics_str
        .split(',')
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();

    if epic_tags.is_empty() {
        anyhow::bail!("At least one epic tag is required");
    }

    // Validate that all epics exist
    let tasks = storage.load_tasks()?;
    for tag in &epic_tags {
        if !tasks.contains_key(tag) {
            anyhow::bail!("Epic '{}' not found", tag);
        }
    }

    // Generate group ID from name
    let group_id = name
        .to_lowercase()
        .replace(char::is_whitespace, "-")
        .replace(|c: char| !c.is_alphanumeric() && c != '-', "");

    // Load existing groups
    let mut groups = storage.load_groups()?;

    // Check if group ID already exists
    if groups.get_group(&group_id).is_some() {
        anyhow::bail!("Group '{}' already exists", group_id);
    }

    // Create new group
    let mut group = EpicGroup::new(group_id.clone(), name.to_string(), epic_tags.clone());
    if let Some(desc) = description {
        group.description = Some(desc.to_string());
    }

    groups.add_group(group);
    storage.save_groups(&groups)?;

    println!("{}", "âœ… Epic group created!".green().bold());
    println!();
    println!("{:<20} {}", "Group ID:".yellow(), group_id.cyan());
    println!("{:<20} {}", "Name:".yellow(), name);
    println!("{:<20} {}", "Epics:".yellow(), epic_tags.join(", "));
    if let Some(desc) = description {
        println!("{:<20} {}", "Description:".yellow(), desc);
    }
    println!();
    println!("{}", "Usage:".blue());
    println!("  scud group-status {}", group_id);
    println!("  scud list --group {}", group_id);
    println!("  scud stats --group {}", group_id);
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/init.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);

    if storage.is_initialized() {
        println!("{}", "âœ“ SCUD is already initialized".green());
        return Ok(());
    }

    println!("{}", "Initializing SCUD...".blue());

    storage.initialize()?;

    println!("\n{}", "âœ… SCUD initialized successfully!".green().bold());
    println!("\n{}", "Next steps:".blue());
    println!("  1. Run: scud tags");
    println!("  2. Start with: /tm-pm (or use Claude Code slash command)\n");

    Ok(())
}
</file>

<file path="scud-cli/src/commands/use_tag.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, tag: &str) -> Result<()> {
    let storage = Storage::new(project_root);
    storage.set_active_epic(tag)?;

    println!("{} {}", "âœ“ Active epic set to:".green(), tag.green().bold());

    let tasks = storage.load_tasks()?;
    if let Some(epic) = tasks.get(tag) {
        let stats = epic.get_stats();
        println!("  Tasks: {}", stats.total);
        println!("  Pending: {}", stats.pending);
        println!("  In Progress: {}", stats.in_progress);
        println!("  Done: {}", stats.done);
    }

    Ok(())
}
</file>

<file path="scud-cli/src/llm/mod.rs">
pub mod client;
pub mod prompts;

pub use client::LLMClient;
pub use prompts::Prompts;
</file>

<file path="scud-cli/src/lib.rs">
// Library entry point for SCUD
// This allows testing and using SCUD as a library

pub mod commands;
pub mod llm;
pub mod models;
pub mod storage;
</file>

<file path="scud-mcp/src/resources/stats.ts">
/**
 * Statistics resources - provides read-only access to epic statistics
 */

import type {
  ReadResourceRequest,
  ReadResourceResult,
  Resource,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const STATS_RESOURCES: Resource[] = [
  {
    uri: 'scud://stats/epic',
    name: 'Epic statistics',
    description: 'Read statistics for the active epic (task counts, complexity breakdown)',
    mimeType: 'text/plain',
  },
];

export async function handleStatsResource(
  request: ReadResourceRequest
): Promise<ReadResourceResult> {
  const { uri } = request.params;

  if (uri === 'scud://stats/epic') {
    try {
      const result = await executeScudCommand(['stats']);

      if (result.exitCode !== 0) {
        return {
          contents: [{
            uri,
            mimeType: 'text/plain',
            text: `Error reading stats: ${result.stderr || result.stdout}`,
          }],
        };
      }

      return {
        contents: [{
          uri,
          mimeType: 'text/plain',
          text: result.stdout,
        }],
      };
    } catch (error: any) {
      return {
        contents: [{
          uri,
          mimeType: 'text/plain',
          text: `Error reading stats: ${error.message}`,
        }],
      };
    }
  }

  throw new Error(`Unknown stats resource: ${uri}`);
}
</file>

<file path="scud-mcp/src/resources/tasks.ts">
/**
 * Tasks resources - provides read-only access to tasks
 */

import type {
  ReadResourceRequest,
  ReadResourceResult,
  Resource,
} from '@modelcontextprotocol/sdk/types.js';
import { readFile } from 'fs/promises';
import { join } from 'path';

export const TASK_RESOURCES: Resource[] = [
  {
    uri: 'scud://tasks/list',
    name: 'All tasks in active epic',
    description: 'Read all tasks for the currently active epic',
    mimeType: 'application/json',
  },
];

export async function handleTaskResource(
  request: ReadResourceRequest
): Promise<ReadResourceResult> {
  const { uri } = request.params;

  if (uri === 'scud://tasks/list') {
    try {
      // Read tasks file
      const tasksFile = join(process.cwd(), '.taskmaster', 'tasks', 'tasks.json');
      const content = await readFile(tasksFile, 'utf-8');
      const allTasks = JSON.parse(content);

      // Read workflow state to get active epic
      const stateFile = join(process.cwd(), '.taskmaster', 'workflow-state.json');
      const stateContent = await readFile(stateFile, 'utf-8');
      const state = JSON.parse(stateContent);

      if (!state.active_epic) {
        return {
          contents: [{
            uri,
            mimeType: 'text/plain',
            text: 'No active epic set',
          }],
        };
      }

      // Get tasks for active epic
      const activeTasks = allTasks[state.active_epic] || { tasks: [] };

      return {
        contents: [{
          uri,
          mimeType: 'application/json',
          text: JSON.stringify(activeTasks, null, 2),
        }],
      };
    } catch (error: any) {
      return {
        contents: [{
          uri,
          mimeType: 'text/plain',
          text: `Error reading tasks: ${error.message}`,
        }],
      };
    }
  }

  throw new Error(`Unknown task resource: ${uri}`);
}
</file>

<file path="scud-mcp/src/resources/workflow.ts">
/**
 * Workflow state resource - provides read-only access to workflow state
 */

import type {
  ReadResourceRequest,
  ReadResourceResult,
  Resource,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';
import { readFile } from 'fs/promises';
import { join } from 'path';

export const WORKFLOW_RESOURCES: Resource[] = [
  {
    uri: 'scud://workflow/state',
    name: 'Current workflow state',
    description: 'Read the current workflow state including active epic and phase information',
    mimeType: 'application/json',
  },
];

export async function handleWorkflowResource(
  request: ReadResourceRequest
): Promise<ReadResourceResult> {
  const { uri } = request.params;

  if (uri === 'scud://workflow/state') {
    try {
      // Read workflow state directly from file
      const stateFile = join(process.cwd(), '.taskmaster', 'workflow-state.json');
      const content = await readFile(stateFile, 'utf-8');
      const state = JSON.parse(content);

      return {
        contents: [{
          uri,
          mimeType: 'application/json',
          text: JSON.stringify(state, null, 2),
        }],
      };
    } catch (error: any) {
      return {
        contents: [{
          uri,
          mimeType: 'text/plain',
          text: `Error reading workflow state: ${error.message}`,
        }],
      };
    }
  }

  throw new Error(`Unknown workflow resource: ${uri}`);
}
</file>

<file path="scud-mcp/src/tools/ai.ts">
/**
 * AI-powered tools - require ANTHROPIC_API_KEY
 */

import type {
  CallToolRequest,
  CallToolResult,
  Tool,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const AI_TOOLS: Tool[] = [
  {
    name: 'scud_parse_prd',
    description: 'Parse a PRD/epic markdown file into tasks using AI. Requires ANTHROPIC_API_KEY environment variable.',
    inputSchema: {
      type: 'object',
      properties: {
        file: {
          type: 'string',
          description: 'Path to PRD/epic markdown file (e.g., "docs/epics/epic-1-auth.md")',
        },
        tag: {
          type: 'string',
          description: 'Epic tag to create (e.g., "epic-1-auth")',
        },
      },
      required: ['file', 'tag'],
    },
  },
  {
    name: 'scud_analyze_complexity',
    description: 'Analyze task complexity using AI. Returns Fibonacci complexity score (1,2,3,5,8,13,21) with reasoning. Requires ANTHROPIC_API_KEY.',
    inputSchema: {
      type: 'object',
      properties: {
        task: {
          type: 'string',
          description: 'Specific task ID to analyze (analyzes all tasks if not provided)',
        },
      },
    },
  },
  {
    name: 'scud_expand',
    description: 'Break down complex tasks (>13 complexity) into smaller subtasks using AI. Requires ANTHROPIC_API_KEY.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'Task ID to expand (expands all tasks >13 if not provided)',
        },
        all: {
          type: 'boolean',
          description: 'Expand all tasks with complexity > 13',
          default: false,
        },
      },
    },
  },
  {
    name: 'scud_research',
    description: 'Perform AI-powered research on a topic and save findings. Requires ANTHROPIC_API_KEY.',
    inputSchema: {
      type: 'object',
      properties: {
        query: {
          type: 'string',
          description: 'Research query or question',
        },
      },
      required: ['query'],
    },
  },
];

export async function handleAITool(
  request: CallToolRequest
): Promise<CallToolResult> {
  const { name, arguments: args } = request.params;

  // Check for API key
  if (!process.env.ANTHROPIC_API_KEY) {
    return {
      content: [{
        type: 'text',
        text: 'Error: ANTHROPIC_API_KEY environment variable not set. AI tools require this API key.',
      }],
      isError: true,
    };
  }

  switch (name) {
    case 'scud_parse_prd': {
      if (!args?.file || !args?.tag) {
        return {
          content: [{
            type: 'text',
            text: 'Error: file and tag are required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand([
        'parse-prd',
        args.file as string,
        '--tag',
        args.tag as string,
      ]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error parsing PRD: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_analyze_complexity': {
      const cmdArgs = ['analyze-complexity'];
      if (args?.task) {
        cmdArgs.push('--task', args.task as string);
      }

      const result = await executeScudCommand(cmdArgs);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error analyzing complexity: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_expand': {
      const cmdArgs = ['expand'];

      if (args?.task_id) {
        cmdArgs.push(args.task_id as string);
      } else if (args?.all) {
        cmdArgs.push('--all');
      }

      const result = await executeScudCommand(cmdArgs);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error expanding tasks: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_research': {
      if (!args?.query) {
        return {
          content: [{
            type: 'text',
            text: 'Error: query is required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand([
        'research',
        args.query as string,
      ]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error performing research: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    default:
      return {
        content: [{
          type: 'text',
          text: `Unknown AI tool: ${name}`,
        }],
        isError: true,
      };
  }
}
</file>

<file path="scud-mcp/src/tools/core.ts">
/**
 * Core SCUD tools - basic commands that don't require AI
 */

import type { Server } from '@modelcontextprotocol/sdk/server/index.js';
import type {
  CallToolRequest,
  CallToolResult,
  Tool,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const CORE_TOOLS: Tool[] = [
  {
    name: 'scud_init',
    description: 'Initialize SCUD in the current directory. Creates .taskmaster/ directory structure.',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
  {
    name: 'scud_list',
    description: 'List all tasks in the active epic. Optionally filter by status.',
    inputSchema: {
      type: 'object',
      properties: {
        status: {
          type: 'string',
          description: 'Filter by task status',
          enum: ['pending', 'in-progress', 'done', 'review', 'blocked', 'deferred', 'cancelled'],
        },
      },
    },
  },
  {
    name: 'scud_next',
    description: 'Find the next available task to work on. Respects dependencies and current status.',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
  {
    name: 'scud_stats',
    description: 'Show statistics for the active epic (task counts, complexity breakdown).',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
];

export async function handleCoreTool(
  request: CallToolRequest
): Promise<CallToolResult> {
  const { name, arguments: args } = request.params;

  switch (name) {
    case 'scud_init': {
      const result = await executeScudCommand(['init']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error initializing SCUD: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'SCUD initialized successfully',
        }],
      };
    }

    case 'scud_list': {
      const cmdArgs = ['list'];
      if (args?.status) {
        cmdArgs.push('--status', args.status as string);
      }

      const result = await executeScudCommand(cmdArgs);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error listing tasks: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No tasks found',
        }],
      };
    }

    case 'scud_next': {
      const result = await executeScudCommand(['next']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error finding next task: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No available tasks',
        }],
      };
    }

    case 'scud_stats': {
      const result = await executeScudCommand(['stats']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error getting stats: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No statistics available',
        }],
      };
    }

    default:
      return {
        content: [{
          type: 'text',
          text: `Unknown core tool: ${name}`,
        }],
        isError: true,
      };
  }
}
</file>

<file path="scud-mcp/src/tools/epic.ts">
/**
 * Epic management tools - working with epic tags
 */

import type {
  CallToolRequest,
  CallToolResult,
  Tool,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const EPIC_TOOLS: Tool[] = [
  {
    name: 'scud_tags',
    description: 'List all available epic tags in the project.',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
  {
    name: 'scud_use_tag',
    description: 'Set the active epic tag to work with.',
    inputSchema: {
      type: 'object',
      properties: {
        tag: {
          type: 'string',
          description: 'The epic tag to activate (e.g., "epic-1-auth")',
        },
      },
      required: ['tag'],
    },
  },
];

export async function handleEpicTool(
  request: CallToolRequest
): Promise<CallToolResult> {
  const { name, arguments: args } = request.params;

  switch (name) {
    case 'scud_tags': {
      const result = await executeScudCommand(['tags']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error listing tags: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No epic tags found',
        }],
      };
    }

    case 'scud_use_tag': {
      if (!args?.tag) {
        return {
          content: [{
            type: 'text',
            text: 'Error: tag is required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand(['use-tag', args.tag as string]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error setting active tag: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || `Active epic set to: ${args.tag}`,
        }],
      };
    }

    default:
      return {
        content: [{
          type: 'text',
          text: `Unknown epic tool: ${name}`,
        }],
        isError: true,
      };
  }
}
</file>

<file path="scud-mcp/src/tools/parallel.ts">
/**
 * Parallel development tools - epic groups and task assignments
 */

import type {
  CallToolRequest,
  CallToolResult,
  Tool,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const PARALLEL_TOOLS: Tool[] = [
  {
    name: 'scud_create_group',
    description: 'Create an epic group for parallel development across multiple epics.',
    inputSchema: {
      type: 'object',
      properties: {
        name: {
          type: 'string',
          description: 'Group name (e.g., "sprint-1")',
        },
        epics: {
          type: 'string',
          description: 'Comma-separated list of epic tags (e.g., "epic-1,epic-2,epic-3")',
        },
        description: {
          type: 'string',
          description: 'Optional group description',
        },
      },
      required: ['name', 'epics'],
    },
  },
  {
    name: 'scud_list_groups',
    description: 'List all epic groups.',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
  {
    name: 'scud_group_status',
    description: 'Show status and progress for an epic group.',
    inputSchema: {
      type: 'object',
      properties: {
        group_id: {
          type: 'string',
          description: 'Group ID or name',
        },
      },
      required: ['group_id'],
    },
  },
  {
    name: 'scud_assign',
    description: 'Assign a task to a developer.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'Task ID to assign',
        },
        assignee: {
          type: 'string',
          description: 'Developer name or username',
        },
      },
      required: ['task_id', 'assignee'],
    },
  },
  {
    name: 'scud_claim',
    description: 'Claim a task for yourself. Prevents others from working on it.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'Task ID to claim',
        },
        name: {
          type: 'string',
          description: 'Your name or username',
        },
      },
      required: ['task_id', 'name'],
    },
  },
  {
    name: 'scud_release',
    description: 'Release a claimed task so others can work on it.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'Task ID to release',
        },
        force: {
          type: 'boolean',
          description: 'Force release even if claimed by someone else',
          default: false,
        },
      },
      required: ['task_id'],
    },
  },
  {
    name: 'scud_whois',
    description: 'Show task assignments and who is working on what.',
    inputSchema: {
      type: 'object',
      properties: {},
    },
  },
];

export async function handleParallelTool(
  request: CallToolRequest
): Promise<CallToolResult> {
  const { name, arguments: args } = request.params;

  switch (name) {
    case 'scud_create_group': {
      if (!args?.name || !args?.epics) {
        return {
          content: [{
            type: 'text',
            text: 'Error: name and epics are required',
          }],
          isError: true,
        };
      }

      const cmdArgs = [
        'create-group',
        args.name as string,
        '--epics',
        args.epics as string,
      ];

      if (args.description) {
        cmdArgs.push('--description', args.description as string);
      }

      const result = await executeScudCommand(cmdArgs);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error creating group: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_list_groups': {
      const result = await executeScudCommand(['list-groups']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error listing groups: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No epic groups found',
        }],
      };
    }

    case 'scud_group_status': {
      if (!args?.group_id) {
        return {
          content: [{
            type: 'text',
            text: 'Error: group_id is required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand(['group-status', args.group_id as string]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error getting group status: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_assign': {
      if (!args?.task_id || !args?.assignee) {
        return {
          content: [{
            type: 'text',
            text: 'Error: task_id and assignee are required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand([
        'assign',
        args.task_id as string,
        args.assignee as string,
      ]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error assigning task: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || `Task ${args.task_id} assigned to ${args.assignee}`,
        }],
      };
    }

    case 'scud_claim': {
      if (!args?.task_id || !args?.name) {
        return {
          content: [{
            type: 'text',
            text: 'Error: task_id and name are required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand([
        'claim',
        args.task_id as string,
        '--name',
        args.name as string,
      ]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error claiming task: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || `Task ${args.task_id} claimed by ${args.name}`,
        }],
      };
    }

    case 'scud_release': {
      if (!args?.task_id) {
        return {
          content: [{
            type: 'text',
            text: 'Error: task_id is required',
          }],
          isError: true,
        };
      }

      const cmdArgs = ['release', args.task_id as string];
      if (args.force) {
        cmdArgs.push('--force');
      }

      const result = await executeScudCommand(cmdArgs);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error releasing task: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || `Task ${args.task_id} released`,
        }],
      };
    }

    case 'scud_whois': {
      const result = await executeScudCommand(['whois']);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error getting assignments: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || 'No task assignments found',
        }],
      };
    }

    default:
      return {
        content: [{
          type: 'text',
          text: `Unknown parallel tool: ${name}`,
        }],
        isError: true,
      };
  }
}
</file>

<file path="scud-mcp/src/tools/task.ts">
/**
 * Task operation tools - working with individual tasks
 */

import type {
  CallToolRequest,
  CallToolResult,
  Tool,
} from '@modelcontextprotocol/sdk/types.js';
import { executeScudCommand } from '../utils/exec.js';

export const TASK_TOOLS: Tool[] = [
  {
    name: 'scud_show',
    description: 'Show detailed information about a specific task.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'The task ID to show details for (e.g., "TASK-1")',
        },
      },
      required: ['task_id'],
    },
  },
  {
    name: 'scud_set_status',
    description: 'Update the status of a task.',
    inputSchema: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'The task ID to update',
        },
        status: {
          type: 'string',
          description: 'New status for the task',
          enum: ['pending', 'in-progress', 'done', 'review', 'blocked', 'deferred', 'cancelled'],
        },
      },
      required: ['task_id', 'status'],
    },
  },
];

export async function handleTaskTool(
  request: CallToolRequest
): Promise<CallToolResult> {
  const { name, arguments: args } = request.params;

  switch (name) {
    case 'scud_show': {
      if (!args?.task_id) {
        return {
          content: [{
            type: 'text',
            text: 'Error: task_id is required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand(['show', args.task_id as string]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error showing task: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout,
        }],
      };
    }

    case 'scud_set_status': {
      if (!args?.task_id || !args?.status) {
        return {
          content: [{
            type: 'text',
            text: 'Error: task_id and status are required',
          }],
          isError: true,
        };
      }

      const result = await executeScudCommand([
        'set-status',
        args.task_id as string,
        args.status as string,
      ]);

      if (result.exitCode !== 0) {
        return {
          content: [{
            type: 'text',
            text: `Error setting task status: ${result.stderr || result.stdout}`,
          }],
          isError: true,
        };
      }

      return {
        content: [{
          type: 'text',
          text: result.stdout || `Task ${args.task_id} status updated to ${args.status}`,
        }],
      };
    }

    default:
      return {
        content: [{
          type: 'text',
          text: `Unknown task tool: ${name}`,
        }],
        isError: true,
      };
  }
}
</file>

<file path="scud-mcp/src/utils/exec.ts">
/**
 * CLI execution wrapper for SCUD commands
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import type { ScudCommandResult } from '../types.js';

const execAsync = promisify(exec);

export interface ExecOptions {
  cwd?: string;
  timeout?: number;
}

/**
 * Execute a SCUD CLI command and return the result
 */
export async function executeScudCommand(
  args: string[],
  options?: ExecOptions
): Promise<ScudCommandResult> {
  const command = `scud ${args.join(' ')}`;

  try {
    const { stdout, stderr } = await execAsync(command, {
      cwd: options?.cwd || process.cwd(),
      timeout: options?.timeout || 30000, // 30 second default timeout
      env: {
        ...process.env,
        // Inherit ANTHROPIC_API_KEY and other env vars
      },
      // Increase buffer size for large outputs
      maxBuffer: 10 * 1024 * 1024, // 10MB
    });

    return {
      stdout: stdout.trim(),
      stderr: stderr.trim(),
      exitCode: 0,
    };
  } catch (error: any) {
    return {
      stdout: error.stdout?.trim() || '',
      stderr: error.stderr?.trim() || error.message,
      exitCode: error.code || 1,
    };
  }
}

/**
 * Parse JSON output from SCUD command
 */
export function parseJsonOutput<T>(stdout: string): T {
  try {
    return JSON.parse(stdout);
  } catch (error) {
    throw new Error(`Failed to parse SCUD output as JSON: ${error}`);
  }
}

/**
 * Check if SCUD CLI is available in PATH
 */
export async function checkScudAvailable(): Promise<boolean> {
  try {
    const result = await executeScudCommand(['--version']);
    return result.exitCode === 0;
  } catch {
    return false;
  }
}

/**
 * Validate that a command succeeded
 */
export function ensureSuccess(result: ScudCommandResult, context: string): void {
  if (result.exitCode !== 0) {
    throw new Error(
      `SCUD command failed (${context}): ${result.stderr || result.stdout}`
    );
  }
}
</file>

<file path="scud-mcp/src/index.ts">
#!/usr/bin/env node

/**
 * SCUD MCP Server - Model Context Protocol server for SCUD task management
 *
 * This server wraps the SCUD CLI and exposes it through the MCP protocol,
 * enabling AI assistants like Claude to interact with SCUD task management.
 */

import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
  ListResourcesRequestSchema,
  ReadResourceRequestSchema,
} from '@modelcontextprotocol/sdk/types.js';

// Import all tool handlers
import { CORE_TOOLS, handleCoreTool } from './tools/core.js';
import { EPIC_TOOLS, handleEpicTool } from './tools/epic.js';
import { TASK_TOOLS, handleTaskTool } from './tools/task.js';
import { AI_TOOLS, handleAITool } from './tools/ai.js';
import { PARALLEL_TOOLS, handleParallelTool } from './tools/parallel.js';

// Import all resource handlers
import { WORKFLOW_RESOURCES, handleWorkflowResource } from './resources/workflow.js';
import { TASK_RESOURCES, handleTaskResource } from './resources/tasks.js';
import { STATS_RESOURCES, handleStatsResource } from './resources/stats.js';

import { checkScudAvailable } from './utils/exec.js';

// Combine all tools
const ALL_TOOLS = [
  ...CORE_TOOLS,
  ...EPIC_TOOLS,
  ...TASK_TOOLS,
  ...AI_TOOLS,
  ...PARALLEL_TOOLS,
];

// Combine all resources
const ALL_RESOURCES = [
  ...WORKFLOW_RESOURCES,
  ...TASK_RESOURCES,
  ...STATS_RESOURCES,
];

// Create MCP server
const server = new Server(
  {
    name: 'scud-mcp',
    version: '1.0.0',
  },
  {
    capabilities: {
      tools: {},
      resources: {},
    },
  }
);

// List available tools
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: ALL_TOOLS,
  };
});

// Handle tool execution
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const toolName = request.params.name;

  // Route to appropriate handler based on tool name
  if (CORE_TOOLS.some(t => t.name === toolName)) {
    return handleCoreTool(request);
  }

  if (EPIC_TOOLS.some(t => t.name === toolName)) {
    return handleEpicTool(request);
  }

  if (TASK_TOOLS.some(t => t.name === toolName)) {
    return handleTaskTool(request);
  }

  if (AI_TOOLS.some(t => t.name === toolName)) {
    return handleAITool(request);
  }

  if (PARALLEL_TOOLS.some(t => t.name === toolName)) {
    return handleParallelTool(request);
  }

  // Unknown tool
  return {
    content: [{
      type: 'text',
      text: `Unknown tool: ${toolName}`,
    }],
    isError: true,
  };
});

// List available resources
server.setRequestHandler(ListResourcesRequestSchema, async () => {
  return {
    resources: ALL_RESOURCES,
  };
});

// Handle resource reads
server.setRequestHandler(ReadResourceRequestSchema, async (request) => {
  const uri = request.params.uri;

  // Route to appropriate handler based on URI
  if (uri.startsWith('scud://workflow/')) {
    return handleWorkflowResource(request);
  }

  if (uri.startsWith('scud://tasks/')) {
    return handleTaskResource(request);
  }

  if (uri.startsWith('scud://stats/')) {
    return handleStatsResource(request);
  }

  // Unknown resource
  throw new Error(`Unknown resource URI: ${uri}`);
});

// Start server
async function main() {
  // Check if SCUD CLI is available
  const isAvailable = await checkScudAvailable();
  if (!isAvailable) {
    console.error('Error: SCUD CLI not found in PATH');
    console.error('Please install SCUD first: npm install -g scud');
    process.exit(1);
  }

  // Start MCP server with stdio transport
  const transport = new StdioServerTransport();
  await server.connect(transport);

  console.error('SCUD MCP server started successfully');
  console.error(`Exposing ${ALL_TOOLS.length} tools and ${ALL_RESOURCES.length} resources`);
}

main().catch((error) => {
  console.error('Fatal error starting SCUD MCP server:', error);
  process.exit(1);
});
</file>

<file path="scud-mcp/src/types.ts">
/**
 * TypeScript type definitions for SCUD MCP server
 */

export interface ScudCommandResult {
  stdout: string;
  stderr: string;
  exitCode: number;
}

export interface ScudTask {
  id: string;
  title: string;
  description: string;
  status: TaskStatus;
  priority: Priority;
  complexity: number;
  dependencies: string[];
  assigned_to?: string;
  locked_by?: string;
  locked_at?: string;
  created_at: string;
  updated_at: string;
  details?: string;
}

export type TaskStatus =
  | 'pending'
  | 'in-progress'
  | 'done'
  | 'review'
  | 'blocked'
  | 'deferred'
  | 'cancelled';

export type Priority = 'high' | 'medium' | 'low';

export interface ScudEpic {
  tag: string;
  tasks: ScudTask[];
}

export interface WorkflowState {
  active_epic?: string;
  current_phase: string;
  phases: Record<string, PhaseInfo>;
  completed_epics: CompletedEpic[];
}

export interface PhaseInfo {
  status: string;
  started_at?: string;
  completed_at?: string;
}

export interface CompletedEpic {
  tag: string;
  completed_at: string;
  total_tasks: number;
  total_complexity: number;
}

export interface EpicStats {
  total_tasks: number;
  by_status: Record<TaskStatus, number>;
  total_complexity: number;
  completed_complexity: number;
}

export interface EpicGroup {
  id: string;
  name: string;
  description?: string;
  epic_tags: string[];
  created_at: string;
}
</file>

<file path="scud-mcp/.gitignore">
# Dependencies
node_modules/
package-lock.json

# Build output
dist/
*.tsbuildinfo

# Logs
*.log
npm-debug.log*

# Environment
.env
.env.local

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
</file>

<file path="scud-mcp/.npmignore">
# Source files (only ship dist/)
src/
tsconfig.json

# Development files
.git/
.gitignore
*.log

# Documentation (keep README)
# README.md is included automatically
</file>

<file path="scud-mcp/EXAMPLE_CONFIG.json">
{
  "mcpServers": {
    "scud": {
      "command": "scud-mcp",
      "env": {
        "ANTHROPIC_API_KEY": "sk-ant-your-api-key-here"
      }
    }
  }
}
</file>

<file path="scud-mcp/package.json">
{
  "name": "scud-mcp",
  "version": "1.0.0",
  "description": "Model Context Protocol server for SCUD task management",
  "type": "module",
  "bin": {
    "scud-mcp": "./dist/index.js"
  },
  "scripts": {
    "build": "tsc",
    "dev": "tsc --watch",
    "prepare": "npm run build"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.4"
  },
  "devDependencies": {
    "@types/node": "^20.11.0",
    "typescript": "^5.3.3"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "keywords": [
    "mcp",
    "model-context-protocol",
    "scud",
    "task-management",
    "ai",
    "workflow",
    "sprint",
    "agile"
  ],
  "author": "",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/bmad-tm"
  }
}
</file>

<file path="scud-mcp/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "Node16",
    "moduleResolution": "Node16",
    "lib": ["ES2022"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="install-claude-code.sh">
#!/bin/bash

# BMAD-TM Lite Installation Script for Claude Code CLI
# This script sets up the workflow orchestration system

set -e

echo "ðŸš€ BMAD-TM Lite Installation for Claude Code CLI"
echo "=================================================="
echo ""

# Colors for output
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Get project root
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
echo -e "${BLUE}Project root:${NC} $PROJECT_ROOT"
echo ""

# Check if Task Master CLI is installed
echo -e "${BLUE}Step 1: Checking Task Master CLI...${NC}"
if command -v task-master &> /dev/null; then
    TASKMASTER_VERSION=$(task-master --version 2>&1 || echo "unknown")
    echo -e "${GREEN}âœ“ Task Master CLI found${NC} ($TASKMASTER_VERSION)"
else
    echo -e "${RED}âœ— Task Master CLI not found${NC}"
    echo ""
    echo "Install Task Master CLI:"
    echo "  npm install -g task-master"
    echo ""
    read -p "Would you like to install it now? (y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        npm install -g task-master
        echo -e "${GREEN}âœ“ Task Master CLI installed${NC}"
    else
        echo -e "${YELLOW}âš  Skipping Task Master CLI installation${NC}"
        echo "You'll need to install it manually before using BMAD-TM Lite"
    fi
fi
echo ""

# Check if Node.js is installed (for validator)
echo -e "${BLUE}Step 2: Checking Node.js...${NC}"
if command -v node &> /dev/null; then
    NODE_VERSION=$(node --version)
    echo -e "${GREEN}âœ“ Node.js found${NC} ($NODE_VERSION)"
else
    echo -e "${RED}âœ— Node.js not found${NC}"
    echo "Node.js is required for the Task Master validator."
    echo "Install from: https://nodejs.org/"
    exit 1
fi
echo ""

# Initialize Task Master if not already done
echo -e "${BLUE}Step 3: Initializing Task Master...${NC}"
cd "$PROJECT_ROOT"
if [ -f ".taskmaster/tasks/tasks.json" ]; then
    echo -e "${GREEN}âœ“ Task Master already initialized${NC}"
else
    mkdir -p .taskmaster/tasks
    echo '{}' > .taskmaster/tasks/tasks.json
    echo -e "${GREEN}âœ“ Task Master initialized${NC}"
fi
echo ""

# Create workflow state file
echo -e "${BLUE}Step 4: Creating workflow state...${NC}"
if [ -f ".taskmaster/workflow-state.json" ]; then
    echo -e "${YELLOW}âš  Workflow state already exists${NC}"
    read -p "Overwrite? (y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo -e "${BLUE}â†’ Keeping existing workflow state${NC}"
    else
        cp .taskmaster/workflow-state.json .taskmaster/workflow-state.json.backup
        echo -e "${YELLOW}â†’ Backed up to .taskmaster/workflow-state.json.backup${NC}"
        # Create fresh state
        cat > .taskmaster/workflow-state.json << 'EOF'
{
  "version": "1.0.0",
  "current_phase": "ideation",
  "active_epic": null,
  "phases": {
    "ideation": {
      "status": "active",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Product definition and PRD creation"
    },
    "planning": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Parse PRD into Task Master epics and tasks"
    },
    "architecture": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-architect",
      "description": "Technical design and architecture planning"
    },
    "implementation": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-dev",
      "description": "Task execution and development"
    },
    "retrospective": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-retrospective",
      "description": "Post-epic analysis and learning capture"
    }
  },
  "history": [],
  "completed_epics": [],
  "last_updated": null
}
EOF
        echo -e "${GREEN}âœ“ Workflow state created${NC}"
    fi
else
    cat > .taskmaster/workflow-state.json << 'EOF'
{
  "version": "1.0.0",
  "current_phase": "ideation",
  "active_epic": null,
  "phases": {
    "ideation": {
      "status": "active",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Product definition and PRD creation"
    },
    "planning": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Parse PRD into Task Master epics and tasks"
    },
    "architecture": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-architect",
      "description": "Technical design and architecture planning"
    },
    "implementation": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-dev",
      "description": "Task execution and development"
    },
    "retrospective": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-retrospective",
      "description": "Post-epic analysis and learning capture"
    }
  },
  "history": [],
  "completed_epics": [],
  "last_updated": null
}
EOF
    echo -e "${GREEN}âœ“ Workflow state created${NC}"
fi
echo ""

# Create directory structure
echo -e "${BLUE}Step 5: Creating directory structure...${NC}"
mkdir -p docs/prd
mkdir -p docs/epics
mkdir -p docs/architecture
mkdir -p docs/retrospectives
echo -e "${GREEN}âœ“ Directory structure created${NC}"
echo ""

# Copy slash commands to Claude Code directory
echo -e "${BLUE}Step 6: Installing slash commands...${NC}"
CLAUDE_COMMANDS_DIR="$HOME/.config/claude-code/commands"

if [ -d "$CLAUDE_COMMANDS_DIR" ]; then
    cp -r .claude/commands/* "$CLAUDE_COMMANDS_DIR/"
    echo -e "${GREEN}âœ“ Slash commands installed to $CLAUDE_COMMANDS_DIR${NC}"
    echo "  â€¢ /status"
    echo "  â€¢ /tm-pm"
    echo "  â€¢ /tm-architect"
    echo "  â€¢ /tm-dev"
    echo "  â€¢ /tm-retrospective"
else
    echo -e "${YELLOW}âš  Claude Code commands directory not found${NC}"
    echo "  Expected: $CLAUDE_COMMANDS_DIR"
    echo ""
    echo "Options:"
    echo "  1. Symlink commands to your project (recommended):"
    echo "     ln -s $PROJECT_ROOT/.claude/commands ~/.config/claude-code/commands"
    echo ""
    echo "  2. Copy commands manually when Claude Code is installed"
fi
echo ""

# Make validator executable and add to PATH
echo -e "${BLUE}Step 7: Setting up Task Master validator...${NC}"
chmod +x "$PROJECT_ROOT/src/validators/taskmaster-validator.js"
echo -e "${GREEN}âœ“ Validator made executable${NC}"
echo ""
echo "To use the validator globally, add to your PATH:"
echo "  export PATH=\"\$PATH:$PROJECT_ROOT/src/validators\""
echo ""
echo "Or add this to your ~/.bashrc or ~/.zshrc:"
echo "  echo 'export PATH=\"\$PATH:$PROJECT_ROOT/src/validators\"' >> ~/.bashrc"
echo ""

# Test validator
echo -e "${BLUE}Step 8: Testing validator...${NC}"
if "$PROJECT_ROOT/src/validators/taskmaster-validator.js" get-command-availability &> /dev/null; then
    echo -e "${GREEN}âœ“ Validator working correctly${NC}"
else
    echo -e "${YELLOW}âš  Validator test failed (may need Node.js modules)${NC}"
fi
echo ""

# Create .gitignore if it doesn't exist
echo -e "${BLUE}Step 9: Updating .gitignore...${NC}"
if [ ! -f ".gitignore" ]; then
    touch .gitignore
fi

# Add Task Master files to gitignore if not already present
if ! grep -q ".taskmaster/tasks/tasks.json" .gitignore; then
    echo "" >> .gitignore
    echo "# Task Master state (optional - depends on team workflow)" >> .gitignore
    echo "# .taskmaster/tasks/tasks.json" >> .gitignore
    echo "# .taskmaster/workflow-state.json" >> .gitignore
fi
echo -e "${GREEN}âœ“ .gitignore updated${NC}"
echo ""

# Installation complete
echo ""
echo -e "${GREEN}âœ… BMAD-TM Lite installation complete!${NC}"
echo "=================================================="
echo ""
echo -e "${BLUE}Quick Start:${NC}"
echo ""
echo "  1. Check your workflow status:"
echo "     /status"
echo ""
echo "  2. Start your first epic:"
echo "     /tm-pm"
echo ""
echo "  3. Follow the workflow phases:"
echo "     Ideation â†’ Planning â†’ Architecture â†’ Implementation â†’ Retrospective"
echo ""
echo -e "${BLUE}Documentation:${NC}"
echo "  â€¢ Workflow Guide: src/workflows/workflow-plan-and-build.md"
echo "  â€¢ Quick Start: QUICKSTART.md"
echo ""
echo -e "${BLUE}Slash Commands Available:${NC}"
echo "  /status           - Show workflow status"
echo "  /tm-pm            - Product Manager (create PRD, plan epics)"
echo "  /tm-architect     - Architect (design technical solution)"
echo "  /tm-dev           - Developer (implement tasks)"
echo "  /tm-retrospective - Retrospective (capture learnings)"
echo ""
echo -e "${YELLOW}Next Steps:${NC}"
echo "  â€¢ Read QUICKSTART.md for a guided walkthrough"
echo "  â€¢ Run /status to see your current workflow state"
echo "  â€¢ Start with /tm-pm when ready to create your first epic"
echo ""
echo "Happy building! ðŸš€"
echo ""
</file>

<file path="install-opencode.sh">
#!/bin/bash

# BMAD-TM Lite Installation Script for OpenCode
# This script sets up the workflow orchestration system for OpenCode

set -e

echo "ðŸš€ BMAD-TM Lite Installation for OpenCode"
echo "=========================================="
echo ""

# Colors for output
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Get project root
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
echo -e "${BLUE}Project root:${NC} $PROJECT_ROOT"
echo ""

# Check if Task Master CLI is installed
echo -e "${BLUE}Step 1: Checking Task Master CLI...${NC}"
if command -v task-master &> /dev/null; then
    TASKMASTER_VERSION=$(task-master --version 2>&1 || echo "unknown")
    echo -e "${GREEN}âœ“ Task Master CLI found${NC} ($TASKMASTER_VERSION)"
else
    echo -e "${RED}âœ— Task Master CLI not found${NC}"
    echo ""
    echo "Install Task Master CLI:"
    echo "  npm install -g task-master"
    echo ""
    read -p "Would you like to install it now? (y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        npm install -g task-master
        echo -e "${GREEN}âœ“ Task Master CLI installed${NC}"
    else
        echo -e "${YELLOW}âš  Skipping Task Master CLI installation${NC}"
        echo "You'll need to install it manually before using BMAD-TM Lite"
    fi
fi
echo ""

# Check if Node.js is installed (for validator)
echo -e "${BLUE}Step 2: Checking Node.js...${NC}"
if command -v node &> /dev/null; then
    NODE_VERSION=$(node --version)
    echo -e "${GREEN}âœ“ Node.js found${NC} ($NODE_VERSION)"
else
    echo -e "${RED}âœ— Node.js not found${NC}"
    echo "Node.js is required for the Task Master validator."
    echo "Install from: https://nodejs.org/"
    exit 1
fi
echo ""

# Initialize Task Master if not already done
echo -e "${BLUE}Step 3: Initializing Task Master...${NC}"
cd "$PROJECT_ROOT"
if [ -f ".taskmaster/tasks/tasks.json" ]; then
    echo -e "${GREEN}âœ“ Task Master already initialized${NC}"
else
    mkdir -p .taskmaster/tasks
    echo '{}' > .taskmaster/tasks/tasks.json
    echo -e "${GREEN}âœ“ Task Master initialized${NC}"
fi
echo ""

# Create workflow state file
echo -e "${BLUE}Step 4: Creating workflow state...${NC}"
if [ -f ".taskmaster/workflow-state.json" ]; then
    echo -e "${YELLOW}âš  Workflow state already exists${NC}"
    read -p "Overwrite? (y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo -e "${BLUE}â†’ Keeping existing workflow state${NC}"
    else
        cp .taskmaster/workflow-state.json .taskmaster/workflow-state.json.backup
        echo -e "${YELLOW}â†’ Backed up to .taskmaster/workflow-state.json.backup${NC}"
        # Create fresh state
        cat > .taskmaster/workflow-state.json << 'EOF'
{
  "version": "1.0.0",
  "current_phase": "ideation",
  "active_epic": null,
  "phases": {
    "ideation": {
      "status": "active",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Product definition and PRD creation"
    },
    "planning": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Parse PRD into Task Master epics and tasks"
    },
    "architecture": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-architect",
      "description": "Technical design and architecture planning"
    },
    "implementation": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-dev",
      "description": "Task execution and development"
    },
    "retrospective": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-retrospective",
      "description": "Post-epic analysis and learning capture"
    }
  },
  "history": [],
  "completed_epics": [],
  "last_updated": null
}
EOF
        echo -e "${GREEN}âœ“ Workflow state created${NC}"
    fi
else
    cat > .taskmaster/workflow-state.json << 'EOF'
{
  "version": "1.0.0",
  "current_phase": "ideation",
  "active_epic": null,
  "phases": {
    "ideation": {
      "status": "active",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Product definition and PRD creation"
    },
    "planning": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-pm",
      "description": "Parse PRD into Task Master epics and tasks"
    },
    "architecture": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-architect",
      "description": "Technical design and architecture planning"
    },
    "implementation": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-dev",
      "description": "Task execution and development"
    },
    "retrospective": {
      "status": "pending",
      "completed_at": null,
      "agent": "tm-retrospective",
      "description": "Post-epic analysis and learning capture"
    }
  },
  "history": [],
  "completed_epics": [],
  "last_updated": null
}
EOF
    echo -e "${GREEN}âœ“ Workflow state created${NC}"
fi
echo ""

# Create directory structure
echo -e "${BLUE}Step 5: Creating directory structure...${NC}"
mkdir -p docs/prd
mkdir -p docs/epics
mkdir -p docs/architecture
mkdir -p docs/retrospectives
echo -e "${GREEN}âœ“ Directory structure created${NC}"
echo ""

# Create OpenCode skills directory
echo -e "${BLUE}Step 6: Creating OpenCode skills...${NC}"
mkdir -p .opencode/skills

# Create skill files from slash commands
cat > .opencode/skills/status.md << 'EOF'
# BMAD-TM Workflow Status Skill

Invoke this skill to show the current BMAD-TM workflow status.

## How to Use
User says: "show status" or "what's my workflow status?" or "status"

## Skill Behavior
Load and display:
- Current workflow phase
- Active epic and task progress
- Available commands
- Warnings or blockers
- Next steps guidance

Reference the full command documentation at: .claude/commands/status.md
EOF

cat > .opencode/skills/tm-pm.md << 'EOF'
# Product Manager Skill

Invoke this skill when the user wants to:
- Create a Product Requirements Document (PRD)
- Plan a new epic
- Break down requirements into tasks

## How to Use
User says: "I need to create a PRD" or "start product planning" or "tm-pm"

## Skill Behavior
1. Validate workflow phase (must be ideation or planning)
2. Load Product Manager agent persona from: .claude/commands/tm-pm.md
3. Follow the agent's workflow for current phase

Reference the full agent documentation at: .claude/commands/tm-pm.md
EOF

cat > .opencode/skills/tm-architect.md << 'EOF'
# Architect Skill

Invoke this skill when the user wants to:
- Design technical architecture
- Create technical specifications
- Enhance tasks with implementation details

## How to Use
User says: "design the architecture" or "create technical design" or "tm-architect"

## Skill Behavior
1. Validate workflow phase (must be architecture)
2. Validate active epic exists
3. Load Architect agent persona from: .claude/commands/tm-architect.md
4. Follow the agent's workflow

Reference the full agent documentation at: .claude/commands/tm-architect.md
EOF

cat > .opencode/skills/tm-dev.md << 'EOF'
# Developer Skill

Invoke this skill when the user wants to:
- Implement tasks from Task Master
- Write code following architecture
- Execute the development phase

## How to Use
User says: "start development" or "implement tasks" or "tm-dev"

## Skill Behavior
1. Validate workflow phase (must be implementation)
2. Validate active epic and architecture complete
3. Load Developer agent persona from: .claude/commands/tm-dev.md
4. Follow dependency-aware implementation workflow

Reference the full agent documentation at: .claude/commands/tm-dev.md
EOF

cat > .opencode/skills/tm-retrospective.md << 'EOF'
# Retrospective Skill

Invoke this skill when the user wants to:
- Conduct post-epic retrospective
- Capture learnings and insights
- Analyze completed work

## How to Use
User says: "run retrospective" or "review the epic" or "tm-retrospective"

## Skill Behavior
1. Validate all tasks in epic are complete
2. Load Retrospective agent persona from: .claude/commands/tm-retrospective.md
3. Follow retrospective workflow
4. Create comprehensive retrospective document

Reference the full agent documentation at: .claude/commands/tm-retrospective.md
EOF

echo -e "${GREEN}âœ“ OpenCode skills created${NC}"
echo "  â€¢ status"
echo "  â€¢ tm-pm"
echo "  â€¢ tm-architect"
echo "  â€¢ tm-dev"
echo "  â€¢ tm-retrospective"
echo ""

# Make validator executable and add to PATH
echo -e "${BLUE}Step 7: Setting up Task Master validator...${NC}"
chmod +x "$PROJECT_ROOT/src/validators/taskmaster-validator.js"
echo -e "${GREEN}âœ“ Validator made executable${NC}"
echo ""
echo "To use the validator globally, add to your PATH:"
echo "  export PATH=\"\$PATH:$PROJECT_ROOT/src/validators\""
echo ""
echo "Or add this to your ~/.bashrc or ~/.zshrc:"
echo "  echo 'export PATH=\"\$PATH:$PROJECT_ROOT/src/validators\"' >> ~/.bashrc"
echo ""

# Test validator
echo -e "${BLUE}Step 8: Testing validator...${NC}"
if "$PROJECT_ROOT/src/validators/taskmaster-validator.js" get-command-availability &> /dev/null; then
    echo -e "${GREEN}âœ“ Validator working correctly${NC}"
else
    echo -e "${YELLOW}âš  Validator test failed (may need Node.js modules)${NC}"
fi
echo ""

# Create .gitignore if it doesn't exist
echo -e "${BLUE}Step 9: Updating .gitignore...${NC}"
if [ ! -f ".gitignore" ]; then
    touch .gitignore
fi

# Add Task Master files to gitignore if not already present
if ! grep -q ".taskmaster/tasks/tasks.json" .gitignore; then
    echo "" >> .gitignore
    echo "# Task Master state (optional - depends on team workflow)" >> .gitignore
    echo "# .taskmaster/tasks/tasks.json" >> .gitignore
    echo "# .taskmaster/workflow-state.json" >> .gitignore
fi
echo -e "${GREEN}âœ“ .gitignore updated${NC}"
echo ""

# Installation complete
echo ""
echo -e "${GREEN}âœ… BMAD-TM Lite installation for OpenCode complete!${NC}"
echo "========================================================="
echo ""
echo -e "${BLUE}Quick Start:${NC}"
echo ""
echo "  1. Tell OpenCode: 'show status'"
echo "     This will display your current workflow state"
echo ""
echo "  2. Start your first epic: 'start product planning'"
echo "     This will activate the Product Manager skill"
echo ""
echo "  3. Follow the workflow phases:"
echo "     Ideation â†’ Planning â†’ Architecture â†’ Implementation â†’ Retrospective"
echo ""
echo -e "${BLUE}Documentation:${NC}"
echo "  â€¢ Workflow Guide: src/workflows/workflow-plan-and-build.md"
echo "  â€¢ Quick Start: QUICKSTART.md"
echo ""
echo -e "${BLUE}Skills Available:${NC}"
echo "  status           - Show workflow status"
echo "  tm-pm            - Product Manager (create PRD, plan epics)"
echo "  tm-architect     - Architect (design technical solution)"
echo "  tm-dev           - Developer (implement tasks)"
echo "  tm-retrospective - Retrospective (capture learnings)"
echo ""
echo -e "${BLUE}How to Invoke Skills:${NC}"
echo "  Just describe what you want in natural language:"
echo "  â€¢ 'show me the current status'"
echo "  â€¢ 'I need to create a product requirements document'"
echo "  â€¢ 'let's design the architecture'"
echo "  â€¢ 'start implementing tasks'"
echo "  â€¢ 'run a retrospective'"
echo ""
echo -e "${YELLOW}Next Steps:${NC}"
echo "  â€¢ Read QUICKSTART.md for a guided walkthrough"
echo "  â€¢ Tell OpenCode 'show status' to see your workflow state"
echo "  â€¢ Start with 'create a PRD' when ready for your first epic"
echo ""
echo "Happy building! ðŸš€"
echo ""
</file>

<file path="bin/scud.js">
#!/usr/bin/env node

/**
 * SCUD CLI
 * Sprint Cycle Unified Development
 * Main entry point for scud commands
 */

const { execSync } = require('child_process');
const path = require('path');
const fs = require('fs');

const command = process.argv[2];
const args = process.argv.slice(3);

// Task management commands (use Rust CLI)
const taskCommands = ['tags', 'use-tag', 'list', 'show', 'set-status', 'next', 'stats'];

// AI-powered commands (use Rust CLI)
const aiCommands = ['parse-prd', 'analyze-complexity', 'expand', 'research'];

// All commands handled by Rust CLI
const rustCommands = [...taskCommands, ...aiCommands];

const commands = {
  init: 'Initialize SCUD in current project',
  status: 'Show current workflow status',
  install: 'Install slash commands for Claude Code',
  validate: 'Run workflow validation',
  help: 'Show this help message',
  // Task commands
  tags: 'List all epic tags',
  'use-tag': 'Switch to epic',
  list: 'List tasks in active epic',
  show: 'Show task details',
  'set-status': 'Update task status',
  next: 'Find next available task',
  stats: 'Show task statistics'
};

function showHelp() {
  console.log(`
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                    â”‚
â”‚   SCUD CLI                         â”‚
â”‚   Sprint Cycle Unified Development â”‚
â”‚                                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Usage: scud <command> [options]

Setup Commands:
  init          Initialize SCUD in current project
  install       Install slash commands for Claude Code
  status        Show current workflow status
  validate      Run workflow validation

Task Management (built-in, fast):
  tags                        List all epic tags
  use-tag <tag>              Switch to epic
  list [--status=<status>]   List tasks in active epic
  show <id>                  Show task details
  set-status <id> <status>   Update task status
  next                       Find next available task
  stats                      Show task statistics

AI-Powered (built-in, requires ANTHROPIC_API_KEY):
  parse-prd <file> --tag=<tag>    Parse PRD into tasks
  analyze-complexity [--task=<id>] Analyze task complexity
  expand [<id>] [--all]           Expand task into subtasks
  research "<query>"              AI research

Examples:
  scud init                       # Initialize in current directory
  scud tags                       # List all epics
  scud use-tag epic-1-auth        # Switch to epic
  scud next                       # Find next available task
  scud set-status 3 in-progress   # Start task 3

  scud parse-prd epic.md --tag epic-1   # Parse PRD (AI)
  scud analyze-complexity               # Analyze all tasks (AI)
  scud expand --all                     # Expand complex tasks (AI)
  scud research "OAuth best practices"  # Research topic (AI)

For more information, visit:
https://github.com/yourusername/scud
`);
}

function init() {
  const installScript = path.join(__dirname, '..', 'bin', 'install.js');
  try {
    execSync(`node "${installScript}" init`, { stdio: 'inherit' });
  } catch (error) {
    console.error('Installation failed:', error.message);
    process.exit(1);
  }
}

function install() {
  const installScript = path.join(__dirname, '..', 'bin', 'install.js');
  const installArgs = args.join(' ');
  try {
    execSync(`node "${installScript}" ${installArgs}`, { stdio: 'inherit' });
  } catch (error) {
    console.error('Installation failed:', error.message);
    process.exit(1);
  }
}

function status() {
  const validator = path.join(__dirname, '..', 'src', 'validators', 'taskmaster-validator.js');
  try {
    const result = execSync(`node "${validator}" get-command-availability`, { encoding: 'utf8' });
    const availability = JSON.parse(result);

    console.log('\nðŸ“Š SCUD Workflow Status\n');
    console.log('Available Commands:');

    for (const [cmd, info] of Object.entries(availability)) {
      const icon = info.available ? 'âœ…' : 'âŒ';
      console.log(`  ${icon} /${cmd}`);
      console.log(`     ${info.reason}`);
    }
    console.log('');
  } catch (error) {
    console.error('Status check failed:', error.message);
    process.exit(1);
  }
}

function validate() {
  const validator = path.join(__dirname, '..', 'src', 'validators', 'taskmaster-validator.js');
  try {
    execSync(`node "${validator}" validate-cli`, { stdio: 'inherit' });
    console.log('âœ… Validation passed');
  } catch (error) {
    console.error('âŒ Validation failed');
    process.exit(1);
  }
}

// Check if this is a command handled by Rust CLI
if (rustCommands.includes(command)) {
  // Find the Rust binary
  const rustBinary = path.join(__dirname, '..', 'scud-cli', 'target', 'release', 'scud');
  const debugBinary = path.join(__dirname, '..', 'scud-cli', 'target', 'debug', 'scud');

  // Use release binary if available, otherwise fall back to debug
  const scudBinary = fs.existsSync(rustBinary) ? rustBinary : debugBinary;

  if (!fs.existsSync(scudBinary)) {
    console.error('âŒ SCUD Rust CLI not found. Building...');
    try {
      const scudCliDir = path.join(__dirname, '..', 'scud-cli');
      execSync('cargo build --release', { cwd: scudCliDir, stdio: 'inherit' });
    } catch (error) {
      console.error('Failed to build Rust CLI. Please run: cd scud-cli && cargo build --release');
      process.exit(1);
    }
  }

  try {
    execSync(`"${scudBinary}" ${command} ${args.join(' ')}`, { stdio: 'inherit' });
    process.exit(0);
  } catch (error) {
    process.exit(1);
  }
}

switch (command) {
  case 'init':
    init();
    break;
  case 'install':
    install();
    break;
  case 'status':
    status();
    break;
  case 'validate':
    validate();
    break;
  case 'help':
  case undefined:
    showHelp();
    break;
  default:
    console.error(`Unknown command: ${command}`);
    console.log('Run "scud help" for usage information');
    process.exit(1);
}
</file>

<file path="scud-cli/src/commands/ai/analyze_complexity.rs">
use anyhow::Result;
use colored::Colorize;
use indicatif::{ProgressBar, ProgressStyle};
use serde::Deserialize;
use std::path::PathBuf;

use crate::llm::{LLMClient, Prompts};
use crate::storage::Storage;

#[derive(Debug, Deserialize)]
struct ComplexityAnalysis {
    complexity: u32,
    reasoning: String,
}

pub async fn run(project_root: Option<PathBuf>, task_id: Option<&str>) -> Result<()> {
    let storage = Storage::new(project_root);
    let active_epic = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    let mut all_tasks = storage.load_tasks()?;
    let epic = all_tasks
        .get_mut(&active_epic)
        .ok_or_else(|| anyhow::anyhow!("Epic '{}' not found", active_epic))?;

    let client = LLMClient::new()?;

    // Determine which tasks to analyze
    let task_ids: Vec<String> = if let Some(id) = task_id {
        vec![id.to_string()]
    } else {
        epic.tasks.iter().map(|t| t.id.clone()).collect()
    };

    if task_ids.is_empty() {
        println!("{}", "No tasks to analyze".yellow());
        return Ok(());
    }

    println!(
        "{} {} task(s)...",
        "Analyzing complexity for".blue(),
        task_ids.len()
    );

    for id in task_ids {
        let task = epic
            .get_task_mut(&id)
            .ok_or_else(|| anyhow::anyhow!("Task {} not found", id))?;

        let spinner = ProgressBar::new_spinner();
        spinner.set_style(
            ProgressStyle::default_spinner()
                .template("{spinner:.blue} {msg}")
                .unwrap(),
        );
        spinner.set_message(format!("Analyzing task {}: {}", id, task.title));
        spinner.enable_steady_tick(std::time::Duration::from_millis(100));

        let prompt =
            Prompts::analyze_complexity(&task.title, &task.description, task.details.as_deref());

        let analysis: ComplexityAnalysis = client.complete_json(&prompt).await?;

        task.complexity = analysis.complexity;
        task.complexity_analysis = Some(analysis.reasoning.clone());
        task.update();

        spinner.finish_with_message(format!(
            "{} Task {}: {} â†’ complexity {}",
            "âœ“".green(),
            id.cyan(),
            task.title,
            analysis.complexity.to_string().yellow()
        ));

        if analysis.complexity > 13 {
            println!(
                "  {} Task complexity >13. Consider running: scud expand {}",
                "âš ".yellow(),
                id
            );
        }
    }

    // Get stats and tasks needing expansion before saving (to avoid borrow checker issues)
    let stats = epic.get_stats();
    let tasks_needing_expansion: Vec<_> = epic
        .get_tasks_needing_expansion()
        .iter()
        .map(|t| (t.id.clone(), t.title.clone(), t.complexity))
        .collect();

    storage.save_tasks(&all_tasks)?;

    println!("\n{}", "âœ… Complexity analysis complete!".green().bold());

    // Show summary
    println!();
    println!(
        "{:<25} {}",
        "Total complexity:".yellow(),
        stats.total_complexity
    );

    if !tasks_needing_expansion.is_empty() {
        println!();
        println!(
            "{} {} task(s) with complexity >13:",
            "âš ".yellow(),
            tasks_needing_expansion.len()
        );
        for (id, title, complexity) in tasks_needing_expansion {
            println!("  {} {} [{}]", id.cyan(), title, complexity);
        }
        println!();
        println!("{}", "Run: scud expand --all".blue());
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/ai/expand.rs">
use anyhow::Result;
use colored::Colorize;
use indicatif::{ProgressBar, ProgressStyle};
use serde::Deserialize;
use std::path::PathBuf;

use crate::llm::{LLMClient, Prompts};
use crate::models::{Priority, Task};
use crate::storage::Storage;

#[derive(Debug, Deserialize)]
struct ExpandedTask {
    title: String,
    description: String,
    priority: String,
    complexity: u32,
    #[serde(default)]
    dependencies: Vec<String>,
}

pub async fn run(
    project_root: Option<PathBuf>,
    task_id: Option<&str>,
    expand_all: bool,
) -> Result<()> {
    let storage = Storage::new(project_root);
    let active_epic = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    let mut all_tasks = storage.load_tasks()?;
    let epic = all_tasks
        .get_mut(&active_epic)
        .ok_or_else(|| anyhow::anyhow!("Epic '{}' not found", active_epic))?;

    let client = LLMClient::new()?;

    // Determine which tasks to expand
    let task_ids: Vec<String> = if let Some(id) = task_id {
        vec![id.to_string()]
    } else if expand_all {
        epic.tasks
            .iter()
            .filter(|t| t.needs_expansion())
            .map(|t| t.id.clone())
            .collect()
    } else {
        anyhow::bail!("Specify a task ID or use --all to expand all tasks with complexity >13");
    };

    if task_ids.is_empty() {
        println!("{}", "No tasks need expansion (all complexity â‰¤13)".green());
        return Ok(());
    }

    println!("{} {} task(s)...", "Expanding".blue(), task_ids.len());

    for id in task_ids {
        let task = epic
            .get_task(&id)
            .ok_or_else(|| anyhow::anyhow!("Task {} not found", id))?;

        if !task.needs_expansion() {
            println!(
                "{} Task {} doesn't need expansion (complexity: {})",
                "âŠ˜".yellow(),
                id.cyan(),
                task.complexity
            );
            continue;
        }

        let spinner = ProgressBar::new_spinner();
        spinner.set_style(
            ProgressStyle::default_spinner()
                .template("{spinner:.blue} {msg}")
                .unwrap(),
        );
        spinner.set_message(format!("Expanding task {}: {}", id, task.title));
        spinner.enable_steady_tick(std::time::Duration::from_millis(100));

        let prompt = Prompts::expand_task(
            &task.title,
            &task.description,
            task.complexity,
            task.details.as_deref(),
        );

        let expanded_tasks: Vec<ExpandedTask> = client.complete_json(&prompt).await?;

        spinner.finish_with_message(format!(
            "{} Task {} expanded into {} subtasks",
            "âœ“".green(),
            id.cyan(),
            expanded_tasks.len()
        ));

        // Get the highest current task ID to start numbering from
        let max_id: u32 = epic
            .tasks
            .iter()
            .filter_map(|t| t.id.parse::<u32>().ok())
            .max()
            .unwrap_or(0);

        // Create new subtasks
        let mut new_subtask_ids = Vec::new();
        for (idx, expanded) in expanded_tasks.iter().enumerate() {
            let new_id = (max_id + idx as u32 + 1).to_string();

            let priority = match expanded.priority.to_lowercase().as_str() {
                "high" => Priority::High,
                "low" => Priority::Low,
                _ => Priority::Medium,
            };

            let mut new_task = Task::new(
                new_id.clone(),
                expanded.title.clone(),
                expanded.description.clone(),
            );
            new_task.complexity = expanded.complexity;
            new_task.priority = priority;

            // Map dependency references
            // If dependencies refer to indices in the expanded array, map them to actual IDs
            new_task.dependencies = expanded
                .dependencies
                .iter()
                .filter_map(|dep| {
                    if let Ok(dep_idx) = dep.parse::<usize>() {
                        new_subtask_ids.get(dep_idx).cloned()
                    } else {
                        Some(dep.clone())
                    }
                })
                .collect();

            new_subtask_ids.push(new_id.clone());
            epic.add_task(new_task);

            println!(
                "  {} Created subtask {}: {} [complexity: {}]",
                "+".green(),
                new_id.cyan(),
                expanded.title,
                expanded.complexity.to_string().yellow()
            );
        }

        // Update original task to mark it as expanded (parent)
        let original_task = epic.get_task_mut(&id).unwrap();
        original_task.title = format!("[PARENT] {}", original_task.title);
        original_task.description = format!(
            "{}\n\n[This task has been expanded into subtasks: {}]",
            original_task.description,
            new_subtask_ids.join(", ")
        );
        original_task.update();
    }

    storage.save_tasks(&all_tasks)?;

    println!("\n{}", "âœ… Task expansion complete!".green().bold());
    println!();
    println!("{}", "Next steps:".blue());
    println!("  1. Review tasks: scud list");
    println!("  2. Continue with /tm-architect");
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/ai/mod.rs">
pub mod analyze_complexity;
pub mod expand;
pub mod parse_prd;
pub mod research;
</file>

<file path="scud-cli/src/commands/ai/parse_prd.rs">
use anyhow::Result;
use colored::Colorize;
use indicatif::{ProgressBar, ProgressStyle};
use serde::Deserialize;
use std::path::{Path, PathBuf};

use crate::llm::{LLMClient, Prompts};
use crate::models::{Epic, Priority, Task};
use crate::storage::Storage;

#[derive(Debug, Deserialize)]
struct ParsedTask {
    title: String,
    description: String,
    priority: String,
    complexity: u32,
    #[serde(default)]
    dependencies: Vec<String>,
}

pub async fn run(project_root: Option<PathBuf>, file_path: &Path, tag: &str) -> Result<()> {
    let storage = Storage::new(project_root);

    if !storage.is_initialized() {
        anyhow::bail!("SCUD not initialized. Run: scud init");
    }

    // Read the epic file
    println!("{} {}", "Reading epic from:".blue(), file_path.display());
    let epic_content = storage.read_file(file_path)?;

    // Create LLM client
    let client = LLMClient::new()?;

    // Show progress
    let spinner = ProgressBar::new_spinner();
    spinner.set_style(
        ProgressStyle::default_spinner()
            .template("{spinner:.blue} {msg}")
            .unwrap(),
    );
    spinner.set_message("Parsing epic with AI...");
    spinner.enable_steady_tick(std::time::Duration::from_millis(100));

    // Call LLM to parse the epic
    let prompt = Prompts::parse_prd(&epic_content);
    let parsed_tasks: Vec<ParsedTask> = client.complete_json(&prompt).await?;

    spinner.finish_with_message(format!(
        "{} Parsed {} tasks",
        "âœ“".green(),
        parsed_tasks.len()
    ));

    // Convert to our task model
    let mut epic = Epic::new(tag.to_string());

    for (idx, parsed) in parsed_tasks.iter().enumerate() {
        let task_id = (idx + 1).to_string();

        let priority = match parsed.priority.to_lowercase().as_str() {
            "high" => Priority::High,
            "low" => Priority::Low,
            _ => Priority::Medium,
        };

        let mut task = Task::new(
            task_id.clone(),
            parsed.title.clone(),
            parsed.description.clone(),
        );
        task.complexity = parsed.complexity;
        task.priority = priority;
        task.dependencies = parsed.dependencies.clone();

        epic.add_task(task);
    }

    // Load existing tasks and add new epic
    let mut all_tasks = storage.load_tasks().unwrap_or_default();

    if all_tasks.contains_key(tag) {
        println!(
            "{}",
            format!("âš  Epic '{}' already exists. Overwriting...", tag).yellow()
        );
    }

    all_tasks.insert(tag.to_string(), epic);
    storage.save_tasks(&all_tasks)?;

    // Set as active epic
    storage.set_active_epic(tag)?;

    println!(
        "\n{}",
        "âœ… Epic parsed and created successfully!".green().bold()
    );
    println!();
    println!("{:<20} {}", "Tag:".yellow(), tag.cyan());
    println!("{:<20} {}", "Tasks created:".yellow(), parsed_tasks.len());
    println!();
    println!("{}", "Next steps:".blue());
    println!("  1. Review tasks: scud list");
    println!("  2. Analyze complexity: scud analyze-complexity");
    println!("  3. Use /tm-architect to add technical details");
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/group_status.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, group_id: &str) -> Result<()> {
    let storage = Storage::new(project_root);
    let groups = storage.load_groups()?;

    let group = groups
        .get_group(group_id)
        .ok_or_else(|| anyhow::anyhow!("Group '{}' not found", group_id))?;

    let tasks = storage.load_tasks()?;

    println!("\n{} {}", "Group:".blue().bold(), group.name.green());
    println!("{}", "=".repeat(50).blue());
    println!("{:<20} {}", "ID:".yellow(), group.id);
    println!("{:<20} {:?}", "Status:".yellow(), group.status);
    if let Some(ref desc) = group.description {
        println!("{:<20} {}", "Description:".yellow(), desc);
    }
    println!();

    // Aggregate stats across all epics in group
    let mut total_tasks = 0;
    let mut pending = 0;
    let mut in_progress = 0;
    let mut done = 0;
    let mut blocked = 0;
    let mut total_complexity = 0;

    println!("{}", "Epics in Group:".blue().bold());
    for epic_tag in &group.epic_tags {
        if let Some(epic) = tasks.get(epic_tag) {
            let stats = epic.get_stats();
            println!("  {} {} tasks", epic_tag.cyan(), stats.total);

            total_tasks += stats.total;
            pending += stats.pending;
            in_progress += stats.in_progress;
            done += stats.done;
            blocked += stats.blocked;
            total_complexity += stats.total_complexity;
        }
    }

    println!();
    println!("{}", "Aggregate Statistics:".blue().bold());
    println!("{:<20} {}", "Total Tasks:".yellow(), total_tasks);
    println!("{:<20} {}", "Pending:".yellow(), pending);
    println!("{:<20} {}", "In Progress:".yellow(), in_progress);
    println!("{:<20} {}", "Done:".yellow(), done.to_string().green());
    println!("{:<20} {}", "Blocked:".yellow(), blocked.to_string().red());
    println!();
    println!("{:<20} {}", "Total Complexity:".yellow(), total_complexity);

    let completion_pct = if total_tasks > 0 {
        (done as f32 / total_tasks as f32 * 100.0) as u32
    } else {
        0
    };
    println!(
        "{:<20} {}%",
        "Completion:".yellow(),
        completion_pct.to_string().green()
    );

    // Progress bar
    let bar_length = 50;
    let filled = (completion_pct as f32 / 100.0 * bar_length as f32) as usize;
    let empty = bar_length - filled;
    let bar = format!("[{}{}]", "=".repeat(filled).green(), " ".repeat(empty));
    println!("\n{}", bar);
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/list_groups.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);
    let groups = storage.load_groups()?;

    if groups.groups.is_empty() {
        println!("{}", "No epic groups found".yellow());
        println!("Create a group with: scud create-group <name> --epics <tag1>,<tag2>");
        return Ok(());
    }

    println!("{}", "Epic Groups:".blue().bold());
    println!();

    for group in &groups.groups {
        let status_icon = match group.status {
            crate::models::GroupStatus::Active => "â—".green(),
            crate::models::GroupStatus::Completed => "âœ“".blue(),
            crate::models::GroupStatus::Archived => "â–¡".white(),
        };

        println!(
            "{} {} {}",
            status_icon,
            group.name.bold(),
            format!("({})", group.id).white()
        );
        println!("  Epics: {}", group.epic_tags.join(", ").cyan());
        if let Some(ref desc) = group.description {
            println!("  {}", desc.white());
        }
        println!();
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/release.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, task_id: &str, force: bool) -> Result<()> {
    let storage = Storage::new(project_root);
    let active_epic = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    let mut all_tasks = storage.load_tasks()?;
    let epic = all_tasks
        .get_mut(&active_epic)
        .ok_or_else(|| anyhow::anyhow!("Epic '{}' not found", active_epic))?;

    let task = epic
        .get_task_mut(task_id)
        .ok_or_else(|| anyhow::anyhow!("Task {} not found in epic '{}'", task_id, active_epic))?;

    if !task.is_locked() {
        println!("{}", "âŠ˜ Task is not locked".yellow());
        return Ok(());
    }

    if !force {
        if let Some(ref locked_by) = task.locked_by {
            println!("{}", "âš  Task is locked".yellow());
            println!("{:<20} {}", "Locked by:".yellow(), locked_by.green());
            if let Some(age) = task.lock_age_hours() {
                println!("{:<20} {:.1}h ago", "Locked:".yellow(), age);
            }
            println!();
            println!("To force release: scud release {} --force", task_id);
            return Ok(());
        }
    }

    let was_locked_by = task.locked_by.clone();
    task.release();
    storage.save_tasks(&all_tasks)?;

    println!("{} Task {} released", "âœ“".green(), task_id.cyan());
    if let Some(locked_by) = was_locked_by {
        println!("  Previously locked by: {}", locked_by);
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/tags.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);
    let tasks = storage.load_tasks()?;
    let active_epic = storage.get_active_epic()?;

    if tasks.is_empty() {
        println!("{}", "No epic tags found".yellow());
        println!("Create an epic with: scud parse-prd <file> --tag <tag>");
        return Ok(());
    }

    println!("{}", "Epic Tags:".blue().bold());
    for (tag, epic) in tasks.iter() {
        let task_count = epic.tasks.len();
        if Some(tag) == active_epic.as_ref() {
            println!(
                "  {} {} ({} tasks)",
                "â—".green(),
                tag.green().bold(),
                task_count
            );
        } else {
            println!("  {} {} ({} tasks)", "â—‹".white(), tag, task_count);
        }
    }

    if let Some(active) = active_epic {
        println!("\n{} {}", "Active epic:".blue(), active.green());
    } else {
        println!("\n{}", "No active epic. Run: scud use-tag <tag>".yellow());
    }

    Ok(())
}
</file>

<file path="scud-cli/src/llm/client.rs">
use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::env;

#[derive(Debug, Serialize)]
struct AnthropicRequest {
    model: String,
    max_tokens: u32,
    messages: Vec<Message>,
}

#[derive(Debug, Serialize, Deserialize)]
struct Message {
    role: String,
    content: String,
}

#[derive(Debug, Deserialize)]
struct AnthropicResponse {
    content: Vec<Content>,
}

#[derive(Debug, Deserialize)]
struct Content {
    text: String,
}

pub struct LLMClient {
    api_key: String,
    model: String,
    client: reqwest::Client,
}

impl LLMClient {
    pub fn new() -> Result<Self> {
        let api_key = env::var("ANTHROPIC_API_KEY")
            .context("ANTHROPIC_API_KEY environment variable not set")?;

        let model =
            env::var("SCUD_MODEL").unwrap_or_else(|_| "claude-sonnet-4-20250514".to_string());

        Ok(LLMClient {
            api_key,
            model,
            client: reqwest::Client::new(),
        })
    }

    pub async fn complete(&self, prompt: &str) -> Result<String> {
        let request = AnthropicRequest {
            model: self.model.clone(),
            max_tokens: 4096,
            messages: vec![Message {
                role: "user".to_string(),
                content: prompt.to_string(),
            }],
        };

        let response = self
            .client
            .post("https://api.anthropic.com/v1/messages")
            .header("x-api-key", &self.api_key)
            .header("anthropic-version", "2023-06-01")
            .header("content-type", "application/json")
            .json(&request)
            .send()
            .await
            .context("Failed to send request to Anthropic API")?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            anyhow::bail!("Anthropic API error ({}): {}", status, error_text);
        }

        let api_response: AnthropicResponse = response
            .json()
            .await
            .context("Failed to parse Anthropic API response")?;

        Ok(api_response
            .content
            .first()
            .map(|c| c.text.clone())
            .unwrap_or_default())
    }

    pub async fn complete_json<T>(&self, prompt: &str) -> Result<T>
    where
        T: serde::de::DeserializeOwned,
    {
        let response_text = self.complete(prompt).await?;

        // Try to find JSON in the response (LLM might include markdown or explanations)
        let json_str = if let Some(start) = response_text.find('[') {
            if let Some(end) = response_text.rfind(']') {
                &response_text[start..=end]
            } else {
                &response_text
            }
        } else if let Some(start) = response_text.find('{') {
            if let Some(end) = response_text.rfind('}') {
                &response_text[start..=end]
            } else {
                &response_text
            }
        } else {
            &response_text
        };

        serde_json::from_str(json_str).context("Failed to parse JSON from LLM response")
    }
}
</file>

<file path="scud-cli/src/llm/prompts.rs">
pub struct Prompts;

impl Prompts {
    pub fn parse_prd(epic_content: &str) -> String {
        format!(
            r#"You are a Scrum Master parsing an epic into actionable development tasks.

Epic Content:
{}

Parse this epic into discrete, actionable tasks. Return a JSON array of tasks with the following structure:

[
  {{
    "title": "Task name (concise, action-oriented)",
    "description": "What needs to be done (2-3 sentences)",
    "priority": "high|medium|low",
    "complexity": <1|2|3|5|8|13|21>,
    "dependencies": []
  }}
]

Guidelines:
- Each task should be atomic and independently testable
- Use Fibonacci complexity scale:
  * 1 = Trivial (~30 min, e.g., update config value)
  * 2 = Simple (30m-1h, e.g., add basic validation)
  * 3 = Moderate (1-2h, e.g., create new API endpoint)
  * 5 = Complex (2-4h, e.g., integrate third-party service)
  * 8 = Very Complex (4-8h, e.g., build feature with multiple components)
  * 13 = Extremely Complex (1 day, SHOULD BE SPLIT)
  * 21 = Too Large (MUST BE SPLIT - only use if absolutely necessary)
- Identify dependencies where tasks must be done in specific order (use task indices, e.g., ["1", "2"])
- Order tasks logically (foundational work first)
- Each task should have clear success criteria

Return ONLY the JSON array, no additional explanation."#,
            epic_content
        )
    }

    pub fn analyze_complexity(
        task_title: &str,
        task_description: &str,
        existing_details: Option<&str>,
    ) -> String {
        let context = existing_details
            .map(|d| format!("\nExisting Technical Details:\n{}\n", d))
            .unwrap_or_default();

        format!(
            r#"You are analyzing the complexity of a development task.

Task: {}
Description: {}{}

Analyze this task and provide:
1. A complexity score (1, 2, 3, 5, 8, 13, or 21) using Fibonacci scale
2. A brief reasoning explaining the score

Consider:
- Technical difficulty and unknowns
- Number of components/files affected
- Testing requirements
- Integration points and dependencies
- Research needed
- Edge cases to handle

Complexity Scale:
- 1 = Trivial (~30 min)
- 2 = Simple (30m-1h)
- 3 = Moderate (1-2h)
- 5 = Complex (2-4h)
- 8 = Very Complex (4-8h)
- 13 = Extremely Complex (1 day) - Should be split
- 21 = Too Large - Must be split

Return a JSON object:
{{
  "complexity": <number>,
  "reasoning": "explanation of the score"
}}

Return ONLY the JSON object, no additional explanation."#,
            task_title, task_description, context
        )
    }

    pub fn expand_task(
        task_title: &str,
        task_description: &str,
        complexity: u32,
        existing_details: Option<&str>,
    ) -> String {
        let context = existing_details
            .map(|d| format!("\nExisting Technical Details:\n{}\n", d))
            .unwrap_or_default();

        format!(
            r#"You are breaking down a complex task into smaller, manageable subtasks.

Original Task (Complexity {}): {}
Description: {}{}

This task is too complex (>13 points) and needs to be broken down into smaller subtasks.

Create subtasks that:
- Each have complexity â‰¤ 8 (ideally â‰¤ 5)
- Are independently testable
- Have clear dependencies between them
- Cover all aspects of the original task
- Maintain logical order

Return a JSON array of subtasks:
[
  {{
    "title": "Subtask name",
    "description": "What needs to be done",
    "priority": "high|medium|low",
    "complexity": <1-8>,
    "dependencies": []  // IDs of other subtasks this depends on
  }}
]

Guidelines:
- Start with foundational work (models, schemas)
- Then build core logic
- Then add UI/API layers
- Finally add tests and documentation
- Each subtask should take at most 8 hours
- Use dependencies to enforce correct order

Return ONLY the JSON array, no additional explanation."#,
            complexity, task_title, task_description, context
        )
    }

    pub fn research_topic(query: &str) -> String {
        format!(
            r#"You are a technical research assistant helping a developer.

Research Query: {}

Provide a comprehensive but concise response covering:
1. Key concepts and best practices
2. Common pitfalls to avoid
3. Recommended approaches
4. Code examples if relevant
5. Links to documentation or resources (if you're aware of them)

Focus on practical, actionable information that helps with implementation.
Be concise but thorough - aim for 200-400 words.

Format your response in markdown."#,
            query
        )
    }
}
</file>

<file path="scud-cli/src/models/epic.rs">
use super::task::Task;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Epic {
    pub name: String,
    pub tasks: Vec<Task>,
}

impl Epic {
    pub fn new(name: String) -> Self {
        Epic {
            name,
            tasks: Vec::new(),
        }
    }

    pub fn add_task(&mut self, task: Task) {
        self.tasks.push(task);
    }

    pub fn get_task(&self, task_id: &str) -> Option<&Task> {
        self.tasks.iter().find(|t| t.id == task_id)
    }

    pub fn get_task_mut(&mut self, task_id: &str) -> Option<&mut Task> {
        self.tasks.iter_mut().find(|t| t.id == task_id)
    }

    pub fn remove_task(&mut self, task_id: &str) -> Option<Task> {
        self.tasks
            .iter()
            .position(|t| t.id == task_id)
            .map(|idx| self.tasks.remove(idx))
    }

    pub fn get_stats(&self) -> EpicStats {
        let total = self.tasks.len();
        let mut pending = 0;
        let mut in_progress = 0;
        let mut done = 0;
        let mut blocked = 0;
        let mut total_complexity = 0;

        for task in &self.tasks {
            total_complexity += task.complexity;
            match task.status {
                super::task::TaskStatus::Pending => pending += 1,
                super::task::TaskStatus::InProgress => in_progress += 1,
                super::task::TaskStatus::Done => done += 1,
                super::task::TaskStatus::Blocked => blocked += 1,
                _ => {}
            }
        }

        EpicStats {
            total,
            pending,
            in_progress,
            done,
            blocked,
            total_complexity,
        }
    }

    pub fn find_next_task(&self) -> Option<&Task> {
        self.tasks.iter().find(|task| {
            task.status == super::task::TaskStatus::Pending
                && task.has_dependencies_met(&self.tasks)
        })
    }

    pub fn get_tasks_needing_expansion(&self) -> Vec<&Task> {
        self.tasks.iter().filter(|t| t.needs_expansion()).collect()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpicStats {
    pub total: usize,
    pub pending: usize,
    pub in_progress: usize,
    pub done: usize,
    pub blocked: usize,
    pub total_complexity: u32,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::models::task::{Task, TaskStatus};

    #[test]
    fn test_epic_creation() {
        let epic = Epic::new("epic-1-auth".to_string());

        assert_eq!(epic.name, "epic-1-auth");
        assert!(epic.tasks.is_empty());
    }

    #[test]
    fn test_add_task() {
        let mut epic = Epic::new("epic-1".to_string());
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );

        epic.add_task(task.clone());

        assert_eq!(epic.tasks.len(), 1);
        assert_eq!(epic.tasks[0].id, "TASK-1");
    }

    #[test]
    fn test_get_task() {
        let mut epic = Epic::new("epic-1".to_string());
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );
        epic.add_task(task);

        let retrieved = epic.get_task("TASK-1");
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().id, "TASK-1");

        let missing = epic.get_task("TASK-99");
        assert!(missing.is_none());
    }

    #[test]
    fn test_get_task_mut() {
        let mut epic = Epic::new("epic-1".to_string());
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );
        epic.add_task(task);

        {
            let task_mut = epic.get_task_mut("TASK-1").unwrap();
            task_mut.set_status(TaskStatus::InProgress);
        }

        assert_eq!(
            epic.get_task("TASK-1").unwrap().status,
            TaskStatus::InProgress
        );
    }

    #[test]
    fn test_remove_task() {
        let mut epic = Epic::new("epic-1".to_string());
        let task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        let task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        epic.add_task(task1);
        epic.add_task(task2);

        let removed = epic.remove_task("TASK-1");
        assert!(removed.is_some());
        assert_eq!(removed.unwrap().id, "TASK-1");
        assert_eq!(epic.tasks.len(), 1);
        assert_eq!(epic.tasks[0].id, "TASK-2");

        let missing = epic.remove_task("TASK-99");
        assert!(missing.is_none());
    }

    #[test]
    fn test_get_stats_empty_epic() {
        let epic = Epic::new("epic-1".to_string());
        let stats = epic.get_stats();

        assert_eq!(stats.total, 0);
        assert_eq!(stats.pending, 0);
        assert_eq!(stats.in_progress, 0);
        assert_eq!(stats.done, 0);
        assert_eq!(stats.blocked, 0);
        assert_eq!(stats.total_complexity, 0);
    }

    #[test]
    fn test_get_stats_with_tasks() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.complexity = 3;
        task1.set_status(TaskStatus::Done);

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        task2.complexity = 5;
        task2.set_status(TaskStatus::InProgress);

        let mut task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );
        task3.complexity = 8;
        // Pending by default

        let mut task4 = Task::new(
            "TASK-4".to_string(),
            "Task 4".to_string(),
            "Desc".to_string(),
        );
        task4.complexity = 2;
        task4.set_status(TaskStatus::Blocked);

        epic.add_task(task1);
        epic.add_task(task2);
        epic.add_task(task3);
        epic.add_task(task4);

        let stats = epic.get_stats();

        assert_eq!(stats.total, 4);
        assert_eq!(stats.pending, 1);
        assert_eq!(stats.in_progress, 1);
        assert_eq!(stats.done, 1);
        assert_eq!(stats.blocked, 1);
        assert_eq!(stats.total_complexity, 18); // 3 + 5 + 8 + 2
    }

    #[test]
    fn test_find_next_task_no_dependencies() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        // Pending, no dependencies

        let task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );
        // Pending, no dependencies

        epic.add_task(task1);
        epic.add_task(task2);
        epic.add_task(task3);

        let next = epic.find_next_task();
        assert!(next.is_some());
        assert_eq!(next.unwrap().id, "TASK-2"); // First pending task
    }

    #[test]
    fn test_find_next_task_with_dependencies() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        // Pending, no dependencies

        let mut task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );
        task3.dependencies = vec!["TASK-1".to_string(), "TASK-2".to_string()];
        // Pending, but depends on TASK-2 which is not done

        epic.add_task(task1);
        epic.add_task(task2);
        epic.add_task(task3);

        let next = epic.find_next_task();
        assert!(next.is_some());
        assert_eq!(next.unwrap().id, "TASK-2"); // TASK-3 blocked by dependencies
    }

    #[test]
    fn test_find_next_task_dependencies_met() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        task2.set_status(TaskStatus::Done);

        let mut task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );
        task3.dependencies = vec!["TASK-1".to_string(), "TASK-2".to_string()];
        // Pending, dependencies met

        epic.add_task(task1);
        epic.add_task(task2);
        epic.add_task(task3);

        let next = epic.find_next_task();
        assert!(next.is_some());
        assert_eq!(next.unwrap().id, "TASK-3"); // Dependencies met
    }

    #[test]
    fn test_find_next_task_none_available() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        task2.set_status(TaskStatus::InProgress);

        epic.add_task(task1);
        epic.add_task(task2);

        let next = epic.find_next_task();
        assert!(next.is_none()); // No pending tasks
    }

    #[test]
    fn test_get_tasks_needing_expansion() {
        let mut epic = Epic::new("epic-1".to_string());

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Small Task".to_string(),
            "Desc".to_string(),
        );
        task1.complexity = 5;

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Medium Task".to_string(),
            "Desc".to_string(),
        );
        task2.complexity = 13;

        let mut task3 = Task::new(
            "TASK-3".to_string(),
            "Large Task".to_string(),
            "Desc".to_string(),
        );
        task3.complexity = 21;

        let mut task4 = Task::new(
            "TASK-4".to_string(),
            "Huge Task".to_string(),
            "Desc".to_string(),
        );
        task4.complexity = 34;

        epic.add_task(task1);
        epic.add_task(task2);
        epic.add_task(task3);
        epic.add_task(task4);

        let needing_expansion = epic.get_tasks_needing_expansion();

        assert_eq!(needing_expansion.len(), 2); // TASK-3 and TASK-4 (complexity > 13)
        assert!(needing_expansion.iter().any(|t| t.id == "TASK-3"));
        assert!(needing_expansion.iter().any(|t| t.id == "TASK-4"));
    }

    #[test]
    fn test_epic_serialization() {
        let mut epic = Epic::new("epic-1".to_string());
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );
        epic.add_task(task);

        let json = serde_json::to_string(&epic).unwrap();
        let deserialized: Epic = serde_json::from_str(&json).unwrap();

        assert_eq!(epic.name, deserialized.name);
        assert_eq!(epic.tasks.len(), deserialized.tasks.len());
        assert_eq!(epic.tasks[0].id, deserialized.tasks[0].id);
    }
}
</file>

<file path="scud-cli/src/models/group.rs">
use serde::{Deserialize, Serialize};

/// Epic Group - for coordinating related epics (e.g., backend/frontend)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EpicGroup {
    pub id: String,
    pub name: String,
    pub epic_tags: Vec<String>,
    pub description: Option<String>,
    pub created_at: String,
    pub status: GroupStatus,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum GroupStatus {
    Active,
    Completed,
    Archived,
}

impl EpicGroup {
    pub fn new(id: String, name: String, epic_tags: Vec<String>) -> Self {
        EpicGroup {
            id,
            name,
            epic_tags,
            description: None,
            created_at: chrono::Utc::now().to_rfc3339(),
            status: GroupStatus::Active,
        }
    }

    pub fn contains_epic(&self, tag: &str) -> bool {
        self.epic_tags.iter().any(|t| t == tag)
    }

    pub fn add_epic(&mut self, tag: String) {
        if !self.contains_epic(&tag) {
            self.epic_tags.push(tag);
        }
    }

    pub fn remove_epic(&mut self, tag: &str) -> bool {
        if let Some(pos) = self.epic_tags.iter().position(|t| t == tag) {
            self.epic_tags.remove(pos);
            true
        } else {
            false
        }
    }
}

/// Groups collection stored in .taskmaster/epic-groups.json
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct EpicGroups {
    pub groups: Vec<EpicGroup>,
}

impl EpicGroups {
    pub fn new() -> Self {
        EpicGroups { groups: Vec::new() }
    }

    pub fn add_group(&mut self, group: EpicGroup) {
        self.groups.push(group);
    }

    pub fn get_group(&self, id: &str) -> Option<&EpicGroup> {
        self.groups.iter().find(|g| g.id == id)
    }

    pub fn get_group_mut(&mut self, id: &str) -> Option<&mut EpicGroup> {
        self.groups.iter_mut().find(|g| g.id == id)
    }

    pub fn find_group_for_epic(&self, epic_tag: &str) -> Option<&EpicGroup> {
        self.groups.iter().find(|g| g.contains_epic(epic_tag))
    }

    pub fn remove_group(&mut self, id: &str) -> Option<EpicGroup> {
        self.groups
            .iter()
            .position(|g| g.id == id)
            .map(|idx| self.groups.remove(idx))
    }
}
</file>

<file path="scud-cli/Cargo.toml">
[package]
name = "scud"
version = "0.1.0"
edition = "2021"
authors = ["SCUD Team"]
description = "Fast, simple task master for AI-driven development"
license = "MIT"

[lib]
name = "scud"
path = "src/lib.rs"

[[bin]]
name = "scud"
path = "src/main.rs"

[dependencies]
clap = { version = "4.5", features = ["derive", "cargo"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1.0", features = ["full"] }
reqwest = { version = "0.11", features = ["json", "rustls-tls"], default-features = false }
anyhow = "1.0"
thiserror = "1.0"
chrono = { version = "0.4", features = ["serde"] }
colored = "2.1"
indicatif = "0.17"
dirs = "5.0"
fs2 = "0.4"  # File locking for concurrent access

[dev-dependencies]
tempfile = "3.8"  # Temporary directories for tests
mockall = "0.12"  # Mock objects for testing
tokio-test = "0.4"  # Testing utilities for tokio
criterion = "0.5"  # Benchmarking framework
</file>

<file path="src/validators/taskmaster-validator.js">
#!/usr/bin/env node

/**
 * BMAD-TM Validator
 *
 * Validates Task Master state and enforces workflow rules.
 * Used by slash commands to ensure correct workflow usage.
 */

const fs = require('fs');
const path = require('path');

class TaskMasterValidator {
  constructor(projectRoot = process.cwd()) {
    this.projectRoot = projectRoot;
    this.workflowStatePath = path.join(projectRoot, '.taskmaster', 'workflow-state.json');
    this.tasksPath = path.join(projectRoot, '.taskmaster', 'tasks', 'tasks.json');
  }

  /**
   * Load workflow state from disk
   */
  loadWorkflowState() {
    if (!fs.existsSync(this.workflowStatePath)) {
      throw new Error(`Workflow state not found: ${this.workflowStatePath}\nRun installation script first.`);
    }
    return JSON.parse(fs.readFileSync(this.workflowStatePath, 'utf8'));
  }

  /**
   * Load Task Master tasks from disk
   */
  loadTasks() {
    if (!fs.existsSync(this.tasksPath)) {
      throw new Error(`Task Master tasks not found: ${this.tasksPath}\nRun: task-master init`);
    }
    return JSON.parse(fs.readFileSync(this.tasksPath, 'utf8'));
  }

  /**
   * Save workflow state to disk
   */
  saveWorkflowState(state) {
    fs.writeFileSync(this.workflowStatePath, JSON.stringify(state, null, 2));
  }

  /**
   * Validate that Task Master CLI is available
   */
  validateTaskMasterCLI() {
    const { execSync } = require('child_process');
    try {
      execSync('task-master --version', { stdio: 'ignore' });
      return { valid: true };
    } catch (error) {
      return {
        valid: false,
        error: 'Task Master CLI not found. Install: npm install -g task-master'
      };
    }
  }

  /**
   * Validate workflow phase for agent activation
   */
  validatePhase(agentName, allowedPhases) {
    const state = this.loadWorkflowState();
    const currentPhase = state.current_phase;

    if (!allowedPhases.includes(currentPhase)) {
      return {
        valid: false,
        currentPhase,
        allowedPhases,
        error: `Agent '${agentName}' can only run in phases: ${allowedPhases.join(', ')}. Current phase: ${currentPhase}`
      };
    }

    return { valid: true, currentPhase };
  }

  /**
   * Validate that active epic exists in Task Master
   */
  validateActiveEpic() {
    const state = this.loadWorkflowState();
    const tasks = this.loadTasks();

    if (!state.active_epic) {
      return {
        valid: false,
        error: 'No active epic in workflow state. Run /tm-pm to create one.'
      };
    }

    if (!tasks[state.active_epic]) {
      return {
        valid: false,
        error: `Active epic '${state.active_epic}' not found in Task Master.`
      };
    }

    return {
      valid: true,
      epic: state.active_epic,
      tasks: tasks[state.active_epic].tasks
    };
  }

  /**
   * Validate task dependencies are met
   */
  validateDependencies(epicTag, taskId) {
    const tasks = this.loadTasks();
    const epic = tasks[epicTag];

    if (!epic) {
      return {
        valid: false,
        error: `Epic '${epicTag}' not found in Task Master.`
      };
    }

    const task = epic.tasks.find(t => t.id === taskId);
    if (!task) {
      return {
        valid: false,
        error: `Task ${taskId} not found in epic '${epicTag}'.`
      };
    }

    const dependencies = task.dependencies || [];
    const unmetDependencies = [];

    for (const depId of dependencies) {
      const depTask = epic.tasks.find(t => t.id === depId);
      if (!depTask) {
        return {
          valid: false,
          error: `Dependency task ${depId} not found in epic.`
        };
      }

      if (depTask.status !== 'done') {
        unmetDependencies.push({
          id: depTask.id,
          title: depTask.title,
          status: depTask.status
        });
      }
    }

    if (unmetDependencies.length > 0) {
      return {
        valid: false,
        unmetDependencies,
        error: `Task ${taskId} has ${unmetDependencies.length} incomplete dependencies.`
      };
    }

    return {
      valid: true,
      task,
      dependencies
    };
  }

  /**
   * Validate all tasks in epic are complete
   */
  validateEpicComplete(epicTag) {
    const tasks = this.loadTasks();
    const epic = tasks[epicTag];

    if (!epic) {
      return {
        valid: false,
        error: `Epic '${epicTag}' not found in Task Master.`
      };
    }

    const incompleteTasks = epic.tasks.filter(t => t.status !== 'done');

    if (incompleteTasks.length > 0) {
      return {
        valid: false,
        incompleteTasks: incompleteTasks.map(t => ({
          id: t.id,
          title: t.title,
          status: t.status
        })),
        error: `Epic has ${incompleteTasks.length} incomplete tasks.`
      };
    }

    return {
      valid: true,
      totalTasks: epic.tasks.length
    };
  }

  /**
   * Get available tasks (no unmet dependencies)
   */
  getAvailableTasks(epicTag) {
    const tasks = this.loadTasks();
    const epic = tasks[epicTag];

    if (!epic) {
      return {
        valid: false,
        error: `Epic '${epicTag}' not found in Task Master.`
      };
    }

    const availableTasks = [];
    const blockedTasks = [];

    for (const task of epic.tasks) {
      if (task.status === 'done') continue;

      const depCheck = this.validateDependencies(epicTag, task.id);

      if (depCheck.valid) {
        availableTasks.push({
          id: task.id,
          title: task.title,
          status: task.status,
          priority: task.priority,
          complexity: task.complexity
        });
      } else {
        blockedTasks.push({
          id: task.id,
          title: task.title,
          status: task.status,
          unmetDependencies: depCheck.unmetDependencies
        });
      }
    }

    return {
      valid: true,
      availableTasks,
      blockedTasks
    };
  }

  /**
   * Update workflow phase
   */
  updatePhase(newPhase, updates = {}) {
    const state = this.loadWorkflowState();
    const now = new Date().toISOString();

    // Mark current phase as complete
    if (state.current_phase && state.phases[state.current_phase]) {
      state.phases[state.current_phase].status = 'completed';
      state.phases[state.current_phase].completed_at = now;
    }

    // Activate new phase
    state.current_phase = newPhase;
    if (state.phases[newPhase]) {
      state.phases[newPhase].status = 'active';
    }

    // Apply additional updates
    Object.assign(state, updates);

    state.last_updated = now;

    this.saveWorkflowState(state);

    return { success: true, state };
  }

  /**
   * Add entry to workflow history
   */
  addHistoryEntry(entry) {
    const state = this.loadWorkflowState();

    if (!state.history) {
      state.history = [];
    }

    state.history.push({
      ...entry,
      timestamp: new Date().toISOString()
    });

    state.last_updated = new Date().toISOString();

    this.saveWorkflowState(state);

    return { success: true };
  }

  /**
   * Get epic statistics
   */
  getEpicStats(epicTag) {
    const tasks = this.loadTasks();
    const epic = tasks[epicTag];

    if (!epic) {
      return {
        valid: false,
        error: `Epic '${epicTag}' not found in Task Master.`
      };
    }

    const tasksByStatus = {
      done: [],
      'in-progress': [],
      blocked: [],
      pending: []
    };

    let totalComplexity = 0;

    for (const task of epic.tasks) {
      const status = task.status || 'pending';
      if (tasksByStatus[status]) {
        tasksByStatus[status].push(task);
      }
      totalComplexity += task.complexity || 0;
    }

    return {
      valid: true,
      epic: epicTag,
      totalTasks: epic.tasks.length,
      totalComplexity,
      byStatus: {
        done: tasksByStatus.done.length,
        inProgress: tasksByStatus['in-progress'].length,
        blocked: tasksByStatus.blocked.length,
        pending: tasksByStatus.pending.length
      },
      tasks: tasksByStatus
    };
  }

  /**
   * List all epic tags in Task Master
   */
  listEpicTags() {
    const tasks = this.loadTasks();
    const tags = Object.keys(tasks);

    return {
      valid: true,
      tags,
      count: tags.length
    };
  }

  /**
   * Get currently active epic tag from workflow state
   */
  getActiveEpicTag() {
    const state = this.loadWorkflowState();
    return {
      valid: true,
      activeEpic: state.active_epic || null
    };
  }

  /**
   * Set active epic tag in workflow state
   */
  setActiveEpicTag(epicTag) {
    const state = this.loadWorkflowState();
    const tasks = this.loadTasks();

    // Verify epic exists
    if (!tasks[epicTag]) {
      return {
        valid: false,
        error: `Epic '${epicTag}' not found in Task Master.`
      };
    }

    state.active_epic = epicTag;
    state.last_updated = new Date().toISOString();

    this.saveWorkflowState(state);

    return {
      valid: true,
      activeEpic: epicTag
    };
  }

  /**
   * Get command availability for /status
   */
  getCommandAvailability() {
    const state = this.loadWorkflowState();
    const currentPhase = state.current_phase;

    const commands = {
      'tm-pm': { available: false, reason: '' },
      'tm-architect': { available: false, reason: '' },
      'tm-dev': { available: false, reason: '' },
      'tm-retrospective': { available: false, reason: '' }
    };

    // tm-pm: Always available in ideation/planning
    if (['ideation', 'planning'].includes(currentPhase)) {
      commands['tm-pm'].available = true;
      commands['tm-pm'].reason = 'Ready to create PRD or parse into Task Master';
    } else {
      commands['tm-pm'].reason = `Only available in ideation/planning phases (current: ${currentPhase})`;
    }

    // tm-architect: Available when planning complete and epic exists
    if (currentPhase === 'architecture' && state.active_epic) {
      commands['tm-architect'].available = true;
      commands['tm-architect'].reason = 'Ready to design architecture';
    } else if (!state.active_epic) {
      commands['tm-architect'].reason = 'No epic in Task Master - run /tm-pm first';
    } else {
      commands['tm-architect'].reason = `Only available in architecture phase (current: ${currentPhase})`;
    }

    // tm-dev: Available when architecture complete
    if (currentPhase === 'implementation' && state.active_epic) {
      commands['tm-dev'].available = true;
      commands['tm-dev'].reason = 'Ready to implement tasks';
    } else if (!state.active_epic) {
      commands['tm-dev'].reason = 'No epic in Task Master - complete planning first';
    } else {
      commands['tm-dev'].reason = `Only available in implementation phase (current: ${currentPhase})`;
    }

    // tm-retrospective: Available when all tasks done
    if (state.active_epic) {
      const epicComplete = this.validateEpicComplete(state.active_epic);
      if (epicComplete.valid) {
        commands['tm-retrospective'].available = true;
        commands['tm-retrospective'].reason = 'All tasks complete - ready for retrospective';
      } else {
        commands['tm-retrospective'].reason = `Epic has ${epicComplete.incompleteTasks.length} incomplete tasks`;
      }
    } else {
      commands['tm-retrospective'].reason = 'No active epic';
    }

    return commands;
  }
}

// CLI Interface
if (require.main === module) {
  const validator = new TaskMasterValidator();
  const command = process.argv[2];

  try {
    let result;

    switch (command) {
      case 'validate-cli':
        result = validator.validateTaskMasterCLI();
        break;

      case 'validate-phase':
        const agent = process.argv[3];
        const phases = process.argv.slice(4);
        result = validator.validatePhase(agent, phases);
        break;

      case 'validate-epic':
        result = validator.validateActiveEpic();
        break;

      case 'validate-dependencies':
        const epicTag = process.argv[3];
        const taskId = process.argv[4];
        result = validator.validateDependencies(epicTag, taskId);
        break;

      case 'validate-epic-complete':
        result = validator.validateEpicComplete(process.argv[3]);
        break;

      case 'get-available-tasks':
        result = validator.getAvailableTasks(process.argv[3]);
        break;

      case 'get-epic-stats':
        result = validator.getEpicStats(process.argv[3]);
        break;

      case 'get-command-availability':
        result = validator.getCommandAvailability();
        break;

      case 'update-phase':
        const newPhase = process.argv[3];
        const updates = process.argv[4] ? JSON.parse(process.argv[4]) : {};
        result = validator.updatePhase(newPhase, updates);
        break;

      case 'add-history':
        const entry = JSON.parse(process.argv[3]);
        result = validator.addHistoryEntry(entry);
        break;

      case 'list-epic-tags':
        result = validator.listEpicTags();
        break;

      case 'get-active-epic-tag':
        result = validator.getActiveEpicTag();
        break;

      case 'set-active-epic-tag':
        const epicTagToSet = process.argv[3];
        result = validator.setActiveEpicTag(epicTagToSet);
        break;

      default:
        console.error(`Unknown command: ${command}`);
        console.log(`
Usage: taskmaster-validator.js <command> [args]

Commands:
  validate-cli                                  Check if Task Master CLI is available
  validate-phase <agent> <phase1> [phase2...]   Validate current phase for agent
  validate-epic                                  Check if active epic exists
  validate-dependencies <epic> <task-id>         Check if task dependencies are met
  validate-epic-complete <epic>                  Check if all tasks in epic are done
  get-available-tasks <epic>                     Get tasks with no unmet dependencies
  get-epic-stats <epic>                          Get epic statistics
  get-command-availability                       Get which commands are available
  update-phase <new-phase> [json-updates]       Update workflow phase
  add-history <json-entry>                       Add entry to workflow history
  list-epic-tags                                 List all epic tags in Task Master
  get-active-epic-tag                            Get currently active epic tag
  set-active-epic-tag <epic-tag>                 Set active epic tag in workflow state
        `);
        process.exit(1);
    }

    console.log(JSON.stringify(result, null, 2));
    process.exit(result.valid !== false && result.success !== false ? 0 : 1);
  } catch (error) {
    console.error(JSON.stringify({
      valid: false,
      error: error.message
    }, null, 2));
    process.exit(1);
  }
}

module.exports = TaskMasterValidator;
</file>

<file path="src/task-manager.js">
#!/usr/bin/env node

/**
 * Simple Task Manager for SCUD
 * Sprint Cycle Unified Development
 *
 * Provides core task operations without external dependencies.
 * For AI-powered features (expand, analyze-complexity, parse-prd),
 * use the external task-master CLI.
 */

const fs = require('fs');
const path = require('path');

class TaskManager {
  constructor(projectRoot = process.cwd()) {
    this.projectRoot = projectRoot;
    this.tasksPath = path.join(projectRoot, '.taskmaster', 'tasks', 'tasks.json');
    this.workflowPath = path.join(projectRoot, '.taskmaster', 'workflow-state.json');
  }

  /**
   * Load tasks from disk
   */
  loadTasks() {
    if (!fs.existsSync(this.tasksPath)) {
      throw new Error(`Tasks file not found: ${this.tasksPath}\nRun: scud init`);
    }
    return JSON.parse(fs.readFileSync(this.tasksPath, 'utf8'));
  }

  /**
   * Save tasks to disk
   */
  saveTasks(tasks) {
    const dir = path.dirname(this.tasksPath);
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }
    fs.writeFileSync(this.tasksPath, JSON.stringify(tasks, null, 2));
  }

  /**
   * Load workflow state
   */
  loadWorkflowState() {
    if (!fs.existsSync(this.workflowPath)) {
      throw new Error(`Workflow state not found: ${this.workflowPath}\nRun: scud init`);
    }
    return JSON.parse(fs.readFileSync(this.workflowPath, 'utf8'));
  }

  /**
   * Save workflow state
   */
  saveWorkflowState(state) {
    fs.writeFileSync(this.workflowPath, JSON.stringify(state, null, 2));
  }

  /**
   * Get active epic tag from workflow state
   */
  getActiveEpic() {
    const state = this.loadWorkflowState();
    return state.active_epic;
  }

  /**
   * Set active epic tag in workflow state
   */
  setActiveEpic(epicTag) {
    const tasks = this.loadTasks();
    if (!tasks[epicTag]) {
      throw new Error(`Epic '${epicTag}' not found`);
    }

    const state = this.loadWorkflowState();
    state.active_epic = epicTag;
    state.last_updated = new Date().toISOString();
    this.saveWorkflowState(state);

    return epicTag;
  }

  /**
   * List all epic tags
   */
  listTags() {
    const tasks = this.loadTasks();
    const tags = Object.keys(tasks);
    const activeEpic = this.getActiveEpic();

    return tags.map(tag => ({
      tag,
      active: tag === activeEpic,
      taskCount: tasks[tag].tasks ? tasks[tag].tasks.length : 0
    }));
  }

  /**
   * List tasks in active epic
   */
  listTasks(options = {}) {
    const activeEpic = this.getActiveEpic();
    if (!activeEpic) {
      throw new Error('No active epic. Run: scud use-tag <epic-tag>');
    }

    const tasks = this.loadTasks();
    const epic = tasks[activeEpic];
    if (!epic || !epic.tasks) {
      return [];
    }

    let taskList = epic.tasks;

    // Filter by status if provided
    if (options.status) {
      taskList = taskList.filter(t => t.status === options.status);
    }

    return taskList.map(task => ({
      id: task.id,
      title: task.title,
      status: task.status || 'pending',
      complexity: task.complexity || 0,
      priority: task.priority || 'medium',
      dependencies: task.dependencies || []
    }));
  }

  /**
   * Show detailed task information
   */
  showTask(taskId) {
    const activeEpic = this.getActiveEpic();
    if (!activeEpic) {
      throw new Error('No active epic. Run: scud use-tag <epic-tag>');
    }

    const tasks = this.loadTasks();
    const epic = tasks[activeEpic];
    const task = epic.tasks.find(t => t.id === taskId || t.id === String(taskId));

    if (!task) {
      throw new Error(`Task ${taskId} not found in epic '${activeEpic}'`);
    }

    return task;
  }

  /**
   * Update task status
   */
  setStatus(taskId, status) {
    const validStatuses = ['pending', 'in-progress', 'done', 'review', 'blocked', 'deferred', 'cancelled'];
    if (!validStatuses.includes(status)) {
      throw new Error(`Invalid status: ${status}. Valid: ${validStatuses.join(', ')}`);
    }

    const activeEpic = this.getActiveEpic();
    if (!activeEpic) {
      throw new Error('No active epic. Run: scud use-tag <epic-tag>');
    }

    const allTasks = this.loadTasks();
    const epic = allTasks[activeEpic];
    const task = epic.tasks.find(t => t.id === taskId || t.id === String(taskId));

    if (!task) {
      throw new Error(`Task ${taskId} not found in epic '${activeEpic}'`);
    }

    task.status = status;
    task.updated_at = new Date().toISOString();

    this.saveTasks(allTasks);

    return task;
  }

  /**
   * Find next available task (dependencies met, status pending)
   */
  findNext() {
    const activeEpic = this.getActiveEpic();
    if (!activeEpic) {
      throw new Error('No active epic. Run: scud use-tag <epic-tag>');
    }

    const tasks = this.loadTasks();
    const epic = tasks[activeEpic];

    if (!epic || !epic.tasks) {
      return null;
    }

    // Find pending tasks with all dependencies met
    for (const task of epic.tasks) {
      if (task.status !== 'pending') {
        continue;
      }

      // Check dependencies
      const dependencies = task.dependencies || [];
      const allDepsMet = dependencies.every(depId => {
        const depTask = epic.tasks.find(t => t.id === depId || t.id === String(depId));
        return depTask && depTask.status === 'done';
      });

      if (allDepsMet) {
        return task;
      }
    }

    return null;
  }

  /**
   * Get task statistics
   */
  getStats() {
    const activeEpic = this.getActiveEpic();
    if (!activeEpic) {
      throw new Error('No active epic. Run: scud use-tag <epic-tag>');
    }

    const tasks = this.loadTasks();
    const epic = tasks[activeEpic];

    if (!epic || !epic.tasks) {
      return {
        total: 0,
        pending: 0,
        inProgress: 0,
        done: 0,
        blocked: 0
      };
    }

    const stats = {
      total: epic.tasks.length,
      pending: 0,
      inProgress: 0,
      done: 0,
      blocked: 0,
      totalComplexity: 0
    };

    epic.tasks.forEach(task => {
      const status = task.status || 'pending';
      if (status === 'pending') stats.pending++;
      else if (status === 'in-progress') stats.inProgress++;
      else if (status === 'done') stats.done++;
      else if (status === 'blocked') stats.blocked++;

      stats.totalComplexity += task.complexity || 0;
    });

    return stats;
  }
}

// CLI Interface
if (require.main === module) {
  const tm = new TaskManager();
  const command = process.argv[2];
  const args = process.argv.slice(3);

  try {
    let result;

    switch (command) {
      case 'tags':
      case 'list-tags':
        result = tm.listTags();
        const activeTag = result.find(t => t.active);
        console.log('\nEpic Tags:');
        result.forEach(({ tag, active, taskCount }) => {
          const marker = active ? 'â†’' : ' ';
          console.log(`  ${marker} ${tag} (${taskCount} tasks)`);
        });
        if (activeTag) {
          console.log(`\nActive: ${activeTag.tag}`);
        }
        break;

      case 'use-tag':
        if (!args[0]) {
          console.error('Usage: scud use-tag <epic-tag>');
          process.exit(1);
        }
        tm.setActiveEpic(args[0]);
        console.log(`âœ“ Switched to epic: ${args[0]}`);
        break;

      case 'list':
        const status = args[0] && args[0].startsWith('--status=')
          ? args[0].split('=')[1]
          : null;
        result = tm.listTasks(status ? { status } : {});

        if (result.length === 0) {
          console.log('No tasks found');
        } else {
          console.log(`\nTasks in ${tm.getActiveEpic()}:\n`);
          result.forEach(task => {
            const statusIcon = {
              'pending': 'â—‹',
              'in-progress': 'â—',
              'done': 'â—',
              'blocked': 'âœ–',
              'review': 'â—”'
            }[task.status] || 'â—‹';

            console.log(`  ${statusIcon} Task ${task.id}: ${task.title}`);
            console.log(`    Status: ${task.status} | Complexity: ${task.complexity} | Priority: ${task.priority}`);
            if (task.dependencies.length > 0) {
              console.log(`    Dependencies: ${task.dependencies.join(', ')}`);
            }
            console.log('');
          });
        }
        break;

      case 'show':
        if (!args[0]) {
          console.error('Usage: scud show <task-id>');
          process.exit(1);
        }
        result = tm.showTask(args[0]);
        console.log(`\nTask ${result.id}: ${result.title}\n`);
        console.log(`Status: ${result.status || 'pending'}`);
        console.log(`Complexity: ${result.complexity || 0}`);
        console.log(`Priority: ${result.priority || 'medium'}`);
        if (result.dependencies && result.dependencies.length > 0) {
          console.log(`Dependencies: ${result.dependencies.join(', ')}`);
        }
        console.log(`\nDescription:\n${result.description || 'No description'}`);
        if (result.details) {
          console.log(`\nDetails:\n${result.details}`);
        }
        if (result.testStrategy) {
          console.log(`\nTest Strategy:\n${result.testStrategy}`);
        }
        break;

      case 'set-status':
        if (!args[0] || !args[1]) {
          console.error('Usage: scud set-status <task-id> <status>');
          console.error('Valid statuses: pending, in-progress, done, review, blocked, deferred, cancelled');
          process.exit(1);
        }
        result = tm.setStatus(args[0], args[1]);
        console.log(`âœ“ Task ${result.id} status updated to: ${result.status}`);
        break;

      case 'next':
        result = tm.findNext();
        if (result) {
          console.log(`\nNext available task:\n`);
          console.log(`Task ${result.id}: ${result.title}`);
          console.log(`Complexity: ${result.complexity || 0}`);
          console.log(`Priority: ${result.priority || 'medium'}`);
          console.log(`\nRun: scud show ${result.id}`);
        } else {
          console.log('No tasks available (all tasks are blocked or complete)');
        }
        break;

      case 'stats':
        result = tm.getStats();
        console.log(`\nTask Statistics for ${tm.getActiveEpic()}:\n`);
        console.log(`Total Tasks: ${result.total}`);
        console.log(`  â—‹ Pending: ${result.pending}`);
        console.log(`  â— In Progress: ${result.inProgress}`);
        console.log(`  â— Done: ${result.done}`);
        console.log(`  âœ– Blocked: ${result.blocked}`);
        console.log(`\nTotal Complexity: ${result.totalComplexity}`);
        break;

      default:
        console.log(`
Simple Task Manager for SCUD

Core Commands (fast, no dependencies):
  tags                      List all epic tags
  use-tag <tag>            Switch to epic
  list [--status=<status>]  List tasks in active epic
  show <id>                Show task details
  set-status <id> <status> Update task status
  next                     Find next available task
  stats                    Show task statistics

AI-Powered Commands (use task-master CLI):
  task-master parse-prd <file> --tag=<tag>    Parse PRD into tasks
  task-master analyze-complexity              Analyze task complexity
  task-master expand --id=<id>                Expand task into subtasks
  task-master research "<query>"              AI research

Examples:
  scud tags                      # List all epics
  scud use-tag epic-1-auth       # Switch to epic
  scud list                      # List tasks
  scud next                      # Find next task
  scud show 3                    # Show task 3
  scud set-status 3 in-progress  # Start task 3
  scud set-status 3 done         # Complete task 3
        `);
        process.exit(command ? 1 : 0);
    }

    process.exit(0);
  } catch (error) {
    console.error(`Error: ${error.message}`);
    process.exit(1);
  }
}

module.exports = TaskManager;
</file>

<file path=".npmignore">
# Development files
*.log
npm-debug.log*
node_modules/
.DS_Store

# Git
.git/
.gitignore

# IDE
.vscode/
.idea/

# Project-specific (not needed in package)
.taskmaster/
docs/prd/
docs/epics/
docs/architecture/
docs/retrospectives/
log_docs/

# Keep only documentation templates
!docs/.gitkeep

# Installation scripts (already in project)
install-claude-code.sh
install-opencode.sh

# Rust build artifacts
scud-cli/target/

# Keep these for the package
!bin/
!src/
!scud-cli/
!.claude/
!.opencode/
!README.md
!QUICKSTART.md
!COMPLETE_GUIDE.md
!QUICK_REFERENCE.md
!PARALLEL_FEATURES.md
!LICENSE
</file>

<file path="scud-cli/src/commands/list.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::models::TaskStatus;
use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, status_filter: Option<&str>) -> Result<()> {
    let storage = Storage::new(project_root);

    // OPTIMIZED: Load only active epic (uses cache + lazy loading)
    let epic = storage.load_active_epic()?;

    // Parse filter status once
    let filter_status = status_filter
        .map(|s| {
            TaskStatus::from_str(s).ok_or_else(|| {
                anyhow::anyhow!("Invalid status: {}. Valid: {:?}", s, TaskStatus::all())
            })
        })
        .transpose()?;

    // OPTIMIZED: Use iterator instead of clone
    let task_iter = epic
        .tasks
        .iter()
        .filter(|t| filter_status.as_ref().map(|fs| t.status == *fs).unwrap_or(true));

    if task_iter.clone().count() == 0 {
        println!("{}", "No tasks found".yellow());
        return Ok(());
    }

    println!(
        "{} {}",
        "Tasks in epic:".blue().bold(),
        epic.name.green()
    );
    println!();

    for task in task_iter {
        let status_color = match task.status {
            TaskStatus::Done => "done".green(),
            TaskStatus::InProgress => "in-progress".yellow(),
            TaskStatus::Blocked => "blocked".red(),
            TaskStatus::Pending => "pending".white(),
            _ => task.status.as_str().white(),
        };

        let complexity_str = if task.complexity > 0 {
            format!("[{}]", task.complexity)
        } else {
            "".to_string()
        };

        println!(
            "  {:<4} {:<15} {} {}",
            task.id.cyan(),
            status_color,
            task.title,
            complexity_str.yellow()
        );
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/mod.rs">
pub mod ai;
pub mod init;
pub mod list;
pub mod next;
pub mod set_status;
pub mod show;
pub mod stats;
pub mod tags;
pub mod use_tag;

// Epic group commands
pub mod add_to_group;
pub mod create_group;
pub mod group_status;
pub mod list_groups;

// Task assignment commands
pub mod assign;
pub mod claim;
pub mod release;
pub mod whois;
</file>

<file path="scud-cli/src/commands/next.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);

    // OPTIMIZED: Load only active epic (uses cache + lazy loading)
    let epic = storage.load_active_epic()?;

    match epic.find_next_task() {
        Some(task) => {
            println!("{}", "Next Available Task:".green().bold());
            println!();
            println!("{:<20} {}", "ID:".yellow(), task.id.cyan());
            println!("{:<20} {}", "Title:".yellow(), task.title.bold());
            println!("{:<20} {}", "Complexity:".yellow(), task.complexity);
            println!("{:<20} {:?}", "Priority:".yellow(), task.priority);
            println!();
            println!("{}", "Description:".yellow());
            println!("{}", task.description);

            if let Some(details) = &task.details {
                println!();
                println!("{}", "Technical Details:".yellow());
                println!("{}", details);
            }

            if let Some(test_strategy) = &task.test_strategy {
                println!();
                println!("{}", "Test Strategy:".yellow());
                println!("{}", test_strategy);
            }

            println!();
            println!("{}", "To start this task:".blue());
            println!("  scud set-status {} in-progress", task.id);
        }
        None => {
            println!(
                "{}",
                "No available tasks with all dependencies met".yellow()
            );
            println!("Run: scud list --status pending");
        }
    }

    Ok(())
}
</file>

<file path="scud-cli/src/commands/set_status.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::models::TaskStatus;
use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, task_id: &str, status_str: &str) -> Result<()> {
    let new_status = TaskStatus::from_str(status_str).ok_or_else(|| {
        anyhow::anyhow!(
            "Invalid status: {}. Valid: {:?}",
            status_str,
            TaskStatus::all()
        )
    })?;

    let storage = Storage::new(project_root);

    // OPTIMIZED: Get active epic from cache
    let active_tag = storage
        .get_active_epic()?
        .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

    // OPTIMIZED: Load only active epic
    let mut epic = storage.load_epic(&active_tag)?;

    let task = epic.get_task_mut(task_id).ok_or_else(|| {
        anyhow::anyhow!("Task {} not found in epic '{}'", task_id, active_tag)
    })?;

    task.set_status(new_status);

    // OPTIMIZED: Save only active epic
    storage.update_epic(&active_tag, &epic)?;

    println!(
        "{} Task {} â†’ {}",
        "âœ“".green(),
        task_id.cyan(),
        status_str.green()
    );

    Ok(())
}
</file>

<file path="scud-cli/src/commands/show.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>, task_id: &str) -> Result<()> {
    let storage = Storage::new(project_root);

    // OPTIMIZED: Load only active epic (uses cache + lazy loading)
    let epic = storage.load_active_epic()?;

    let task = epic.get_task(task_id).ok_or_else(|| {
        anyhow::anyhow!("Task {} not found in epic '{}'", task_id, epic.name)
    })?;

    println!("\n{}", "Task Details".blue().bold());
    println!("{}", "=============".blue());
    println!("{:<20} {}", "ID:".yellow(), task.id.cyan());
    println!("{:<20} {}", "Title:".yellow(), task.title.bold());
    println!("{:<20} {}", "Status:".yellow(), task.status.as_str());
    println!("{:<20} {}", "Complexity:".yellow(), task.complexity);
    println!("{:<20} {:?}", "Priority:".yellow(), task.priority);

    if !task.dependencies.is_empty() {
        println!("{:<20} {:?}", "Dependencies:".yellow(), task.dependencies);
    }

    println!("\n{}", "Description:".yellow());
    println!("{}", task.description);

    if let Some(details) = &task.details {
        println!("\n{}", "Technical Details:".yellow());
        println!("{}", details);
    }

    if let Some(test_strategy) = &task.test_strategy {
        println!("\n{}", "Test Strategy:".yellow());
        println!("{}", test_strategy);
    }

    if let Some(analysis) = &task.complexity_analysis {
        println!("\n{}", "Complexity Analysis:".yellow());
        println!("{}", analysis);
    }

    if let Some(created) = &task.created_at {
        println!("\n{:<20} {}", "Created:".yellow(), created);
    }

    if let Some(updated) = &task.updated_at {
        println!("{:<20} {}", "Updated:".yellow(), updated);
    }

    println!();
    Ok(())
}
</file>

<file path="scud-cli/src/commands/stats.rs">
use anyhow::Result;
use colored::Colorize;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);

    // OPTIMIZED: Load only active epic (uses cache + lazy loading)
    let epic = storage.load_active_epic()?;
    let active_epic = &epic.name;

    let stats = epic.get_stats();

    let completion_pct = if stats.total > 0 {
        (stats.done as f32 / stats.total as f32 * 100.0) as u32
    } else {
        0
    };

    println!(
        "\n{} {}",
        "Epic Statistics:".blue().bold(),
        active_epic.green()
    );
    println!("{}", "=================".blue());
    println!();
    println!("{:<20} {}", "Total Tasks:".yellow(), stats.total);
    println!("{:<20} {}", "Pending:".yellow(), stats.pending);
    println!("{:<20} {}", "In Progress:".yellow(), stats.in_progress);
    println!(
        "{:<20} {}",
        "Done:".yellow(),
        stats.done.to_string().green()
    );
    println!(
        "{:<20} {}",
        "Blocked:".yellow(),
        stats.blocked.to_string().red()
    );
    println!();
    println!(
        "{:<20} {}",
        "Total Complexity:".yellow(),
        stats.total_complexity
    );
    println!(
        "{:<20} {}%",
        "Completion:".yellow(),
        completion_pct.to_string().green()
    );

    // Show progress bar
    let bar_length = 50;
    let filled = (completion_pct as f32 / 100.0 * bar_length as f32) as usize;
    let empty = bar_length - filled;
    let bar = format!("[{}{}]", "=".repeat(filled).green(), " ".repeat(empty));
    println!("\n{}", bar);
    println!();

    Ok(())
}
</file>

<file path="scud-cli/src/commands/whois.rs">
use anyhow::Result;
use colored::Colorize;
use std::collections::HashMap;
use std::path::PathBuf;

use crate::storage::Storage;

pub fn run(project_root: Option<PathBuf>) -> Result<()> {
    let storage = Storage::new(project_root);
    let tasks = storage.load_tasks()?;

    let mut assignments: HashMap<String, Vec<(String, String, String)>> = HashMap::new();
    let mut stale_locks: Vec<(String, String, String, f64)> = Vec::new();

    // Collect all assignments across all epics
    for (epic_tag, epic) in tasks.iter() {
        for task in &epic.tasks {
            if let Some(ref assigned) = task.assigned_to {
                assignments
                    .entry(assigned.clone())
                    .or_default()
                    .push((epic_tag.clone(), task.id.clone(), task.title.clone()));
            }

            // Check for stale locks
            if task.is_stale_lock(24.0) {
                if let (Some(locked_by), Some(age)) = (&task.locked_by, task.lock_age_hours()) {
                    stale_locks.push((epic_tag.clone(), task.id.clone(), locked_by.clone(), age));
                }
            }
        }
    }

    if assignments.is_empty() {
        println!("{}", "No tasks are currently assigned".yellow());
        println!();
        println!("{}", "Assign tasks with:".blue());
        println!("  scud assign <task-id> <assignee>");
        println!("  scud claim <task-id> --name <your-name>");
        return Ok(());
    }

    println!("\n{}", "Task Assignments".blue().bold());
    println!("{}", "=".repeat(60).blue());
    println!();

    for (assignee, tasks_list) in assignments.iter() {
        println!("{} {}", "â—".green(), assignee.green().bold());
        for (epic, task_id, title) in tasks_list {
            println!("  {} {} - {}", epic.cyan(), task_id.yellow(), title);
        }
        println!();
    }

    // Show stale locks warning
    if !stale_locks.is_empty() {
        println!("{}", "âš  Stale Locks (>24h)".yellow().bold());
        println!("{}", "=".repeat(60).yellow());
        println!();

        for (epic, task_id, locked_by, age) in stale_locks {
            println!(
                "  {} {} locked by {} ({:.1}h ago)",
                epic.cyan(),
                task_id.yellow(),
                locked_by.red(),
                age
            );
        }
        println!();
        println!("{}", "Consider releasing stale locks:".blue());
        println!("  scud release <task-id> --force");
        println!();
    }

    Ok(())
}
</file>

<file path="scud-cli/src/models/mod.rs">
pub mod epic;
pub mod group;
pub mod task;
pub mod workflow;

pub use epic::Epic;
pub use group::{EpicGroup, EpicGroups, GroupStatus};
pub use task::{Priority, Task, TaskStatus};
pub use workflow::WorkflowState;
</file>

<file path="scud-cli/src/models/workflow.rs">
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum Phase {
    Ideation,
    Planning,
    Architecture,
    Implementation,
    Retrospective,
}

impl Phase {
    pub fn as_str(&self) -> &'static str {
        match self {
            Phase::Ideation => "ideation",
            Phase::Planning => "planning",
            Phase::Architecture => "architecture",
            Phase::Implementation => "implementation",
            Phase::Retrospective => "retrospective",
        }
    }

    #[allow(clippy::should_implement_trait)]
    pub fn from_str(s: &str) -> Option<Self> {
        match s {
            "ideation" => Some(Phase::Ideation),
            "planning" => Some(Phase::Planning),
            "architecture" => Some(Phase::Architecture),
            "implementation" => Some(Phase::Implementation),
            "retrospective" => Some(Phase::Retrospective),
            _ => None,
        }
    }

    pub fn next(&self) -> Option<Self> {
        match self {
            Phase::Ideation => Some(Phase::Planning),
            Phase::Planning => Some(Phase::Architecture),
            Phase::Architecture => Some(Phase::Implementation),
            Phase::Implementation => Some(Phase::Retrospective),
            Phase::Retrospective => None, // Completed
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PhaseInfo {
    pub status: String,
    pub completed_at: Option<String>,
    pub agent: String,
    pub description: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompletedEpic {
    pub tag: String,
    pub completed_at: String,
    pub metrics: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowState {
    pub version: String,
    pub current_phase: String,
    pub active_epic: Option<String>,
    pub phases: HashMap<String, PhaseInfo>,
    pub history: Vec<serde_json::Value>,
    pub completed_epics: Vec<CompletedEpic>,
    pub last_updated: Option<String>,
}

impl WorkflowState {
    pub fn new() -> Self {
        let mut phases = HashMap::new();

        phases.insert(
            "ideation".to_string(),
            PhaseInfo {
                status: "active".to_string(),
                completed_at: None,
                agent: "tm-pm".to_string(),
                description: "Product definition and PRD creation".to_string(),
            },
        );

        phases.insert(
            "planning".to_string(),
            PhaseInfo {
                status: "pending".to_string(),
                completed_at: None,
                agent: "tm-sm".to_string(),
                description: "Epic breakdown and task planning".to_string(),
            },
        );

        phases.insert(
            "architecture".to_string(),
            PhaseInfo {
                status: "pending".to_string(),
                completed_at: None,
                agent: "tm-architect".to_string(),
                description: "Technical design and architecture".to_string(),
            },
        );

        phases.insert(
            "implementation".to_string(),
            PhaseInfo {
                status: "pending".to_string(),
                completed_at: None,
                agent: "tm-dev".to_string(),
                description: "Task execution and development".to_string(),
            },
        );

        phases.insert(
            "retrospective".to_string(),
            PhaseInfo {
                status: "pending".to_string(),
                completed_at: None,
                agent: "tm-retrospective".to_string(),
                description: "Post-epic analysis and learning capture".to_string(),
            },
        );

        WorkflowState {
            version: "1.0.0".to_string(),
            current_phase: "ideation".to_string(),
            active_epic: None,
            phases,
            history: Vec::new(),
            completed_epics: Vec::new(),
            last_updated: None,
        }
    }

    pub fn set_phase(&mut self, phase: Phase) {
        self.current_phase = phase.as_str().to_string();
        self.last_updated = Some(chrono::Utc::now().to_rfc3339());
    }

    pub fn get_current_phase(&self) -> Option<Phase> {
        Phase::from_str(&self.current_phase)
    }

    pub fn update(&mut self) {
        self.last_updated = Some(chrono::Utc::now().to_rfc3339());
    }
}

impl Default for WorkflowState {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    // ==================== Phase Tests ====================

    #[test]
    fn test_phase_as_str() {
        assert_eq!(Phase::Ideation.as_str(), "ideation");
        assert_eq!(Phase::Planning.as_str(), "planning");
        assert_eq!(Phase::Architecture.as_str(), "architecture");
        assert_eq!(Phase::Implementation.as_str(), "implementation");
        assert_eq!(Phase::Retrospective.as_str(), "retrospective");
    }

    #[test]
    fn test_phase_from_str_valid() {
        assert_eq!(Phase::from_str("ideation"), Some(Phase::Ideation));
        assert_eq!(Phase::from_str("planning"), Some(Phase::Planning));
        assert_eq!(Phase::from_str("architecture"), Some(Phase::Architecture));
        assert_eq!(
            Phase::from_str("implementation"),
            Some(Phase::Implementation)
        );
        assert_eq!(
            Phase::from_str("retrospective"),
            Some(Phase::Retrospective)
        );
    }

    #[test]
    fn test_phase_from_str_invalid() {
        assert_eq!(Phase::from_str("invalid"), None);
        assert_eq!(Phase::from_str(""), None);
        assert_eq!(Phase::from_str("IDEATION"), None); // Case sensitive
        assert_eq!(Phase::from_str("idea"), None);
    }

    #[test]
    fn test_phase_next() {
        assert_eq!(Phase::Ideation.next(), Some(Phase::Planning));
        assert_eq!(Phase::Planning.next(), Some(Phase::Architecture));
        assert_eq!(Phase::Architecture.next(), Some(Phase::Implementation));
        assert_eq!(Phase::Implementation.next(), Some(Phase::Retrospective));
        assert_eq!(Phase::Retrospective.next(), None); // Final phase
    }

    #[test]
    fn test_phase_serialization() {
        let phase = Phase::Architecture;
        let json = serde_json::to_string(&phase).unwrap();
        assert_eq!(json, r#""architecture""#);

        let deserialized: Phase = serde_json::from_str(&json).unwrap();
        assert_eq!(deserialized, Phase::Architecture);
    }

    // ==================== WorkflowState Tests ====================

    #[test]
    fn test_workflow_state_new() {
        let state = WorkflowState::new();

        assert_eq!(state.version, "1.0.0");
        assert_eq!(state.current_phase, "ideation");
        assert_eq!(state.active_epic, None);
        assert_eq!(state.phases.len(), 5);
        assert_eq!(state.history.len(), 0);
        assert_eq!(state.completed_epics.len(), 0);
        assert_eq!(state.last_updated, None);
    }

    #[test]
    fn test_workflow_state_default() {
        let state = WorkflowState::default();
        let new_state = WorkflowState::new();

        assert_eq!(state.version, new_state.version);
        assert_eq!(state.current_phase, new_state.current_phase);
        assert_eq!(state.active_epic, new_state.active_epic);
    }

    #[test]
    fn test_workflow_state_initial_phases() {
        let state = WorkflowState::new();

        // Check ideation phase is active
        let ideation = state.phases.get("ideation").unwrap();
        assert_eq!(ideation.status, "active");
        assert_eq!(ideation.agent, "tm-pm");
        assert_eq!(ideation.completed_at, None);

        // Check other phases are pending
        let planning = state.phases.get("planning").unwrap();
        assert_eq!(planning.status, "pending");
        assert_eq!(planning.agent, "tm-sm");

        let architecture = state.phases.get("architecture").unwrap();
        assert_eq!(architecture.status, "pending");
        assert_eq!(architecture.agent, "tm-architect");

        let implementation = state.phases.get("implementation").unwrap();
        assert_eq!(implementation.status, "pending");
        assert_eq!(implementation.agent, "tm-dev");

        let retrospective = state.phases.get("retrospective").unwrap();
        assert_eq!(retrospective.status, "pending");
        assert_eq!(retrospective.agent, "tm-retrospective");
    }

    #[test]
    fn test_set_phase() {
        let mut state = WorkflowState::new();
        assert_eq!(state.current_phase, "ideation");
        assert_eq!(state.last_updated, None);

        state.set_phase(Phase::Planning);
        assert_eq!(state.current_phase, "planning");
        assert!(state.last_updated.is_some());

        state.set_phase(Phase::Implementation);
        assert_eq!(state.current_phase, "implementation");
    }

    #[test]
    fn test_get_current_phase() {
        let mut state = WorkflowState::new();

        assert_eq!(state.get_current_phase(), Some(Phase::Ideation));

        state.set_phase(Phase::Architecture);
        assert_eq!(state.get_current_phase(), Some(Phase::Architecture));

        state.set_phase(Phase::Retrospective);
        assert_eq!(state.get_current_phase(), Some(Phase::Retrospective));
    }

    #[test]
    fn test_get_current_phase_invalid() {
        let mut state = WorkflowState::new();
        state.current_phase = "invalid_phase".to_string();

        assert_eq!(state.get_current_phase(), None);
    }

    #[test]
    fn test_active_epic_management() {
        let mut state = WorkflowState::new();
        assert_eq!(state.active_epic, None);

        state.active_epic = Some("epic-1-auth".to_string());
        assert_eq!(state.active_epic, Some("epic-1-auth".to_string()));

        state.active_epic = None;
        assert_eq!(state.active_epic, None);
    }

    #[test]
    fn test_update_timestamp() {
        let mut state = WorkflowState::new();
        assert_eq!(state.last_updated, None);

        state.update();
        assert!(state.last_updated.is_some());

        let first_update = state.last_updated.clone();
        std::thread::sleep(std::time::Duration::from_millis(10));

        state.update();
        assert!(state.last_updated.is_some());
        assert_ne!(state.last_updated, first_update); // Should be different
    }

    #[test]
    fn test_completed_epics() {
        let mut state = WorkflowState::new();
        assert_eq!(state.completed_epics.len(), 0);

        let epic = CompletedEpic {
            tag: "epic-1-auth".to_string(),
            completed_at: "2025-11-16T10:30:00Z".to_string(),
            metrics: None,
        };

        state.completed_epics.push(epic);
        assert_eq!(state.completed_epics.len(), 1);
        assert_eq!(state.completed_epics[0].tag, "epic-1-auth");
    }

    #[test]
    fn test_completed_epic_with_metrics() {
        let mut metrics = HashMap::new();
        metrics.insert(
            "tasks_completed".to_string(),
            serde_json::Value::Number(serde_json::Number::from(12)),
        );
        metrics.insert(
            "total_complexity".to_string(),
            serde_json::Value::Number(serde_json::Number::from(55)),
        );

        let epic = CompletedEpic {
            tag: "epic-2-dashboard".to_string(),
            completed_at: "2025-11-16T12:00:00Z".to_string(),
            metrics: Some(metrics),
        };

        assert_eq!(epic.tag, "epic-2-dashboard");
        assert!(epic.metrics.is_some());
        assert_eq!(epic.metrics.as_ref().unwrap().len(), 2);
    }

    #[test]
    fn test_workflow_state_serialization() {
        let state = WorkflowState::new();
        let json = serde_json::to_string(&state).unwrap();
        let deserialized: WorkflowState = serde_json::from_str(&json).unwrap();

        assert_eq!(deserialized.version, state.version);
        assert_eq!(deserialized.current_phase, state.current_phase);
        assert_eq!(deserialized.active_epic, state.active_epic);
        assert_eq!(deserialized.phases.len(), state.phases.len());
    }

    #[test]
    fn test_phase_info_structure() {
        let phase_info = PhaseInfo {
            status: "completed".to_string(),
            completed_at: Some("2025-11-16T10:00:00Z".to_string()),
            agent: "tm-pm".to_string(),
            description: "Product definition".to_string(),
        };

        assert_eq!(phase_info.status, "completed");
        assert_eq!(
            phase_info.completed_at,
            Some("2025-11-16T10:00:00Z".to_string())
        );
        assert_eq!(phase_info.agent, "tm-pm");
    }

    #[test]
    fn test_full_workflow_cycle() {
        let mut state = WorkflowState::new();
        state.active_epic = Some("epic-1-test".to_string());

        // Progress through all phases
        assert_eq!(state.get_current_phase(), Some(Phase::Ideation));

        state.set_phase(Phase::Planning);
        assert_eq!(state.get_current_phase(), Some(Phase::Planning));

        state.set_phase(Phase::Architecture);
        assert_eq!(state.get_current_phase(), Some(Phase::Architecture));

        state.set_phase(Phase::Implementation);
        assert_eq!(state.get_current_phase(), Some(Phase::Implementation));

        state.set_phase(Phase::Retrospective);
        assert_eq!(state.get_current_phase(), Some(Phase::Retrospective));

        // Complete epic
        let epic = CompletedEpic {
            tag: state.active_epic.clone().unwrap(),
            completed_at: chrono::Utc::now().to_rfc3339(),
            metrics: None,
        };
        state.completed_epics.push(epic);
        state.active_epic = None;

        // Reset to ideation
        state.set_phase(Phase::Ideation);
        assert_eq!(state.get_current_phase(), Some(Phase::Ideation));
        assert_eq!(state.active_epic, None);
        assert_eq!(state.completed_epics.len(), 1);
    }
}
</file>

<file path="package.json">
{
  "name": "scud",
  "version": "1.0.0",
  "description": "Sprint Cycle Unified Development - Lightweight workflow orchestration for building software with Task Master and AI agents",
  "main": "src/validators/taskmaster-validator.js",
  "bin": {
    "scud": "./bin/scud.js"
  },
  "scripts": {
    "postinstall": "node bin/postinstall.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "scud",
    "sprint-cycle",
    "task-master",
    "workflow",
    "orchestration",
    "ai-agents",
    "project-management",
    "agile",
    "scrum",
    "claude-code"
  ],
  "author": "Your Name",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/scud.git"
  },
  "bugs": {
    "url": "https://github.com/yourusername/scud/issues"
  },
  "homepage": "https://github.com/yourusername/scud#readme",
  "engines": {
    "node": ">=16.0.0"
  },
  "files": [
    "bin/",
    "src/",
    "scud-cli/",
    ".claude/",
    ".opencode/",
    "README.md",
    "QUICKSTART.md",
    "COMPLETE_GUIDE.md",
    "QUICK_REFERENCE.md",
    "PARALLEL_FEATURES.md",
    "LICENSE"
  ]
}
</file>

<file path="scud-cli/src/models/task.rs">
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]
#[serde(rename_all = "kebab-case")]
pub enum TaskStatus {
    #[default]
    Pending,
    InProgress,
    Done,
    Review,
    Blocked,
    Deferred,
    Cancelled,
}

impl TaskStatus {
    pub fn as_str(&self) -> &'static str {
        match self {
            TaskStatus::Pending => "pending",
            TaskStatus::InProgress => "in-progress",
            TaskStatus::Done => "done",
            TaskStatus::Review => "review",
            TaskStatus::Blocked => "blocked",
            TaskStatus::Deferred => "deferred",
            TaskStatus::Cancelled => "cancelled",
        }
    }

    #[allow(clippy::should_implement_trait)]
    pub fn from_str(s: &str) -> Option<Self> {
        match s {
            "pending" => Some(TaskStatus::Pending),
            "in-progress" => Some(TaskStatus::InProgress),
            "done" => Some(TaskStatus::Done),
            "review" => Some(TaskStatus::Review),
            "blocked" => Some(TaskStatus::Blocked),
            "deferred" => Some(TaskStatus::Deferred),
            "cancelled" => Some(TaskStatus::Cancelled),
            _ => None,
        }
    }

    pub fn all() -> Vec<&'static str> {
        vec![
            "pending",
            "in-progress",
            "done",
            "review",
            "blocked",
            "deferred",
            "cancelled",
        ]
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]
#[serde(rename_all = "lowercase")]
pub enum Priority {
    High,
    #[default]
    Medium,
    Low,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Task {
    pub id: String,
    pub title: String,
    pub description: String,

    #[serde(default)]
    pub status: TaskStatus,

    #[serde(default)]
    pub complexity: u32,

    #[serde(default)]
    pub priority: Priority,

    #[serde(default)]
    pub dependencies: Vec<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub details: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub test_strategy: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub complexity_analysis: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub created_at: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub updated_at: Option<String>,

    // Parallel execution support
    #[serde(skip_serializing_if = "Option::is_none")]
    pub assigned_to: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub locked_by: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub locked_at: Option<String>,
}

impl Task {
    // Validation constants
    const MAX_TITLE_LENGTH: usize = 200;
    const MAX_DESCRIPTION_LENGTH: usize = 5000;
    const VALID_FIBONACCI_NUMBERS: &'static [u32] = &[0, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89];

    pub fn new(id: String, title: String, description: String) -> Self {
        let now = chrono::Utc::now().to_rfc3339();
        Task {
            id,
            title,
            description,
            status: TaskStatus::Pending,
            complexity: 0,
            priority: Priority::Medium,
            dependencies: Vec::new(),
            details: None,
            test_strategy: None,
            complexity_analysis: None,
            created_at: Some(now.clone()),
            updated_at: Some(now),
            assigned_to: None,
            locked_by: None,
            locked_at: None,
        }
    }

    /// Validate task ID - must contain only alphanumeric characters and hyphens
    pub fn validate_id(id: &str) -> Result<(), String> {
        if id.is_empty() {
            return Err("Task ID cannot be empty".to_string());
        }

        if id.len() > 100 {
            return Err("Task ID too long (max 100 characters)".to_string());
        }

        let valid_chars = id
            .chars()
            .all(|c| c.is_ascii_alphanumeric() || c == '-' || c == '_');

        if !valid_chars {
            return Err(
                "Task ID can only contain alphanumeric characters, hyphens, and underscores"
                    .to_string(),
            );
        }

        Ok(())
    }

    /// Validate title - must not be empty and within length limit
    pub fn validate_title(title: &str) -> Result<(), String> {
        if title.trim().is_empty() {
            return Err("Task title cannot be empty".to_string());
        }

        if title.len() > Self::MAX_TITLE_LENGTH {
            return Err(format!(
                "Task title too long (max {} characters)",
                Self::MAX_TITLE_LENGTH
            ));
        }

        Ok(())
    }

    /// Validate description - within length limit
    pub fn validate_description(description: &str) -> Result<(), String> {
        if description.len() > Self::MAX_DESCRIPTION_LENGTH {
            return Err(format!(
                "Task description too long (max {} characters)",
                Self::MAX_DESCRIPTION_LENGTH
            ));
        }

        Ok(())
    }

    /// Validate complexity - must be a Fibonacci number
    pub fn validate_complexity(complexity: u32) -> Result<(), String> {
        if !Self::VALID_FIBONACCI_NUMBERS.contains(&complexity) {
            return Err(format!(
                "Complexity must be a Fibonacci number: {:?}",
                Self::VALID_FIBONACCI_NUMBERS
            ));
        }

        Ok(())
    }

    /// Sanitize text by removing potentially dangerous HTML/script tags
    pub fn sanitize_text(text: &str) -> String {
        text.replace('<', "&lt;")
            .replace('>', "&gt;")
            .replace('"', "&quot;")
            .replace('\'', "&#x27;")
    }

    /// Comprehensive validation of all task fields
    pub fn validate(&self) -> Result<(), Vec<String>> {
        let mut errors = Vec::new();

        if let Err(e) = Self::validate_id(&self.id) {
            errors.push(e);
        }

        if let Err(e) = Self::validate_title(&self.title) {
            errors.push(e);
        }

        if let Err(e) = Self::validate_description(&self.description) {
            errors.push(e);
        }

        if self.complexity > 0 {
            if let Err(e) = Self::validate_complexity(self.complexity) {
                errors.push(e);
            }
        }

        if errors.is_empty() {
            Ok(())
        } else {
            Err(errors)
        }
    }

    pub fn set_status(&mut self, status: TaskStatus) {
        self.status = status;
        self.updated_at = Some(chrono::Utc::now().to_rfc3339());
    }

    pub fn update(&mut self) {
        self.updated_at = Some(chrono::Utc::now().to_rfc3339());
    }

    pub fn has_dependencies_met(&self, all_tasks: &[Task]) -> bool {
        self.dependencies.iter().all(|dep_id| {
            all_tasks
                .iter()
                .find(|t| &t.id == dep_id)
                .map(|t| t.status == TaskStatus::Done)
                .unwrap_or(false)
        })
    }

    pub fn needs_expansion(&self) -> bool {
        self.complexity > 13
    }

    // Assignment and locking methods
    pub fn assign(&mut self, assignee: &str) {
        self.assigned_to = Some(assignee.to_string());
        self.update();
    }

    pub fn claim(&mut self, assignee: &str) -> Result<(), String> {
        if let Some(ref locked_by) = self.locked_by {
            if locked_by != assignee {
                return Err(format!("Task is locked by {}", locked_by));
            }
        }

        self.assigned_to = Some(assignee.to_string());
        self.locked_by = Some(assignee.to_string());
        self.locked_at = Some(chrono::Utc::now().to_rfc3339());
        self.update();
        Ok(())
    }

    pub fn release(&mut self) {
        self.locked_by = None;
        self.locked_at = None;
        self.update();
    }

    pub fn is_locked(&self) -> bool {
        self.locked_by.is_some()
    }

    pub fn is_locked_by(&self, assignee: &str) -> bool {
        self.locked_by
            .as_ref()
            .map(|s| s == assignee)
            .unwrap_or(false)
    }

    pub fn is_assigned_to(&self, assignee: &str) -> bool {
        self.assigned_to
            .as_ref()
            .map(|s| s == assignee)
            .unwrap_or(false)
    }

    pub fn lock_age_hours(&self) -> Option<f64> {
        self.locked_at.as_ref().and_then(|locked_at| {
            chrono::DateTime::parse_from_rfc3339(locked_at)
                .ok()
                .map(|dt| {
                    let now = chrono::Utc::now();
                    let duration = now.signed_duration_since(dt);
                    duration.num_seconds() as f64 / 3600.0
                })
        })
    }

    pub fn is_stale_lock(&self, hours_threshold: f64) -> bool {
        self.lock_age_hours()
            .map(|hours| hours > hours_threshold)
            .unwrap_or(false)
    }

    /// Check if adding a dependency would create a circular reference
    /// Returns Err with the cycle path if circular dependency detected
    pub fn would_create_cycle(&self, new_dep_id: &str, all_tasks: &[Task]) -> Result<(), String> {
        if self.id == new_dep_id {
            return Err(format!("Self-reference: {} -> {}", self.id, new_dep_id));
        }

        let mut visited = std::collections::HashSet::new();
        let mut path = Vec::new();

        Self::detect_cycle_recursive(new_dep_id, &self.id, all_tasks, &mut visited, &mut path)
    }

    fn detect_cycle_recursive(
        current_id: &str,
        target_id: &str,
        all_tasks: &[Task],
        visited: &mut std::collections::HashSet<String>,
        path: &mut Vec<String>,
    ) -> Result<(), String> {
        if current_id == target_id {
            path.push(current_id.to_string());
            return Err(format!("Circular dependency: {}", path.join(" -> ")));
        }

        if visited.contains(current_id) {
            return Ok(());
        }

        visited.insert(current_id.to_string());
        path.push(current_id.to_string());

        if let Some(task) = all_tasks.iter().find(|t| t.id == current_id) {
            for dep_id in &task.dependencies {
                Self::detect_cycle_recursive(dep_id, target_id, all_tasks, visited, path)?;
            }
        }

        path.pop();
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_task_creation() {
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );

        assert_eq!(task.id, "TASK-1");
        assert_eq!(task.title, "Test Task");
        assert_eq!(task.description, "Description");
        assert_eq!(task.status, TaskStatus::Pending);
        assert_eq!(task.complexity, 0);
        assert_eq!(task.priority, Priority::Medium);
        assert!(task.dependencies.is_empty());
        assert!(task.created_at.is_some());
        assert!(task.updated_at.is_some());
        assert!(task.assigned_to.is_none());
        assert!(task.locked_by.is_none());
        assert!(task.locked_at.is_none());
    }

    #[test]
    fn test_status_conversion() {
        assert_eq!(TaskStatus::Pending.as_str(), "pending");
        assert_eq!(TaskStatus::InProgress.as_str(), "in-progress");
        assert_eq!(TaskStatus::Done.as_str(), "done");
        assert_eq!(TaskStatus::Review.as_str(), "review");
        assert_eq!(TaskStatus::Blocked.as_str(), "blocked");
        assert_eq!(TaskStatus::Deferred.as_str(), "deferred");
        assert_eq!(TaskStatus::Cancelled.as_str(), "cancelled");
    }

    #[test]
    fn test_status_from_string() {
        assert_eq!(TaskStatus::from_str("pending"), Some(TaskStatus::Pending));
        assert_eq!(
            TaskStatus::from_str("in-progress"),
            Some(TaskStatus::InProgress)
        );
        assert_eq!(TaskStatus::from_str("done"), Some(TaskStatus::Done));
        assert_eq!(TaskStatus::from_str("invalid"), None);
    }

    #[test]
    fn test_set_status_updates_timestamp() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());
        let initial_updated = task.updated_at.clone();

        std::thread::sleep(std::time::Duration::from_millis(10));
        task.set_status(TaskStatus::InProgress);

        assert_eq!(task.status, TaskStatus::InProgress);
        assert!(task.updated_at > initial_updated);
    }

    #[test]
    fn test_task_assignment() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.assign("alice");
        assert_eq!(task.assigned_to, Some("alice".to_string()));
        assert!(task.is_assigned_to("alice"));
        assert!(!task.is_assigned_to("bob"));
    }

    #[test]
    fn test_task_claim_success() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        let result = task.claim("alice");
        assert!(result.is_ok());
        assert_eq!(task.assigned_to, Some("alice".to_string()));
        assert_eq!(task.locked_by, Some("alice".to_string()));
        assert!(task.locked_at.is_some());
        assert!(task.is_locked());
        assert!(task.is_locked_by("alice"));
    }

    #[test]
    fn test_task_claim_already_locked_by_same_user() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.claim("alice").unwrap();
        let result = task.claim("alice");
        assert!(result.is_ok()); // Same user can re-claim
    }

    #[test]
    fn test_task_claim_already_locked_by_different_user() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.claim("alice").unwrap();
        let result = task.claim("bob");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err(), "Task is locked by alice");
    }

    #[test]
    fn test_task_release() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.claim("alice").unwrap();
        assert!(task.is_locked());

        task.release();
        assert!(!task.is_locked());
        assert_eq!(task.locked_by, None);
        assert_eq!(task.locked_at, None);
        assert_eq!(task.assigned_to, Some("alice".to_string())); // Assignment persists
    }

    #[test]
    fn test_lock_age_calculation() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.claim("alice").unwrap();

        let age = task.lock_age_hours();
        assert!(age.is_some());
        assert!(age.unwrap() < 0.001); // Should be very recent (< 1 minute)
    }

    #[test]
    fn test_stale_lock_detection() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.claim("alice").unwrap();

        // Not stale immediately
        assert!(!task.is_stale_lock(24.0));

        // Simulate old lock by setting locked_at to 48 hours ago
        let two_days_ago = chrono::Utc::now() - chrono::Duration::hours(48);
        task.locked_at = Some(two_days_ago.to_rfc3339());

        assert!(task.is_stale_lock(24.0));
        assert!(!task.is_stale_lock(72.0));
    }

    #[test]
    fn test_has_dependencies_met_all_done() {
        let mut task = Task::new("TASK-3".to_string(), "Test".to_string(), "Desc".to_string());
        task.dependencies = vec!["TASK-1".to_string(), "TASK-2".to_string()];

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Dep 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Dep 2".to_string(),
            "Desc".to_string(),
        );
        task2.set_status(TaskStatus::Done);

        let all_tasks = vec![task1, task2];
        assert!(task.has_dependencies_met(&all_tasks));
    }

    #[test]
    fn test_has_dependencies_met_some_pending() {
        let mut task = Task::new("TASK-3".to_string(), "Test".to_string(), "Desc".to_string());
        task.dependencies = vec!["TASK-1".to_string(), "TASK-2".to_string()];

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Dep 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let task2 = Task::new(
            "TASK-2".to_string(),
            "Dep 2".to_string(),
            "Desc".to_string(),
        );
        // task2 is pending

        let all_tasks = vec![task1, task2];
        assert!(!task.has_dependencies_met(&all_tasks));
    }

    #[test]
    fn test_has_dependencies_met_missing_dependency() {
        let mut task = Task::new("TASK-3".to_string(), "Test".to_string(), "Desc".to_string());
        task.dependencies = vec!["TASK-1".to_string(), "TASK-MISSING".to_string()];

        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Dep 1".to_string(),
            "Desc".to_string(),
        );
        task1.set_status(TaskStatus::Done);

        let all_tasks = vec![task1];
        assert!(!task.has_dependencies_met(&all_tasks));
    }

    #[test]
    fn test_needs_expansion() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());

        task.complexity = 8;
        assert!(!task.needs_expansion());

        task.complexity = 13;
        assert!(!task.needs_expansion());

        task.complexity = 21;
        assert!(task.needs_expansion());
    }

    #[test]
    fn test_task_serialization() {
        let task = Task::new(
            "TASK-1".to_string(),
            "Test Task".to_string(),
            "Description".to_string(),
        );

        let json = serde_json::to_string(&task).unwrap();
        let deserialized: Task = serde_json::from_str(&json).unwrap();

        assert_eq!(task.id, deserialized.id);
        assert_eq!(task.title, deserialized.title);
        assert_eq!(task.description, deserialized.description);
    }

    #[test]
    fn test_task_serialization_with_optional_fields() {
        let mut task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());
        task.details = Some("Detailed info".to_string());
        task.test_strategy = Some("Test plan".to_string());
        task.claim("alice").unwrap();

        let json = serde_json::to_string(&task).unwrap();
        let deserialized: Task = serde_json::from_str(&json).unwrap();

        assert_eq!(task.details, deserialized.details);
        assert_eq!(task.test_strategy, deserialized.test_strategy);
        assert_eq!(task.locked_by, deserialized.locked_by);
        assert_eq!(task.locked_at, deserialized.locked_at);
    }

    #[test]
    fn test_priority_default() {
        let default_priority = Priority::default();
        assert_eq!(default_priority, Priority::Medium);
    }

    #[test]
    fn test_status_all() {
        let all_statuses = TaskStatus::all();
        assert_eq!(all_statuses.len(), 7);
        assert!(all_statuses.contains(&"pending"));
        assert!(all_statuses.contains(&"in-progress"));
        assert!(all_statuses.contains(&"done"));
        assert!(all_statuses.contains(&"review"));
        assert!(all_statuses.contains(&"blocked"));
        assert!(all_statuses.contains(&"deferred"));
        assert!(all_statuses.contains(&"cancelled"));
    }

    #[test]
    fn test_circular_dependency_self_reference() {
        let task = Task::new("TASK-1".to_string(), "Test".to_string(), "Desc".to_string());
        let all_tasks = vec![task.clone()];

        let result = task.would_create_cycle("TASK-1", &all_tasks);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Self-reference"));
    }

    #[test]
    fn test_circular_dependency_direct_cycle() {
        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.dependencies = vec!["TASK-2".to_string()];

        let task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );

        let all_tasks = vec![task1.clone(), task2.clone()];

        // Trying to add TASK-1 as dependency of TASK-2 would create cycle: TASK-2 -> TASK-1 -> TASK-2
        let result = task2.would_create_cycle("TASK-1", &all_tasks);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Circular dependency"));
    }

    #[test]
    fn test_circular_dependency_indirect_cycle() {
        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.dependencies = vec!["TASK-2".to_string()];

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        task2.dependencies = vec!["TASK-3".to_string()];

        let task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );

        let all_tasks = vec![task1.clone(), task2, task3.clone()];

        // Trying to add TASK-1 as dependency of TASK-3 would create cycle:
        // TASK-3 -> TASK-1 -> TASK-2 -> TASK-3
        let result = task3.would_create_cycle("TASK-1", &all_tasks);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Circular dependency"));
    }

    #[test]
    fn test_circular_dependency_no_cycle() {
        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.dependencies = vec!["TASK-3".to_string()];

        let task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );

        let task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );

        let all_tasks = vec![task1.clone(), task2.clone(), task3];

        // Adding TASK-2 as dependency of TASK-1 is fine (no cycle)
        let result = task1.would_create_cycle("TASK-2", &all_tasks);
        assert!(result.is_ok());
    }

    #[test]
    fn test_circular_dependency_complex_graph() {
        let mut task1 = Task::new(
            "TASK-1".to_string(),
            "Task 1".to_string(),
            "Desc".to_string(),
        );
        task1.dependencies = vec!["TASK-2".to_string(), "TASK-3".to_string()];

        let mut task2 = Task::new(
            "TASK-2".to_string(),
            "Task 2".to_string(),
            "Desc".to_string(),
        );
        task2.dependencies = vec!["TASK-4".to_string()];

        let mut task3 = Task::new(
            "TASK-3".to_string(),
            "Task 3".to_string(),
            "Desc".to_string(),
        );
        task3.dependencies = vec!["TASK-4".to_string()];

        let task4 = Task::new(
            "TASK-4".to_string(),
            "Task 4".to_string(),
            "Desc".to_string(),
        );

        let all_tasks = vec![task1.clone(), task2, task3, task4.clone()];

        // Adding TASK-1 as dependency of TASK-4 would create a cycle
        let result = task4.would_create_cycle("TASK-1", &all_tasks);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Circular dependency"));
    }

    // Validation tests
    #[test]
    fn test_validate_id_success() {
        assert!(Task::validate_id("TASK-123").is_ok());
        assert!(Task::validate_id("task_456").is_ok());
        assert!(Task::validate_id("Feature-789").is_ok());
    }

    #[test]
    fn test_validate_id_empty() {
        let result = Task::validate_id("");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err(), "Task ID cannot be empty");
    }

    #[test]
    fn test_validate_id_too_long() {
        let long_id = "A".repeat(101);
        let result = Task::validate_id(&long_id);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("too long"));
    }

    #[test]
    fn test_validate_id_invalid_characters() {
        assert!(Task::validate_id("TASK@123").is_err());
        assert!(Task::validate_id("TASK 123").is_err());
        assert!(Task::validate_id("TASK#123").is_err());
        assert!(Task::validate_id("TASK.123").is_err());
    }

    #[test]
    fn test_validate_title_success() {
        assert!(Task::validate_title("Valid title").is_ok());
        assert!(Task::validate_title("A").is_ok());
    }

    #[test]
    fn test_validate_title_empty() {
        let result = Task::validate_title("");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err(), "Task title cannot be empty");

        let result = Task::validate_title("   ");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err(), "Task title cannot be empty");
    }

    #[test]
    fn test_validate_title_too_long() {
        let long_title = "A".repeat(201);
        let result = Task::validate_title(&long_title);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("too long"));
    }

    #[test]
    fn test_validate_description_success() {
        assert!(Task::validate_description("Valid description").is_ok());
        assert!(Task::validate_description("").is_ok());
    }

    #[test]
    fn test_validate_description_too_long() {
        let long_desc = "A".repeat(5001);
        let result = Task::validate_description(&long_desc);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("too long"));
    }

    #[test]
    fn test_validate_complexity_success() {
        assert!(Task::validate_complexity(0).is_ok());
        assert!(Task::validate_complexity(1).is_ok());
        assert!(Task::validate_complexity(2).is_ok());
        assert!(Task::validate_complexity(3).is_ok());
        assert!(Task::validate_complexity(5).is_ok());
        assert!(Task::validate_complexity(8).is_ok());
        assert!(Task::validate_complexity(13).is_ok());
        assert!(Task::validate_complexity(21).is_ok());
    }

    #[test]
    fn test_validate_complexity_invalid() {
        assert!(Task::validate_complexity(4).is_err());
        assert!(Task::validate_complexity(6).is_err());
        assert!(Task::validate_complexity(7).is_err());
        assert!(Task::validate_complexity(100).is_err());
    }

    #[test]
    fn test_sanitize_text() {
        assert_eq!(
            Task::sanitize_text("<script>alert('xss')</script>"),
            "&lt;script&gt;alert(&#x27;xss&#x27;)&lt;/script&gt;"
        );
        assert_eq!(
            Task::sanitize_text("Normal text"),
            "Normal text"
        );
        assert_eq!(
            Task::sanitize_text("<div>Content</div>"),
            "&lt;div&gt;Content&lt;/div&gt;"
        );
    }

    #[test]
    fn test_validate_success() {
        let task = Task::new(
            "TASK-1".to_string(),
            "Valid title".to_string(),
            "Valid description".to_string(),
        );
        assert!(task.validate().is_ok());
    }

    #[test]
    fn test_validate_multiple_errors() {
        let mut task = Task::new(
            "TASK@INVALID".to_string(),
            "".to_string(),
            "A".repeat(5001),
        );
        task.complexity = 100; // Invalid Fibonacci number

        let result = task.validate();
        assert!(result.is_err());
        let errors = result.unwrap_err();
        assert_eq!(errors.len(), 4);
        assert!(errors.iter().any(|e| e.contains("ID")));
        assert!(errors.iter().any(|e| e.contains("title")));
        assert!(errors.iter().any(|e| e.contains("description")));
        assert!(errors.iter().any(|e| e.contains("Complexity")));
    }
}
</file>

<file path="scud-cli/src/main.rs">
use anyhow::Result;
use clap::{Parser, Subcommand};
use scud::commands;
use std::path::PathBuf;

#[derive(Parser)]
#[command(name = "scud")]
#[command(about = "Fast, simple task master for AI-driven development", long_about = None)]
#[command(version)]
struct Cli {
    #[command(subcommand)]
    command: Commands,

    /// Project root directory
    #[arg(short, long, global = true)]
    project: Option<PathBuf>,
}

#[derive(Subcommand)]
enum Commands {
    /// Initialize SCUD in current directory
    Init,

    /// List all epic tags
    Tags,

    /// Set active epic tag
    UseTag {
        /// Epic tag to activate
        tag: String,
    },

    /// List tasks in active epic
    List {
        /// Filter by status
        #[arg(short, long)]
        status: Option<String>,
    },

    /// Show detailed task information
    Show {
        /// Task ID
        task_id: String,
    },

    /// Update task status
    SetStatus {
        /// Task ID
        task_id: String,
        /// New status
        status: String,
    },

    /// Find next available task
    Next,

    /// Show epic statistics
    Stats,

    /// Parse PRD/epic markdown into tasks (AI-powered)
    ParsePrd {
        /// Path to PRD/epic markdown file
        file: PathBuf,

        /// Epic tag to create
        #[arg(short, long)]
        tag: String,
    },

    /// Analyze task complexity (AI-powered)
    AnalyzeComplexity {
        /// Specific task ID (analyzes all if not provided)
        #[arg(short, long)]
        task: Option<String>,
    },

    /// Expand complex task into subtasks (AI-powered)
    Expand {
        /// Task ID to expand
        task_id: Option<String>,

        /// Expand all tasks with complexity > 13
        #[arg(short, long)]
        all: bool,
    },

    /// Research a topic using web search (AI-powered)
    Research {
        /// Research query
        query: String,
    },

    // Epic Group commands
    /// Create a new epic group
    CreateGroup {
        /// Group name
        name: String,

        /// Comma-separated list of epic tags
        #[arg(short, long)]
        epics: String,

        /// Optional description
        #[arg(short, long)]
        description: Option<String>,
    },

    /// List all epic groups
    ListGroups,

    /// Show group status and aggregated stats
    GroupStatus {
        /// Group ID
        group_id: String,
    },

    /// Add epic to a group
    AddToGroup {
        /// Group ID
        group_id: String,

        /// Epic tag to add
        epic_tag: String,
    },

    // Task Assignment commands
    /// Assign task to a developer
    Assign {
        /// Task ID
        task_id: String,

        /// Assignee name
        assignee: String,
    },

    /// Claim a task for yourself
    Claim {
        /// Task ID
        task_id: String,

        /// Your name/identifier
        #[arg(short, long)]
        name: String,
    },

    /// Release task assignment/lock
    Release {
        /// Task ID
        task_id: String,

        /// Force release even if locked by someone else
        #[arg(short, long)]
        force: bool,
    },

    /// Show who is working on what
    WhoIs,
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Init => commands::init::run(cli.project),
        Commands::Tags => commands::tags::run(cli.project),
        Commands::UseTag { tag } => commands::use_tag::run(cli.project, &tag),
        Commands::List { status } => commands::list::run(cli.project, status.as_deref()),
        Commands::Show { task_id } => commands::show::run(cli.project, &task_id),
        Commands::SetStatus { task_id, status } => {
            commands::set_status::run(cli.project, &task_id, &status)
        }
        Commands::Next => commands::next::run(cli.project),
        Commands::Stats => commands::stats::run(cli.project),
        Commands::ParsePrd { file, tag } => {
            commands::ai::parse_prd::run(cli.project, &file, &tag).await
        }
        Commands::AnalyzeComplexity { task } => {
            commands::ai::analyze_complexity::run(cli.project, task.as_deref()).await
        }
        Commands::Expand { task_id, all } => {
            commands::ai::expand::run(cli.project, task_id.as_deref(), all).await
        }
        Commands::Research { query } => commands::ai::research::run(cli.project, &query).await,
        Commands::CreateGroup {
            name,
            epics,
            description,
        } => commands::create_group::run(cli.project, &name, &epics, description.as_deref()),
        Commands::ListGroups => commands::list_groups::run(cli.project),
        Commands::GroupStatus { group_id } => commands::group_status::run(cli.project, &group_id),
        Commands::AddToGroup { group_id, epic_tag } => {
            commands::add_to_group::run(cli.project, &group_id, &epic_tag)
        }
        Commands::Assign { task_id, assignee } => {
            commands::assign::run(cli.project, &task_id, &assignee)
        }
        Commands::Claim { task_id, name } => commands::claim::run(cli.project, &task_id, &name),
        Commands::Release { task_id, force } => {
            commands::release::run(cli.project, &task_id, force)
        }
        Commands::WhoIs => commands::whois::run(cli.project),
    }
}
</file>

<file path=".gitignore">
# Rust build artifacts
scud-cli/target/

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
package-lock.json

# SCUD task management (user data)
.taskmaster/
docs/prd/
docs/epics/
docs/architecture/
docs/retrospectives/

# Editor files
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# Temporary files
*.tmp
*.log

# Coverage reports
coverage/
</file>

<file path="scud-cli/src/storage/mod.rs">
use anyhow::{Context, Result};
use fs2::FileExt;
use std::collections::HashMap;
use std::fs::{self, File, OpenOptions};
use std::path::{Path, PathBuf};
use std::sync::RwLock;
use std::thread;
use std::time::Duration;

use crate::models::{Epic, WorkflowState};

pub struct Storage {
    project_root: PathBuf,
    /// Cache for active epic to avoid repeated workflow state loads
    /// Option<Option<String>> represents: None = not cached, Some(None) = no active epic, Some(Some(tag)) = cached tag
    /// Uses RwLock for thread safety (useful for tests and potential daemon mode)
    active_epic_cache: RwLock<Option<Option<String>>>,
}

impl Storage {
    pub fn new(project_root: Option<PathBuf>) -> Self {
        let root = project_root.unwrap_or_else(|| std::env::current_dir().unwrap());
        Storage {
            project_root: root,
            active_epic_cache: RwLock::new(None),
        }
    }

    /// Acquire an exclusive file lock with retry logic
    fn acquire_lock_with_retry(&self, file: &File, max_retries: u32) -> Result<()> {
        let mut retries = 0;
        let mut delay_ms = 10;

        loop {
            match file.try_lock_exclusive() {
                Ok(_) => return Ok(()),
                Err(_) if retries < max_retries => {
                    retries += 1;
                    thread::sleep(Duration::from_millis(delay_ms));
                    delay_ms = (delay_ms * 2).min(1000); // Exponential backoff, max 1s
                }
                Err(e) => {
                    anyhow::bail!(
                        "Failed to acquire file lock after {} retries: {}",
                        max_retries,
                        e
                    )
                }
            }
        }
    }

    /// Perform a locked write operation on a file
    fn write_with_lock<F>(&self, path: &Path, writer: F) -> Result<()>
    where
        F: FnOnce() -> Result<String>,
    {
        let dir = path.parent().unwrap();
        if !dir.exists() {
            fs::create_dir_all(dir)?;
        }

        // Open file for writing
        let file = OpenOptions::new()
            .write(true)
            .create(true)
            .truncate(true)
            .open(path)
            .with_context(|| format!("Failed to open file for writing: {}", path.display()))?;

        // Acquire lock with retry
        self.acquire_lock_with_retry(&file, 10)?;

        // Generate content and write
        let content = writer()?;
        fs::write(path, content)
            .with_context(|| format!("Failed to write to {}", path.display()))?;

        // Lock is automatically released when file is dropped
        Ok(())
    }

    /// Perform a locked read operation on a file
    fn read_with_lock(&self, path: &Path) -> Result<String> {
        if !path.exists() {
            anyhow::bail!("File not found: {}", path.display());
        }

        // Open file for reading
        let file = OpenOptions::new()
            .read(true)
            .open(path)
            .with_context(|| format!("Failed to open file for reading: {}", path.display()))?;

        // Acquire shared lock (allows multiple readers)
        file.lock_shared()
            .with_context(|| format!("Failed to acquire read lock on {}", path.display()))?;

        // Read content
        let content = fs::read_to_string(path)
            .with_context(|| format!("Failed to read from {}", path.display()))?;

        // Lock is automatically released when file is dropped
        Ok(content)
    }

    pub fn taskmaster_dir(&self) -> PathBuf {
        self.project_root.join(".taskmaster")
    }

    pub fn tasks_file(&self) -> PathBuf {
        self.taskmaster_dir().join("tasks").join("tasks.json")
    }

    pub fn workflow_file(&self) -> PathBuf {
        self.taskmaster_dir().join("workflow-state.json")
    }

    pub fn docs_dir(&self) -> PathBuf {
        self.project_root.join("docs")
    }

    pub fn is_initialized(&self) -> bool {
        self.taskmaster_dir().exists()
            && self.tasks_file().exists()
            && self.workflow_file().exists()
    }

    pub fn initialize(&self) -> Result<()> {
        // Create .taskmaster directory structure
        let taskmaster = self.taskmaster_dir();
        fs::create_dir_all(taskmaster.join("tasks"))
            .context("Failed to create .taskmaster/tasks directory")?;

        // Initialize tasks.json with empty object
        let tasks_file = self.tasks_file();
        if !tasks_file.exists() {
            let empty_tasks: HashMap<String, Epic> = HashMap::new();
            self.save_tasks(&empty_tasks)?;
        }

        // Initialize workflow-state.json
        let workflow_file = self.workflow_file();
        if !workflow_file.exists() {
            let workflow_state = WorkflowState::new();
            self.save_workflow_state(&workflow_state)?;
        }

        // Create docs directories
        let docs = self.docs_dir();
        fs::create_dir_all(docs.join("prd"))?;
        fs::create_dir_all(docs.join("epics"))?;
        fs::create_dir_all(docs.join("architecture"))?;
        fs::create_dir_all(docs.join("retrospectives"))?;

        // Update .gitignore
        self.update_gitignore()?;

        Ok(())
    }

    fn update_gitignore(&self) -> Result<()> {
        let gitignore_path = self.project_root.join(".gitignore");
        let entry = "\n# SCUD Task Master\n.taskmaster/\n";

        if gitignore_path.exists() {
            let content = fs::read_to_string(&gitignore_path)?;
            if !content.contains(".taskmaster/") {
                fs::write(&gitignore_path, format!("{}{}", content, entry))?;
            }
        } else {
            fs::write(&gitignore_path, entry)?;
        }

        Ok(())
    }

    pub fn load_tasks(&self) -> Result<HashMap<String, Epic>> {
        let path = self.tasks_file();
        if !path.exists() {
            anyhow::bail!("Tasks file not found: {}\nRun: scud init", path.display());
        }

        let content = self.read_with_lock(&path)?;
        let tasks: HashMap<String, Epic> = serde_json::from_str(&content)
            .with_context(|| "Failed to parse tasks.json".to_string())?;

        Ok(tasks)
    }

    pub fn save_tasks(&self, tasks: &HashMap<String, Epic>) -> Result<()> {
        let path = self.tasks_file();
        self.write_with_lock(&path, || {
            serde_json::to_string_pretty(tasks)
                .with_context(|| "Failed to serialize tasks to JSON".to_string())
        })
    }

    pub fn load_workflow_state(&self) -> Result<WorkflowState> {
        let path = self.workflow_file();
        if !path.exists() {
            anyhow::bail!(
                "Workflow state not found: {}\nRun: scud init",
                path.display()
            );
        }

        let content = self.read_with_lock(&path)?;
        let state: WorkflowState = serde_json::from_str(&content)
            .with_context(|| "Failed to parse workflow-state.json".to_string())?;

        Ok(state)
    }

    pub fn save_workflow_state(&self, state: &WorkflowState) -> Result<()> {
        let path = self.workflow_file();
        self.write_with_lock(&path, || {
            serde_json::to_string_pretty(state)
                .with_context(|| "Failed to serialize workflow state to JSON".to_string())
        })
    }

    pub fn get_active_epic(&self) -> Result<Option<String>> {
        // Check cache first (read lock)
        {
            let cache = self.active_epic_cache.read().unwrap();
            if let Some(cached) = cache.as_ref() {
                return Ok(cached.clone());
            }
        }

        // Load from file and cache (write lock)
        let state = self.load_workflow_state()?;
        let active = state.active_epic.clone();

        // Store in cache
        *self.active_epic_cache.write().unwrap() = Some(active.clone());

        Ok(active)
    }

    pub fn set_active_epic(&self, epic_tag: &str) -> Result<()> {
        let tasks = self.load_tasks()?;
        if !tasks.contains_key(epic_tag) {
            anyhow::bail!("Epic '{}' not found", epic_tag);
        }

        let mut state = self.load_workflow_state()?;
        state.active_epic = Some(epic_tag.to_string());
        state.update();
        self.save_workflow_state(&state)?;

        // Update cache
        *self.active_epic_cache.write().unwrap() = Some(Some(epic_tag.to_string()));

        Ok(())
    }

    /// Clear the active epic cache
    /// Useful when workflow state is modified externally or for testing
    pub fn clear_cache(&self) {
        *self.active_epic_cache.write().unwrap() = None;
    }

    /// Load a single epic by tag without deserializing all epics
    /// More efficient than load_tasks() when only one epic is needed
    pub fn load_epic(&self, epic_tag: &str) -> Result<Epic> {
        let path = self.tasks_file();
        let content = self.read_with_lock(&path)?;

        // Parse as generic JSON value for targeted extraction
        let value: serde_json::Value = serde_json::from_str(&content)
            .with_context(|| "Failed to parse tasks.json")?;

        // Extract specific epic
        if let Some(epic_value) = value.get(epic_tag) {
            let epic: Epic = serde_json::from_value(epic_value.clone())
                .with_context(|| format!("Failed to deserialize epic '{}'", epic_tag))?;
            Ok(epic)
        } else {
            anyhow::bail!("Epic '{}' not found", epic_tag)
        }
    }

    /// Load the active epic directly (optimized)
    /// Combines get_active_epic() and load_epic() in one call
    pub fn load_active_epic(&self) -> Result<Epic> {
        let active_tag = self
            .get_active_epic()?
            .ok_or_else(|| anyhow::anyhow!("No active epic. Run: scud use-tag <epic-tag>"))?;

        self.load_epic(&active_tag)
    }

    /// Update a single epic without loading/saving all epics
    /// More efficient than load_tasks() + save_tasks() for single epic updates
    pub fn update_epic(&self, epic_tag: &str, epic: &Epic) -> Result<()> {
        let path = self.tasks_file();

        // Read current content first (before write lock)
        let content = self.read_with_lock(&path)?;

        self.write_with_lock(&path, || {
            let mut value: serde_json::Value = serde_json::from_str(&content)?;

            // Update specific epic
            if let Some(obj) = value.as_object_mut() {
                obj.insert(epic_tag.to_string(), serde_json::to_value(epic)?);
            }

            serde_json::to_string_pretty(&value)
                .with_context(|| "Failed to serialize tasks to JSON")
        })
    }

    pub fn read_file(&self, path: &Path) -> Result<String> {
        fs::read_to_string(path).with_context(|| format!("Failed to read file: {}", path.display()))
    }

    // Epic Groups management
    pub fn groups_file(&self) -> PathBuf {
        self.taskmaster_dir().join("epic-groups.json")
    }

    pub fn load_groups(&self) -> Result<crate::models::EpicGroups> {
        let path = self.groups_file();
        if !path.exists() {
            return Ok(crate::models::EpicGroups::new());
        }

        let content = self.read_with_lock(&path)?;
        let groups: crate::models::EpicGroups = serde_json::from_str(&content)
            .with_context(|| "Failed to parse epic-groups.json".to_string())?;

        Ok(groups)
    }

    pub fn save_groups(&self, groups: &crate::models::EpicGroups) -> Result<()> {
        let path = self.groups_file();
        self.write_with_lock(&path, || {
            serde_json::to_string_pretty(groups)
                .with_context(|| "Failed to serialize groups to JSON".to_string())
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;
    use tempfile::TempDir;

    fn create_test_storage() -> (Storage, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let storage = Storage::new(Some(temp_dir.path().to_path_buf()));
        storage.initialize().unwrap();
        (storage, temp_dir)
    }

    #[test]
    fn test_write_with_lock_creates_file() {
        let (storage, _temp_dir) = create_test_storage();
        let test_file = storage.taskmaster_dir().join("test.json");

        storage
            .write_with_lock(&test_file, || Ok(r#"{"test": "data"}"#.to_string()))
            .unwrap();

        assert!(test_file.exists());
        let content = fs::read_to_string(&test_file).unwrap();
        assert_eq!(content, r#"{"test": "data"}"#);
    }

    #[test]
    fn test_read_with_lock_reads_existing_file() {
        let (storage, _temp_dir) = create_test_storage();
        let test_file = storage.taskmaster_dir().join("test.json");

        // Create a file
        fs::write(&test_file, r#"{"test": "data"}"#).unwrap();

        // Read with lock
        let content = storage.read_with_lock(&test_file).unwrap();
        assert_eq!(content, r#"{"test": "data"}"#);
    }

    #[test]
    fn test_read_with_lock_fails_on_missing_file() {
        let (storage, _temp_dir) = create_test_storage();
        let test_file = storage.taskmaster_dir().join("nonexistent.json");

        let result = storage.read_with_lock(&test_file);
        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("File not found"));
    }

    #[test]
    fn test_save_and_load_tasks_with_locking() {
        let (storage, _temp_dir) = create_test_storage();
        let mut tasks = HashMap::new();

        let epic = crate::models::Epic::new("TEST-1".to_string());
        tasks.insert("TEST-1".to_string(), epic);

        // Save tasks
        storage.save_tasks(&tasks).unwrap();

        // Load tasks
        let loaded_tasks = storage.load_tasks().unwrap();

        assert_eq!(tasks.len(), loaded_tasks.len());
        assert!(loaded_tasks.contains_key("TEST-1"));
        assert_eq!(loaded_tasks.get("TEST-1").unwrap().name, "TEST-1");
    }

    #[test]
    fn test_save_and_load_workflow_state_with_locking() {
        let (storage, _temp_dir) = create_test_storage();

        let mut state = crate::models::WorkflowState::new();
        state.active_epic = Some("TEST-1".to_string());

        // Save state
        storage.save_workflow_state(&state).unwrap();

        // Load state
        let loaded_state = storage.load_workflow_state().unwrap();

        assert_eq!(loaded_state.active_epic, Some("TEST-1".to_string()));
    }

    #[test]
    fn test_save_and_load_groups_with_locking() {
        let (storage, _temp_dir) = create_test_storage();

        let mut groups = crate::models::EpicGroups::new();
        let group = crate::models::EpicGroup::new(
            "group-1".to_string(),
            "Test Group".to_string(),
            vec!["epic-1".to_string()],
        );
        groups.add_group(group);

        // Save groups
        storage.save_groups(&groups).unwrap();

        // Load groups
        let loaded_groups = storage.load_groups().unwrap();

        assert!(loaded_groups.get_group("group-1").is_some());
    }

    #[test]
    fn test_concurrent_writes_dont_corrupt_data() {
        use std::sync::Arc;
        use std::thread;

        let (storage, _temp_dir) = create_test_storage();
        let storage = Arc::new(storage);
        let mut handles = vec![];

        // Spawn 10 threads that each write tasks
        for i in 0..10 {
            let storage_clone = Arc::clone(&storage);
            let handle = thread::spawn(move || {
                let mut tasks = HashMap::new();
                let epic = crate::models::Epic::new(format!("EPIC-{}", i));
                tasks.insert(format!("EPIC-{}", i), epic);

                // Each thread writes multiple times
                for _ in 0..5 {
                    storage_clone.save_tasks(&tasks).unwrap();
                    thread::sleep(Duration::from_millis(1));
                }
            });
            handles.push(handle);
        }

        // Wait for all threads to complete
        for handle in handles {
            handle.join().unwrap();
        }

        // Verify that the file is still valid JSON
        let tasks = storage.load_tasks().unwrap();
        // Should have the last written data (from one of the threads)
        assert_eq!(tasks.len(), 1);
    }

    #[test]
    fn test_lock_retry_on_contention() {
        use std::sync::Arc;

        let (storage, _temp_dir) = create_test_storage();
        let storage = Arc::new(storage);
        let test_file = storage.taskmaster_dir().join("lock-test.json");

        // Create file
        storage
            .write_with_lock(&test_file, || Ok(r#"{"initial": "data"}"#.to_string()))
            .unwrap();

        // Open and lock the file
        let file = OpenOptions::new()
            .write(true)
            .open(&test_file)
            .unwrap();
        file.lock_exclusive().unwrap();

        // Try to acquire lock with retry in another thread
        let storage_clone = Arc::clone(&storage);
        let test_file_clone = test_file.clone();
        let handle = thread::spawn(move || {
            // This should retry and succeed after lock release
            storage_clone.write_with_lock(&test_file_clone, || {
                Ok(r#"{"updated": "data"}"#.to_string())
            })
        });

        // Keep lock for a bit
        thread::sleep(Duration::from_millis(200));

        // Release lock
        file.unlock().unwrap();
        drop(file);

        // The write should have succeeded after retrying
        let result = handle.join().unwrap();
        assert!(result.is_ok());
    }

    // ==================== Error Handling Tests ====================

    #[test]
    fn test_load_tasks_with_malformed_json() {
        let (storage, _temp_dir) = create_test_storage();
        let tasks_file = storage.tasks_file();

        // Write malformed JSON
        fs::write(&tasks_file, r#"{"invalid": json here}"#).unwrap();

        // Should return error
        let result = storage.load_tasks();
        assert!(result.is_err());
    }

    #[test]
    fn test_load_workflow_state_with_malformed_json() {
        let (storage, _temp_dir) = create_test_storage();
        let workflow_file = storage.workflow_file();

        // Write malformed JSON
        fs::write(&workflow_file, r#"not valid json at all"#).unwrap();

        // Should return error
        let result = storage.load_workflow_state();
        assert!(result.is_err());
    }

    #[test]
    fn test_load_groups_with_malformed_json() {
        let (storage, _temp_dir) = create_test_storage();
        let groups_file = storage.groups_file();

        // Write malformed JSON
        fs::write(&groups_file, r#"{unclosed bracket"#).unwrap();

        // Should return error
        let result = storage.load_groups();
        assert!(result.is_err());
    }

    #[test]
    fn test_load_tasks_with_empty_file() {
        let (storage, _temp_dir) = create_test_storage();
        let tasks_file = storage.tasks_file();

        // Write empty file
        fs::write(&tasks_file, "").unwrap();

        // Should return error
        let result = storage.load_tasks();
        assert!(result.is_err());
    }

    #[test]
    fn test_load_tasks_missing_file_creates_default() {
        let (storage, _temp_dir) = create_test_storage();
        // Don't create tasks file

        // Should return empty HashMap (default)
        let tasks = storage.load_tasks().unwrap();
        assert_eq!(tasks.len(), 0);
    }

    #[test]
    fn test_load_workflow_state_missing_file_creates_default() {
        let (storage, _temp_dir) = create_test_storage();
        // Don't create workflow state file

        // Should return default WorkflowState
        let state = storage.load_workflow_state().unwrap();
        assert_eq!(state.current_phase, "ideation");
        assert_eq!(state.active_epic, None);
    }

    #[test]
    fn test_load_groups_missing_file_creates_default() {
        let (storage, _temp_dir) = create_test_storage();
        // Don't create groups file

        // Should return empty EpicGroups
        let groups = storage.load_groups().unwrap();
        assert_eq!(groups.groups.len(), 0);
    }

    #[test]
    fn test_save_tasks_creates_directory_if_missing() {
        let temp_dir = TempDir::new().unwrap();
        let storage = Storage::new(Some(temp_dir.path().to_path_buf()));
        // Don't call initialize()

        let mut tasks = HashMap::new();
        let epic = crate::models::Epic::new("TEST-1".to_string());
        tasks.insert("TEST-1".to_string(), epic);

        // Should create directory and file
        let result = storage.save_tasks(&tasks);
        assert!(result.is_ok());

        assert!(storage.taskmaster_dir().exists());
        assert!(storage.tasks_file().exists());
    }

    #[test]
    fn test_write_with_lock_handles_directory_creation() {
        let temp_dir = TempDir::new().unwrap();
        let storage = Storage::new(Some(temp_dir.path().to_path_buf()));

        let nested_file = temp_dir
            .path()
            .join("deeply")
            .join("nested")
            .join("test.json");

        // Should create all parent directories
        let result = storage.write_with_lock(&nested_file, || Ok("{}".to_string()));
        assert!(result.is_ok());
        assert!(nested_file.exists());
    }

    #[test]
    fn test_load_tasks_with_invalid_structure() {
        let (storage, _temp_dir) = create_test_storage();
        let tasks_file = storage.tasks_file();

        // Write valid JSON but invalid structure (array instead of object)
        fs::write(&tasks_file, r#"["not", "an", "object"]"#).unwrap();

        // Should return error
        let result = storage.load_tasks();
        assert!(result.is_err());
    }

    #[test]
    fn test_load_workflow_state_with_missing_fields() {
        let (storage, _temp_dir) = create_test_storage();
        let workflow_file = storage.workflow_file();

        // Write JSON with missing required fields
        fs::write(&workflow_file, r#"{"version": "1.0.0"}"#).unwrap();

        // Should return error (missing current_phase, etc.)
        let result = storage.load_workflow_state();
        assert!(result.is_err());
    }

    #[test]
    fn test_save_and_load_with_unicode_content() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();
        let mut epic = crate::models::Epic::new("TEST-UNICODE".to_string());

        // Add task with unicode content
        let task = crate::models::Task::new(
            "task-1".to_string(),
            "æµ‹è¯• Unicode ðŸš€".to_string(),
            "DescripciÃ³n en espaÃ±ol æ—¥æœ¬èªž".to_string(),
        );
        epic.add_task(task);

        tasks.insert("TEST-UNICODE".to_string(), epic);

        // Save and load
        storage.save_tasks(&tasks).unwrap();
        let loaded_tasks = storage.load_tasks().unwrap();

        let loaded_epic = loaded_tasks.get("TEST-UNICODE").unwrap();
        let loaded_task = loaded_epic.get_task("task-1").unwrap();
        assert_eq!(loaded_task.title, "æµ‹è¯• Unicode ðŸš€");
        assert_eq!(loaded_task.description, "DescripciÃ³n en espaÃ±ol æ—¥æœ¬èªž");
    }

    #[test]
    fn test_save_and_load_with_large_dataset() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();

        // Create 100 epics with 50 tasks each
        for i in 0..100 {
            let mut epic = crate::models::Epic::new(format!("EPIC-{}", i));

            for j in 0..50 {
                let task = crate::models::Task::new(
                    format!("task-{}-{}", i, j),
                    format!("Task {} of Epic {}", j, i),
                    format!("Description for task {}-{}", i, j),
                );
                epic.add_task(task);
            }

            tasks.insert(format!("EPIC-{}", i), epic);
        }

        // Save and load
        storage.save_tasks(&tasks).unwrap();
        let loaded_tasks = storage.load_tasks().unwrap();

        assert_eq!(loaded_tasks.len(), 100);
        for i in 0..100 {
            let epic = loaded_tasks.get(&format!("EPIC-{}", i)).unwrap();
            assert_eq!(epic.tasks.len(), 50);
        }
    }

    #[test]
    fn test_concurrent_read_and_write() {
        use std::sync::Arc;
        use std::thread;

        let (storage, _temp_dir) = create_test_storage();
        let storage = Arc::new(storage);

        // Initialize with some data
        let mut tasks = HashMap::new();
        let epic = crate::models::Epic::new("INITIAL".to_string());
        tasks.insert("INITIAL".to_string(), epic);
        storage.save_tasks(&tasks).unwrap();

        let mut handles = vec![];

        // Spawn 5 readers
        for _ in 0..5 {
            let storage_clone = Arc::clone(&storage);
            let handle = thread::spawn(move || {
                for _ in 0..10 {
                    let _ = storage_clone.load_tasks();
                    thread::sleep(Duration::from_millis(1));
                }
            });
            handles.push(handle);
        }

        // Spawn 2 writers
        for i in 0..2 {
            let storage_clone = Arc::clone(&storage);
            let handle = thread::spawn(move || {
                for j in 0..5 {
                    let mut tasks = HashMap::new();
                    let epic = crate::models::Epic::new(format!("WRITER-{}-{}", i, j));
                    tasks.insert(format!("WRITER-{}-{}", i, j), epic);
                    storage_clone.save_tasks(&tasks).unwrap();
                    thread::sleep(Duration::from_millis(2));
                }
            });
            handles.push(handle);
        }

        // Wait for all threads
        for handle in handles {
            handle.join().unwrap();
        }

        // File should still be valid
        let tasks = storage.load_tasks().unwrap();
        assert_eq!(tasks.len(), 1); // Last write wins
    }

    // ==================== Active Epic Cache Tests ====================

    #[test]
    fn test_active_epic_cached_on_second_call() {
        let (storage, _temp_dir) = create_test_storage();

        // Set active epic
        let mut tasks = HashMap::new();
        tasks.insert("TEST-1".to_string(), Epic::new("TEST-1".to_string()));
        storage.save_tasks(&tasks).unwrap();
        storage.set_active_epic("TEST-1").unwrap();

        // First call - loads from file
        let active1 = storage.get_active_epic().unwrap();
        assert_eq!(active1, Some("TEST-1".to_string()));

        // Modify file directly (bypass storage methods)
        let workflow_file = storage.workflow_file();
        let mut state = storage.load_workflow_state().unwrap();
        state.active_epic = Some("DIFFERENT".to_string());
        fs::write(
            &workflow_file,
            serde_json::to_string(&state).unwrap(),
        )
        .unwrap();

        // Second call - should return cached value (not file value)
        let active2 = storage.get_active_epic().unwrap();
        assert_eq!(active2, Some("TEST-1".to_string())); // Still cached

        // After cache clear - should reload from file
        storage.clear_cache();
        let active3 = storage.get_active_epic().unwrap();
        assert_eq!(active3, Some("DIFFERENT".to_string())); // From file
    }

    #[test]
    fn test_cache_invalidated_on_set_active_epic() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();
        tasks.insert("EPIC-1".to_string(), Epic::new("EPIC-1".to_string()));
        tasks.insert("EPIC-2".to_string(), Epic::new("EPIC-2".to_string()));
        storage.save_tasks(&tasks).unwrap();

        storage.set_active_epic("EPIC-1").unwrap();
        assert_eq!(
            storage.get_active_epic().unwrap(),
            Some("EPIC-1".to_string())
        );

        // Change active epic - should update cache
        storage.set_active_epic("EPIC-2").unwrap();
        assert_eq!(
            storage.get_active_epic().unwrap(),
            Some("EPIC-2".to_string())
        );
    }

    #[test]
    fn test_cache_with_no_active_epic() {
        let (storage, _temp_dir) = create_test_storage();

        // Load when no active epic is set
        let active = storage.get_active_epic().unwrap();
        assert_eq!(active, None);

        // Should cache the None value
        let active2 = storage.get_active_epic().unwrap();
        assert_eq!(active2, None);
    }

    // ==================== Lazy Epic Loading Tests ====================

    #[test]
    fn test_load_single_epic_from_many() {
        let (storage, _temp_dir) = create_test_storage();

        // Create 50 epics
        let mut tasks = HashMap::new();
        for i in 0..50 {
            tasks.insert(
                format!("EPIC-{}", i),
                Epic::new(format!("EPIC-{}", i)),
            );
        }
        storage.save_tasks(&tasks).unwrap();

        // Load single epic - should only deserialize that one
        let epic = storage.load_epic("EPIC-25").unwrap();
        assert_eq!(epic.name, "EPIC-25");
    }

    #[test]
    fn test_load_epic_not_found() {
        let (storage, _temp_dir) = create_test_storage();

        let tasks = HashMap::new();
        storage.save_tasks(&tasks).unwrap();

        let result = storage.load_epic("NONEXISTENT");
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("not found"));
    }

    #[test]
    fn test_load_epic_matches_full_load() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();
        let mut epic = Epic::new("TEST-1".to_string());
        epic.add_task(crate::models::Task::new(
            "task-1".to_string(),
            "Test".to_string(),
            "Desc".to_string(),
        ));
        tasks.insert("TEST-1".to_string(), epic.clone());
        storage.save_tasks(&tasks).unwrap();

        // Load via both methods
        let epic_lazy = storage.load_epic("TEST-1").unwrap();
        let tasks_full = storage.load_tasks().unwrap();
        let epic_full = tasks_full.get("TEST-1").unwrap();

        // Should be identical
        assert_eq!(epic_lazy.name, epic_full.name);
        assert_eq!(epic_lazy.tasks.len(), epic_full.tasks.len());
    }

    #[test]
    fn test_load_active_epic() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();
        let mut epic = Epic::new("ACTIVE-1".to_string());
        epic.add_task(crate::models::Task::new(
            "task-1".to_string(),
            "Test".to_string(),
            "Desc".to_string(),
        ));
        tasks.insert("ACTIVE-1".to_string(), epic);
        storage.save_tasks(&tasks).unwrap();
        storage.set_active_epic("ACTIVE-1").unwrap();

        // Load active epic directly
        let epic = storage.load_active_epic().unwrap();
        assert_eq!(epic.name, "ACTIVE-1");
        assert_eq!(epic.tasks.len(), 1);
    }

    #[test]
    fn test_load_active_epic_when_none_set() {
        let (storage, _temp_dir) = create_test_storage();

        // Should error when no active epic
        let result = storage.load_active_epic();
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("No active epic"));
    }

    #[test]
    fn test_update_epic_without_loading_all() {
        let (storage, _temp_dir) = create_test_storage();

        let mut tasks = HashMap::new();
        tasks.insert("EPIC-1".to_string(), Epic::new("EPIC-1".to_string()));
        tasks.insert("EPIC-2".to_string(), Epic::new("EPIC-2".to_string()));
        storage.save_tasks(&tasks).unwrap();

        // Update only EPIC-1
        let mut epic1 = storage.load_epic("EPIC-1").unwrap();
        epic1.add_task(crate::models::Task::new(
            "new-task".to_string(),
            "New".to_string(),
            "Desc".to_string(),
        ));
        storage.update_epic("EPIC-1", &epic1).unwrap();

        // Verify update
        let loaded = storage.load_epic("EPIC-1").unwrap();
        assert_eq!(loaded.tasks.len(), 1);

        // Verify EPIC-2 unchanged
        let epic2 = storage.load_epic("EPIC-2").unwrap();
        assert_eq!(epic2.tasks.len(), 0);
    }
}
</file>

</files>
